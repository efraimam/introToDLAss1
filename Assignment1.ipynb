{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/efraimam/introToDLAss1/blob/submit/Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bhfIKbQzGq2"
      },
      "source": [
        "# Assignment 1. Music Century Classification\n",
        "\n",
        "**Deadline**: Sunday, April 4th, by 9pm.\n",
        "\n",
        "**Submission**: Submit a PDF export of the completed notebook as well as the ipynb file. \n",
        "\n",
        "\n",
        "\n",
        "In this assignment, we will build models to predict which\n",
        "**century** a piece of music was released.  We will be using the \"YearPredictionMSD Data Set\"\n",
        "based on the Million Song Dataset. The data is available to download from the UCI \n",
        "Machine Learning Repository. Here are some links about the data:\n",
        "\n",
        "- https://archive.ics.uci.edu/ml/datasets/yearpredictionmsd\n",
        "- http://millionsongdataset.com/pages/tasks-demos/#yearrecognition\n",
        "\n",
        "Note that you are note allowed to import additional packages **(especially not PyTorch)**. One of the objectives is to understand how the training procedure actually operates, before working with PyTorch's autograd engine which does it all for us.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47oq1vy5PUIV"
      },
      "source": [
        "## Question 1. Data (21%)\n",
        "\n",
        "Start by setting up a Google Colab notebook in which to do your work.\n",
        "Since you are working with a partner, you might find this link helpful:\n",
        "\n",
        "- https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb\n",
        "\n",
        "The recommended way to work together is pair coding, where you and your partner are sitting together and writing code together. \n",
        "\n",
        "To process and read the data, we use the popular `pandas` package for data analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aFWpuNSzGq9"
      },
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7UWL6mFzGq-"
      },
      "source": [
        "Now that your notebook is set up, we can load the data into the notebook. The code below provides\n",
        "two ways of loading the data: directly from the internet, or through mounting Google Drive.\n",
        "The first method is easier but slower, and the second method is a bit involved at first, but\n",
        "can save you time later on. You will need to mount Google Drive for later assignments, so we recommend\n",
        "figuring how to do that now.\n",
        "\n",
        "Here are some resources to help you get started:\n",
        "\n",
        "- http.://colab.research.google.com/notebooks/io.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY6PrfV4zGq_"
      },
      "source": [
        "load_from_drive = False\n",
        "\n",
        "if not load_from_drive:\n",
        "  csv_path = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip\"\n",
        "else:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  csv_path = '/content/gdrive/My Drive/YearPredictionMSD.txt.zip' # TODO - UPDATE ME WITH THE TRUE PATH!\n",
        "\n",
        "t_label = [\"year\"]\n",
        "x_labels = [\"var%d\" % i for i in range(1, 91)]\n",
        "df = pandas.read_csv(csv_path, names=t_label + x_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgB83beNzGq_"
      },
      "source": [
        "Now that the data is loaded to your Colab notebook, you should be able to display the Pandas\n",
        "DataFrame `df` as a table:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5bBEnj3zGq_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "43bc24bd-e65c-4ded-a3ae-ec0362f2ce5b"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>var1</th>\n",
              "      <th>var2</th>\n",
              "      <th>var3</th>\n",
              "      <th>var4</th>\n",
              "      <th>var5</th>\n",
              "      <th>var6</th>\n",
              "      <th>var7</th>\n",
              "      <th>var8</th>\n",
              "      <th>var9</th>\n",
              "      <th>var10</th>\n",
              "      <th>var11</th>\n",
              "      <th>var12</th>\n",
              "      <th>var13</th>\n",
              "      <th>var14</th>\n",
              "      <th>var15</th>\n",
              "      <th>var16</th>\n",
              "      <th>var17</th>\n",
              "      <th>var18</th>\n",
              "      <th>var19</th>\n",
              "      <th>var20</th>\n",
              "      <th>var21</th>\n",
              "      <th>var22</th>\n",
              "      <th>var23</th>\n",
              "      <th>var24</th>\n",
              "      <th>var25</th>\n",
              "      <th>var26</th>\n",
              "      <th>var27</th>\n",
              "      <th>var28</th>\n",
              "      <th>var29</th>\n",
              "      <th>var30</th>\n",
              "      <th>var31</th>\n",
              "      <th>var32</th>\n",
              "      <th>var33</th>\n",
              "      <th>var34</th>\n",
              "      <th>var35</th>\n",
              "      <th>var36</th>\n",
              "      <th>var37</th>\n",
              "      <th>var38</th>\n",
              "      <th>var39</th>\n",
              "      <th>...</th>\n",
              "      <th>var51</th>\n",
              "      <th>var52</th>\n",
              "      <th>var53</th>\n",
              "      <th>var54</th>\n",
              "      <th>var55</th>\n",
              "      <th>var56</th>\n",
              "      <th>var57</th>\n",
              "      <th>var58</th>\n",
              "      <th>var59</th>\n",
              "      <th>var60</th>\n",
              "      <th>var61</th>\n",
              "      <th>var62</th>\n",
              "      <th>var63</th>\n",
              "      <th>var64</th>\n",
              "      <th>var65</th>\n",
              "      <th>var66</th>\n",
              "      <th>var67</th>\n",
              "      <th>var68</th>\n",
              "      <th>var69</th>\n",
              "      <th>var70</th>\n",
              "      <th>var71</th>\n",
              "      <th>var72</th>\n",
              "      <th>var73</th>\n",
              "      <th>var74</th>\n",
              "      <th>var75</th>\n",
              "      <th>var76</th>\n",
              "      <th>var77</th>\n",
              "      <th>var78</th>\n",
              "      <th>var79</th>\n",
              "      <th>var80</th>\n",
              "      <th>var81</th>\n",
              "      <th>var82</th>\n",
              "      <th>var83</th>\n",
              "      <th>var84</th>\n",
              "      <th>var85</th>\n",
              "      <th>var86</th>\n",
              "      <th>var87</th>\n",
              "      <th>var88</th>\n",
              "      <th>var89</th>\n",
              "      <th>var90</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>49.94357</td>\n",
              "      <td>21.47114</td>\n",
              "      <td>73.07750</td>\n",
              "      <td>8.74861</td>\n",
              "      <td>-17.40628</td>\n",
              "      <td>-13.09905</td>\n",
              "      <td>-25.01202</td>\n",
              "      <td>-12.23257</td>\n",
              "      <td>7.83089</td>\n",
              "      <td>-2.46783</td>\n",
              "      <td>3.32136</td>\n",
              "      <td>-2.31521</td>\n",
              "      <td>10.20556</td>\n",
              "      <td>611.10913</td>\n",
              "      <td>951.08960</td>\n",
              "      <td>698.11428</td>\n",
              "      <td>408.98485</td>\n",
              "      <td>383.70912</td>\n",
              "      <td>326.51512</td>\n",
              "      <td>238.11327</td>\n",
              "      <td>251.42414</td>\n",
              "      <td>187.17351</td>\n",
              "      <td>100.42652</td>\n",
              "      <td>179.19498</td>\n",
              "      <td>-8.41558</td>\n",
              "      <td>-317.87038</td>\n",
              "      <td>95.86266</td>\n",
              "      <td>48.10259</td>\n",
              "      <td>-95.66303</td>\n",
              "      <td>-18.06215</td>\n",
              "      <td>1.96984</td>\n",
              "      <td>34.42438</td>\n",
              "      <td>11.72670</td>\n",
              "      <td>1.36790</td>\n",
              "      <td>7.79444</td>\n",
              "      <td>-0.36994</td>\n",
              "      <td>-133.67852</td>\n",
              "      <td>-83.26165</td>\n",
              "      <td>-37.29765</td>\n",
              "      <td>...</td>\n",
              "      <td>-25.38187</td>\n",
              "      <td>-3.90772</td>\n",
              "      <td>13.29258</td>\n",
              "      <td>41.55060</td>\n",
              "      <td>-7.26272</td>\n",
              "      <td>-21.00863</td>\n",
              "      <td>105.50848</td>\n",
              "      <td>64.29856</td>\n",
              "      <td>26.08481</td>\n",
              "      <td>-44.59110</td>\n",
              "      <td>-8.30657</td>\n",
              "      <td>7.93706</td>\n",
              "      <td>-10.73660</td>\n",
              "      <td>-95.44766</td>\n",
              "      <td>-82.03307</td>\n",
              "      <td>-35.59194</td>\n",
              "      <td>4.69525</td>\n",
              "      <td>70.95626</td>\n",
              "      <td>28.09139</td>\n",
              "      <td>6.02015</td>\n",
              "      <td>-37.13767</td>\n",
              "      <td>-41.12450</td>\n",
              "      <td>-8.40816</td>\n",
              "      <td>7.19877</td>\n",
              "      <td>-8.60176</td>\n",
              "      <td>-5.90857</td>\n",
              "      <td>-12.32437</td>\n",
              "      <td>14.68734</td>\n",
              "      <td>-54.32125</td>\n",
              "      <td>40.14786</td>\n",
              "      <td>13.01620</td>\n",
              "      <td>-54.40548</td>\n",
              "      <td>58.99367</td>\n",
              "      <td>15.37344</td>\n",
              "      <td>1.11144</td>\n",
              "      <td>-23.08793</td>\n",
              "      <td>68.40795</td>\n",
              "      <td>-1.82223</td>\n",
              "      <td>-27.46348</td>\n",
              "      <td>2.26327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.73215</td>\n",
              "      <td>18.42930</td>\n",
              "      <td>70.32679</td>\n",
              "      <td>12.94636</td>\n",
              "      <td>-10.32437</td>\n",
              "      <td>-24.83777</td>\n",
              "      <td>8.76630</td>\n",
              "      <td>-0.92019</td>\n",
              "      <td>18.76548</td>\n",
              "      <td>4.59210</td>\n",
              "      <td>2.21920</td>\n",
              "      <td>0.34006</td>\n",
              "      <td>44.38997</td>\n",
              "      <td>2056.93836</td>\n",
              "      <td>605.40696</td>\n",
              "      <td>457.41175</td>\n",
              "      <td>777.15347</td>\n",
              "      <td>415.64880</td>\n",
              "      <td>746.47775</td>\n",
              "      <td>366.45320</td>\n",
              "      <td>317.82946</td>\n",
              "      <td>273.07917</td>\n",
              "      <td>141.75921</td>\n",
              "      <td>317.35269</td>\n",
              "      <td>19.48271</td>\n",
              "      <td>-65.25496</td>\n",
              "      <td>162.75145</td>\n",
              "      <td>135.00765</td>\n",
              "      <td>-96.28436</td>\n",
              "      <td>-86.87955</td>\n",
              "      <td>17.38087</td>\n",
              "      <td>45.90742</td>\n",
              "      <td>32.49908</td>\n",
              "      <td>-32.85429</td>\n",
              "      <td>45.10830</td>\n",
              "      <td>26.84939</td>\n",
              "      <td>-302.57328</td>\n",
              "      <td>-41.71932</td>\n",
              "      <td>-138.85034</td>\n",
              "      <td>...</td>\n",
              "      <td>28.55107</td>\n",
              "      <td>1.52298</td>\n",
              "      <td>70.99515</td>\n",
              "      <td>-43.63073</td>\n",
              "      <td>-42.55014</td>\n",
              "      <td>129.82848</td>\n",
              "      <td>79.95420</td>\n",
              "      <td>-87.14554</td>\n",
              "      <td>-45.75446</td>\n",
              "      <td>-65.82100</td>\n",
              "      <td>-43.90031</td>\n",
              "      <td>-19.45705</td>\n",
              "      <td>12.59163</td>\n",
              "      <td>-407.64130</td>\n",
              "      <td>42.91189</td>\n",
              "      <td>12.15850</td>\n",
              "      <td>-88.37882</td>\n",
              "      <td>42.25246</td>\n",
              "      <td>46.49209</td>\n",
              "      <td>-30.17747</td>\n",
              "      <td>45.98495</td>\n",
              "      <td>130.47892</td>\n",
              "      <td>13.88281</td>\n",
              "      <td>-4.00055</td>\n",
              "      <td>17.85965</td>\n",
              "      <td>-18.32138</td>\n",
              "      <td>-87.99109</td>\n",
              "      <td>14.37524</td>\n",
              "      <td>-22.70119</td>\n",
              "      <td>-58.81266</td>\n",
              "      <td>5.66812</td>\n",
              "      <td>-19.68073</td>\n",
              "      <td>33.04964</td>\n",
              "      <td>42.87836</td>\n",
              "      <td>-9.90378</td>\n",
              "      <td>-32.22788</td>\n",
              "      <td>70.49388</td>\n",
              "      <td>12.04941</td>\n",
              "      <td>58.43453</td>\n",
              "      <td>26.92061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.95714</td>\n",
              "      <td>31.85602</td>\n",
              "      <td>55.81851</td>\n",
              "      <td>13.41693</td>\n",
              "      <td>-6.57898</td>\n",
              "      <td>-18.54940</td>\n",
              "      <td>-3.27872</td>\n",
              "      <td>-2.35035</td>\n",
              "      <td>16.07017</td>\n",
              "      <td>1.39518</td>\n",
              "      <td>2.73553</td>\n",
              "      <td>0.82804</td>\n",
              "      <td>7.46586</td>\n",
              "      <td>699.54544</td>\n",
              "      <td>1016.00954</td>\n",
              "      <td>594.06748</td>\n",
              "      <td>355.73663</td>\n",
              "      <td>507.39931</td>\n",
              "      <td>387.69910</td>\n",
              "      <td>287.15347</td>\n",
              "      <td>112.37152</td>\n",
              "      <td>161.68928</td>\n",
              "      <td>144.14353</td>\n",
              "      <td>199.29693</td>\n",
              "      <td>-4.24359</td>\n",
              "      <td>-297.00587</td>\n",
              "      <td>-148.36392</td>\n",
              "      <td>-7.94726</td>\n",
              "      <td>-18.71630</td>\n",
              "      <td>12.77542</td>\n",
              "      <td>-25.37725</td>\n",
              "      <td>9.71410</td>\n",
              "      <td>0.13843</td>\n",
              "      <td>26.79723</td>\n",
              "      <td>6.30760</td>\n",
              "      <td>28.70107</td>\n",
              "      <td>-74.89005</td>\n",
              "      <td>-289.19553</td>\n",
              "      <td>-166.26089</td>\n",
              "      <td>...</td>\n",
              "      <td>18.50939</td>\n",
              "      <td>16.97216</td>\n",
              "      <td>24.26629</td>\n",
              "      <td>-10.50788</td>\n",
              "      <td>-8.68412</td>\n",
              "      <td>54.75759</td>\n",
              "      <td>194.74034</td>\n",
              "      <td>7.95966</td>\n",
              "      <td>-18.22685</td>\n",
              "      <td>0.06463</td>\n",
              "      <td>-2.63069</td>\n",
              "      <td>26.02561</td>\n",
              "      <td>1.75729</td>\n",
              "      <td>-262.36917</td>\n",
              "      <td>-233.60089</td>\n",
              "      <td>-2.50502</td>\n",
              "      <td>-12.14279</td>\n",
              "      <td>81.37617</td>\n",
              "      <td>2.07554</td>\n",
              "      <td>-1.82381</td>\n",
              "      <td>183.65292</td>\n",
              "      <td>22.64797</td>\n",
              "      <td>-39.98887</td>\n",
              "      <td>43.37381</td>\n",
              "      <td>-31.56737</td>\n",
              "      <td>-4.88840</td>\n",
              "      <td>-36.53213</td>\n",
              "      <td>-23.94662</td>\n",
              "      <td>-84.19275</td>\n",
              "      <td>66.00518</td>\n",
              "      <td>3.03800</td>\n",
              "      <td>26.05866</td>\n",
              "      <td>-50.92779</td>\n",
              "      <td>10.93792</td>\n",
              "      <td>-0.07568</td>\n",
              "      <td>43.20130</td>\n",
              "      <td>-115.00698</td>\n",
              "      <td>-0.05859</td>\n",
              "      <td>39.67068</td>\n",
              "      <td>-0.66345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.24750</td>\n",
              "      <td>-1.89837</td>\n",
              "      <td>36.29772</td>\n",
              "      <td>2.58776</td>\n",
              "      <td>0.97170</td>\n",
              "      <td>-26.21683</td>\n",
              "      <td>5.05097</td>\n",
              "      <td>-10.34124</td>\n",
              "      <td>3.55005</td>\n",
              "      <td>-6.36304</td>\n",
              "      <td>6.63016</td>\n",
              "      <td>-3.35142</td>\n",
              "      <td>37.64085</td>\n",
              "      <td>2174.08189</td>\n",
              "      <td>697.43346</td>\n",
              "      <td>459.24587</td>\n",
              "      <td>742.78961</td>\n",
              "      <td>229.30783</td>\n",
              "      <td>387.89697</td>\n",
              "      <td>249.06662</td>\n",
              "      <td>245.89870</td>\n",
              "      <td>176.20527</td>\n",
              "      <td>98.82222</td>\n",
              "      <td>150.97286</td>\n",
              "      <td>78.49057</td>\n",
              "      <td>-62.00282</td>\n",
              "      <td>43.49659</td>\n",
              "      <td>-96.42719</td>\n",
              "      <td>-108.96608</td>\n",
              "      <td>14.22854</td>\n",
              "      <td>14.54178</td>\n",
              "      <td>-23.55608</td>\n",
              "      <td>-39.36953</td>\n",
              "      <td>-43.59209</td>\n",
              "      <td>20.83714</td>\n",
              "      <td>35.63919</td>\n",
              "      <td>-181.34947</td>\n",
              "      <td>-93.66614</td>\n",
              "      <td>-90.55616</td>\n",
              "      <td>...</td>\n",
              "      <td>4.56917</td>\n",
              "      <td>-37.32280</td>\n",
              "      <td>4.15159</td>\n",
              "      <td>12.24315</td>\n",
              "      <td>35.02697</td>\n",
              "      <td>-178.89573</td>\n",
              "      <td>82.46573</td>\n",
              "      <td>-20.49425</td>\n",
              "      <td>101.78577</td>\n",
              "      <td>-19.77808</td>\n",
              "      <td>-21.52657</td>\n",
              "      <td>3.36303</td>\n",
              "      <td>-11.63176</td>\n",
              "      <td>51.55411</td>\n",
              "      <td>-50.57576</td>\n",
              "      <td>-28.14755</td>\n",
              "      <td>-83.15795</td>\n",
              "      <td>-7.35260</td>\n",
              "      <td>-22.11505</td>\n",
              "      <td>1.18279</td>\n",
              "      <td>-122.70467</td>\n",
              "      <td>150.57360</td>\n",
              "      <td>24.37468</td>\n",
              "      <td>41.19821</td>\n",
              "      <td>-37.04318</td>\n",
              "      <td>-28.72986</td>\n",
              "      <td>162.19614</td>\n",
              "      <td>22.18309</td>\n",
              "      <td>-8.63509</td>\n",
              "      <td>85.23416</td>\n",
              "      <td>34.57337</td>\n",
              "      <td>-171.70734</td>\n",
              "      <td>-16.96705</td>\n",
              "      <td>-46.67617</td>\n",
              "      <td>-12.51516</td>\n",
              "      <td>82.58061</td>\n",
              "      <td>-72.08993</td>\n",
              "      <td>9.90558</td>\n",
              "      <td>199.62971</td>\n",
              "      <td>18.85382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.97020</td>\n",
              "      <td>42.20998</td>\n",
              "      <td>67.09964</td>\n",
              "      <td>8.46791</td>\n",
              "      <td>-15.85279</td>\n",
              "      <td>-16.81409</td>\n",
              "      <td>-12.48207</td>\n",
              "      <td>-9.37636</td>\n",
              "      <td>12.63699</td>\n",
              "      <td>0.93609</td>\n",
              "      <td>1.60923</td>\n",
              "      <td>2.19223</td>\n",
              "      <td>47.32082</td>\n",
              "      <td>894.28471</td>\n",
              "      <td>809.86615</td>\n",
              "      <td>318.78559</td>\n",
              "      <td>435.04497</td>\n",
              "      <td>341.61467</td>\n",
              "      <td>334.30734</td>\n",
              "      <td>322.99589</td>\n",
              "      <td>190.61921</td>\n",
              "      <td>235.84715</td>\n",
              "      <td>96.89517</td>\n",
              "      <td>210.58870</td>\n",
              "      <td>5.60463</td>\n",
              "      <td>-199.63958</td>\n",
              "      <td>204.85812</td>\n",
              "      <td>-77.17695</td>\n",
              "      <td>-65.79741</td>\n",
              "      <td>-6.95097</td>\n",
              "      <td>-12.15262</td>\n",
              "      <td>-3.85410</td>\n",
              "      <td>20.68990</td>\n",
              "      <td>-20.30480</td>\n",
              "      <td>37.15045</td>\n",
              "      <td>11.20673</td>\n",
              "      <td>-124.09519</td>\n",
              "      <td>-295.98542</td>\n",
              "      <td>-33.31169</td>\n",
              "      <td>...</td>\n",
              "      <td>45.25506</td>\n",
              "      <td>10.42226</td>\n",
              "      <td>27.88782</td>\n",
              "      <td>-17.12676</td>\n",
              "      <td>-31.54772</td>\n",
              "      <td>-76.86293</td>\n",
              "      <td>41.17343</td>\n",
              "      <td>-138.32535</td>\n",
              "      <td>-53.96905</td>\n",
              "      <td>-21.30266</td>\n",
              "      <td>-24.87362</td>\n",
              "      <td>-2.46595</td>\n",
              "      <td>-4.05003</td>\n",
              "      <td>-56.51161</td>\n",
              "      <td>-34.56445</td>\n",
              "      <td>-5.07092</td>\n",
              "      <td>-47.75605</td>\n",
              "      <td>64.81513</td>\n",
              "      <td>-97.42948</td>\n",
              "      <td>-12.59418</td>\n",
              "      <td>55.23699</td>\n",
              "      <td>28.85657</td>\n",
              "      <td>54.53513</td>\n",
              "      <td>-31.97077</td>\n",
              "      <td>20.03279</td>\n",
              "      <td>-8.07892</td>\n",
              "      <td>-55.12617</td>\n",
              "      <td>26.58961</td>\n",
              "      <td>-10.27183</td>\n",
              "      <td>-30.64232</td>\n",
              "      <td>9.92661</td>\n",
              "      <td>-55.95724</td>\n",
              "      <td>64.92712</td>\n",
              "      <td>-17.72522</td>\n",
              "      <td>-1.49237</td>\n",
              "      <td>-7.50035</td>\n",
              "      <td>51.76631</td>\n",
              "      <td>7.88713</td>\n",
              "      <td>55.66926</td>\n",
              "      <td>28.74903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515340</th>\n",
              "      <td>2006</td>\n",
              "      <td>51.28467</td>\n",
              "      <td>45.88068</td>\n",
              "      <td>22.19582</td>\n",
              "      <td>-5.53319</td>\n",
              "      <td>-3.61835</td>\n",
              "      <td>-16.36914</td>\n",
              "      <td>2.12652</td>\n",
              "      <td>5.18160</td>\n",
              "      <td>-8.66890</td>\n",
              "      <td>2.67217</td>\n",
              "      <td>0.45234</td>\n",
              "      <td>2.51380</td>\n",
              "      <td>18.79583</td>\n",
              "      <td>592.17931</td>\n",
              "      <td>619.01842</td>\n",
              "      <td>681.30323</td>\n",
              "      <td>415.21939</td>\n",
              "      <td>639.90327</td>\n",
              "      <td>287.20710</td>\n",
              "      <td>375.31963</td>\n",
              "      <td>212.76265</td>\n",
              "      <td>246.26651</td>\n",
              "      <td>143.48234</td>\n",
              "      <td>217.45556</td>\n",
              "      <td>9.90577</td>\n",
              "      <td>-62.51153</td>\n",
              "      <td>-76.96635</td>\n",
              "      <td>-60.62065</td>\n",
              "      <td>67.81811</td>\n",
              "      <td>-9.20742</td>\n",
              "      <td>-30.73303</td>\n",
              "      <td>21.58525</td>\n",
              "      <td>-31.21664</td>\n",
              "      <td>-36.39659</td>\n",
              "      <td>28.18814</td>\n",
              "      <td>39.46981</td>\n",
              "      <td>-77.13200</td>\n",
              "      <td>-43.39948</td>\n",
              "      <td>-57.69462</td>\n",
              "      <td>...</td>\n",
              "      <td>-74.40960</td>\n",
              "      <td>78.78128</td>\n",
              "      <td>-14.74786</td>\n",
              "      <td>18.02148</td>\n",
              "      <td>-19.61304</td>\n",
              "      <td>-50.34714</td>\n",
              "      <td>87.06521</td>\n",
              "      <td>43.77874</td>\n",
              "      <td>-5.00339</td>\n",
              "      <td>101.08108</td>\n",
              "      <td>-13.34314</td>\n",
              "      <td>-59.17573</td>\n",
              "      <td>-46.22182</td>\n",
              "      <td>-27.10155</td>\n",
              "      <td>-7.07840</td>\n",
              "      <td>23.04732</td>\n",
              "      <td>29.32027</td>\n",
              "      <td>2.10740</td>\n",
              "      <td>-5.77951</td>\n",
              "      <td>2.68326</td>\n",
              "      <td>-13.78081</td>\n",
              "      <td>6.33542</td>\n",
              "      <td>-37.38191</td>\n",
              "      <td>-14.90918</td>\n",
              "      <td>26.87263</td>\n",
              "      <td>7.07232</td>\n",
              "      <td>-127.04955</td>\n",
              "      <td>86.78200</td>\n",
              "      <td>-68.14511</td>\n",
              "      <td>67.44416</td>\n",
              "      <td>4.81440</td>\n",
              "      <td>-3.75991</td>\n",
              "      <td>-30.92584</td>\n",
              "      <td>26.33968</td>\n",
              "      <td>-5.03390</td>\n",
              "      <td>21.86037</td>\n",
              "      <td>-142.29410</td>\n",
              "      <td>3.42901</td>\n",
              "      <td>-41.14721</td>\n",
              "      <td>-15.46052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515341</th>\n",
              "      <td>2006</td>\n",
              "      <td>49.87870</td>\n",
              "      <td>37.93125</td>\n",
              "      <td>18.65987</td>\n",
              "      <td>-3.63581</td>\n",
              "      <td>-27.75665</td>\n",
              "      <td>-18.52988</td>\n",
              "      <td>7.76108</td>\n",
              "      <td>3.56109</td>\n",
              "      <td>-2.50351</td>\n",
              "      <td>2.20175</td>\n",
              "      <td>-0.58487</td>\n",
              "      <td>-9.78657</td>\n",
              "      <td>35.81410</td>\n",
              "      <td>1047.28364</td>\n",
              "      <td>1451.87226</td>\n",
              "      <td>633.17982</td>\n",
              "      <td>448.46796</td>\n",
              "      <td>826.14418</td>\n",
              "      <td>277.55902</td>\n",
              "      <td>202.20787</td>\n",
              "      <td>241.85866</td>\n",
              "      <td>199.31274</td>\n",
              "      <td>180.60934</td>\n",
              "      <td>168.49980</td>\n",
              "      <td>89.28058</td>\n",
              "      <td>237.30605</td>\n",
              "      <td>-72.22211</td>\n",
              "      <td>-10.02772</td>\n",
              "      <td>-41.24980</td>\n",
              "      <td>-7.59473</td>\n",
              "      <td>-5.23307</td>\n",
              "      <td>24.88978</td>\n",
              "      <td>39.42813</td>\n",
              "      <td>-40.17760</td>\n",
              "      <td>26.51372</td>\n",
              "      <td>79.84191</td>\n",
              "      <td>-15.49724</td>\n",
              "      <td>46.37942</td>\n",
              "      <td>-209.97900</td>\n",
              "      <td>...</td>\n",
              "      <td>-61.06002</td>\n",
              "      <td>50.86072</td>\n",
              "      <td>-3.54799</td>\n",
              "      <td>36.50303</td>\n",
              "      <td>20.94570</td>\n",
              "      <td>-79.43478</td>\n",
              "      <td>-15.49133</td>\n",
              "      <td>17.79165</td>\n",
              "      <td>95.84510</td>\n",
              "      <td>-37.68620</td>\n",
              "      <td>8.51302</td>\n",
              "      <td>13.72492</td>\n",
              "      <td>-71.83419</td>\n",
              "      <td>-191.37407</td>\n",
              "      <td>-34.71662</td>\n",
              "      <td>28.34789</td>\n",
              "      <td>45.25187</td>\n",
              "      <td>17.07862</td>\n",
              "      <td>31.46894</td>\n",
              "      <td>-13.44802</td>\n",
              "      <td>38.68815</td>\n",
              "      <td>109.03046</td>\n",
              "      <td>-42.45525</td>\n",
              "      <td>18.67531</td>\n",
              "      <td>-50.86612</td>\n",
              "      <td>11.26242</td>\n",
              "      <td>59.30165</td>\n",
              "      <td>178.15846</td>\n",
              "      <td>-29.04997</td>\n",
              "      <td>70.22336</td>\n",
              "      <td>32.38589</td>\n",
              "      <td>-32.75535</td>\n",
              "      <td>-61.05473</td>\n",
              "      <td>56.65182</td>\n",
              "      <td>15.29965</td>\n",
              "      <td>95.88193</td>\n",
              "      <td>-10.63242</td>\n",
              "      <td>12.96552</td>\n",
              "      <td>92.11633</td>\n",
              "      <td>10.88815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515342</th>\n",
              "      <td>2006</td>\n",
              "      <td>45.12852</td>\n",
              "      <td>12.65758</td>\n",
              "      <td>-38.72018</td>\n",
              "      <td>8.80882</td>\n",
              "      <td>-29.29985</td>\n",
              "      <td>-2.28706</td>\n",
              "      <td>-18.40424</td>\n",
              "      <td>-22.28726</td>\n",
              "      <td>-4.52429</td>\n",
              "      <td>-11.46411</td>\n",
              "      <td>3.28514</td>\n",
              "      <td>1.99943</td>\n",
              "      <td>27.77109</td>\n",
              "      <td>1693.72442</td>\n",
              "      <td>3825.48305</td>\n",
              "      <td>2714.53243</td>\n",
              "      <td>1036.34216</td>\n",
              "      <td>1171.81248</td>\n",
              "      <td>468.44308</td>\n",
              "      <td>1042.15436</td>\n",
              "      <td>278.94429</td>\n",
              "      <td>497.83085</td>\n",
              "      <td>423.82729</td>\n",
              "      <td>239.91028</td>\n",
              "      <td>-61.01287</td>\n",
              "      <td>-1383.48696</td>\n",
              "      <td>-1828.43740</td>\n",
              "      <td>-131.54731</td>\n",
              "      <td>138.81510</td>\n",
              "      <td>51.36991</td>\n",
              "      <td>-45.25035</td>\n",
              "      <td>138.31791</td>\n",
              "      <td>-107.60348</td>\n",
              "      <td>-17.01878</td>\n",
              "      <td>-36.53276</td>\n",
              "      <td>226.67213</td>\n",
              "      <td>716.76768</td>\n",
              "      <td>-267.06525</td>\n",
              "      <td>-362.27860</td>\n",
              "      <td>...</td>\n",
              "      <td>191.56779</td>\n",
              "      <td>72.49396</td>\n",
              "      <td>-38.96949</td>\n",
              "      <td>61.22195</td>\n",
              "      <td>24.49062</td>\n",
              "      <td>182.62433</td>\n",
              "      <td>510.41684</td>\n",
              "      <td>-379.38804</td>\n",
              "      <td>226.54992</td>\n",
              "      <td>-201.28237</td>\n",
              "      <td>6.89971</td>\n",
              "      <td>86.07237</td>\n",
              "      <td>-42.85773</td>\n",
              "      <td>-215.01900</td>\n",
              "      <td>88.60866</td>\n",
              "      <td>14.51385</td>\n",
              "      <td>-28.33832</td>\n",
              "      <td>255.17385</td>\n",
              "      <td>14.17125</td>\n",
              "      <td>25.06417</td>\n",
              "      <td>218.85618</td>\n",
              "      <td>-222.53173</td>\n",
              "      <td>35.58546</td>\n",
              "      <td>30.88622</td>\n",
              "      <td>-24.91594</td>\n",
              "      <td>-2.65009</td>\n",
              "      <td>-69.53483</td>\n",
              "      <td>333.67598</td>\n",
              "      <td>-28.24399</td>\n",
              "      <td>202.51566</td>\n",
              "      <td>-18.73598</td>\n",
              "      <td>-71.15954</td>\n",
              "      <td>-123.98443</td>\n",
              "      <td>121.26989</td>\n",
              "      <td>10.89629</td>\n",
              "      <td>34.62409</td>\n",
              "      <td>-248.61020</td>\n",
              "      <td>-6.07171</td>\n",
              "      <td>53.96319</td>\n",
              "      <td>-8.09364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515343</th>\n",
              "      <td>2006</td>\n",
              "      <td>44.16614</td>\n",
              "      <td>32.38368</td>\n",
              "      <td>-3.34971</td>\n",
              "      <td>-2.49165</td>\n",
              "      <td>-19.59278</td>\n",
              "      <td>-18.67098</td>\n",
              "      <td>8.78428</td>\n",
              "      <td>4.02039</td>\n",
              "      <td>-12.01230</td>\n",
              "      <td>-0.74075</td>\n",
              "      <td>-1.26523</td>\n",
              "      <td>-4.41983</td>\n",
              "      <td>140.44937</td>\n",
              "      <td>2850.23336</td>\n",
              "      <td>1875.28895</td>\n",
              "      <td>1362.98053</td>\n",
              "      <td>784.39737</td>\n",
              "      <td>908.09838</td>\n",
              "      <td>367.12005</td>\n",
              "      <td>692.58547</td>\n",
              "      <td>286.72625</td>\n",
              "      <td>395.46735</td>\n",
              "      <td>221.19089</td>\n",
              "      <td>211.62098</td>\n",
              "      <td>141.17304</td>\n",
              "      <td>647.52054</td>\n",
              "      <td>-451.67671</td>\n",
              "      <td>-170.33993</td>\n",
              "      <td>-106.30851</td>\n",
              "      <td>129.80285</td>\n",
              "      <td>-118.54997</td>\n",
              "      <td>116.14019</td>\n",
              "      <td>-18.36186</td>\n",
              "      <td>-29.42843</td>\n",
              "      <td>13.59803</td>\n",
              "      <td>296.86552</td>\n",
              "      <td>-332.24640</td>\n",
              "      <td>219.84847</td>\n",
              "      <td>-180.27193</td>\n",
              "      <td>...</td>\n",
              "      <td>14.33401</td>\n",
              "      <td>-10.61959</td>\n",
              "      <td>-37.44137</td>\n",
              "      <td>32.72492</td>\n",
              "      <td>-16.62357</td>\n",
              "      <td>-343.07974</td>\n",
              "      <td>148.00075</td>\n",
              "      <td>-64.73672</td>\n",
              "      <td>59.16029</td>\n",
              "      <td>-129.60142</td>\n",
              "      <td>24.47146</td>\n",
              "      <td>-90.78617</td>\n",
              "      <td>-34.58624</td>\n",
              "      <td>-285.37506</td>\n",
              "      <td>-8.78066</td>\n",
              "      <td>63.91160</td>\n",
              "      <td>58.86067</td>\n",
              "      <td>43.28537</td>\n",
              "      <td>22.69472</td>\n",
              "      <td>-0.93940</td>\n",
              "      <td>417.76862</td>\n",
              "      <td>78.26912</td>\n",
              "      <td>-173.95232</td>\n",
              "      <td>-35.42845</td>\n",
              "      <td>10.59859</td>\n",
              "      <td>-16.51518</td>\n",
              "      <td>157.75671</td>\n",
              "      <td>294.31838</td>\n",
              "      <td>-37.30155</td>\n",
              "      <td>80.00327</td>\n",
              "      <td>67.16763</td>\n",
              "      <td>282.77624</td>\n",
              "      <td>-4.63677</td>\n",
              "      <td>144.00125</td>\n",
              "      <td>21.62652</td>\n",
              "      <td>-29.72432</td>\n",
              "      <td>71.47198</td>\n",
              "      <td>20.32240</td>\n",
              "      <td>14.83107</td>\n",
              "      <td>39.74909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515344</th>\n",
              "      <td>2005</td>\n",
              "      <td>51.85726</td>\n",
              "      <td>59.11655</td>\n",
              "      <td>26.39436</td>\n",
              "      <td>-5.46030</td>\n",
              "      <td>-20.69012</td>\n",
              "      <td>-19.95528</td>\n",
              "      <td>-6.72771</td>\n",
              "      <td>2.29590</td>\n",
              "      <td>10.31018</td>\n",
              "      <td>6.26597</td>\n",
              "      <td>-1.78800</td>\n",
              "      <td>-6.19786</td>\n",
              "      <td>20.16600</td>\n",
              "      <td>598.45275</td>\n",
              "      <td>1140.69539</td>\n",
              "      <td>721.49244</td>\n",
              "      <td>272.84841</td>\n",
              "      <td>564.06690</td>\n",
              "      <td>199.41547</td>\n",
              "      <td>189.04637</td>\n",
              "      <td>217.32042</td>\n",
              "      <td>137.13390</td>\n",
              "      <td>150.34608</td>\n",
              "      <td>98.21589</td>\n",
              "      <td>48.12644</td>\n",
              "      <td>-601.59295</td>\n",
              "      <td>10.58466</td>\n",
              "      <td>-83.35368</td>\n",
              "      <td>96.86756</td>\n",
              "      <td>69.40708</td>\n",
              "      <td>8.06033</td>\n",
              "      <td>-26.01693</td>\n",
              "      <td>-2.93173</td>\n",
              "      <td>26.18398</td>\n",
              "      <td>-12.24660</td>\n",
              "      <td>-14.52391</td>\n",
              "      <td>-121.61676</td>\n",
              "      <td>119.15632</td>\n",
              "      <td>-229.55722</td>\n",
              "      <td>...</td>\n",
              "      <td>1.78072</td>\n",
              "      <td>64.75548</td>\n",
              "      <td>24.55866</td>\n",
              "      <td>-1.12509</td>\n",
              "      <td>-13.58287</td>\n",
              "      <td>-99.66038</td>\n",
              "      <td>-124.73875</td>\n",
              "      <td>67.02630</td>\n",
              "      <td>33.05618</td>\n",
              "      <td>60.25818</td>\n",
              "      <td>28.00288</td>\n",
              "      <td>10.62425</td>\n",
              "      <td>-8.86772</td>\n",
              "      <td>78.13543</td>\n",
              "      <td>-181.10013</td>\n",
              "      <td>74.69489</td>\n",
              "      <td>57.45083</td>\n",
              "      <td>114.08816</td>\n",
              "      <td>-9.91322</td>\n",
              "      <td>7.53612</td>\n",
              "      <td>97.06395</td>\n",
              "      <td>233.17754</td>\n",
              "      <td>-100.68441</td>\n",
              "      <td>27.67012</td>\n",
              "      <td>-37.33008</td>\n",
              "      <td>-0.34676</td>\n",
              "      <td>-207.78766</td>\n",
              "      <td>116.75005</td>\n",
              "      <td>-91.82912</td>\n",
              "      <td>8.35020</td>\n",
              "      <td>-11.50511</td>\n",
              "      <td>-69.18291</td>\n",
              "      <td>60.58456</td>\n",
              "      <td>28.64599</td>\n",
              "      <td>-4.39620</td>\n",
              "      <td>-64.56491</td>\n",
              "      <td>-45.61012</td>\n",
              "      <td>-5.51512</td>\n",
              "      <td>32.35602</td>\n",
              "      <td>12.17352</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>515345 rows Ã— 91 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        year      var1      var2  ...     var88      var89     var90\n",
              "0       2001  49.94357  21.47114  ...  -1.82223  -27.46348   2.26327\n",
              "1       2001  48.73215  18.42930  ...  12.04941   58.43453  26.92061\n",
              "2       2001  50.95714  31.85602  ...  -0.05859   39.67068  -0.66345\n",
              "3       2001  48.24750  -1.89837  ...   9.90558  199.62971  18.85382\n",
              "4       2001  50.97020  42.20998  ...   7.88713   55.66926  28.74903\n",
              "...      ...       ...       ...  ...       ...        ...       ...\n",
              "515340  2006  51.28467  45.88068  ...   3.42901  -41.14721 -15.46052\n",
              "515341  2006  49.87870  37.93125  ...  12.96552   92.11633  10.88815\n",
              "515342  2006  45.12852  12.65758  ...  -6.07171   53.96319  -8.09364\n",
              "515343  2006  44.16614  32.38368  ...  20.32240   14.83107  39.74909\n",
              "515344  2005  51.85726  59.11655  ...  -5.51512   32.35602  12.17352\n",
              "\n",
              "[515345 rows x 91 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaLuAMH_zGrA"
      },
      "source": [
        "To set up our data for classification, we'll use the \"year\" field to represent\n",
        "whether a song was released in the 20-th century. In our case `df[\"year\"]` will be 1 if\n",
        "the year was released after 2000, and 0 otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZdGlNgdzGrA"
      },
      "source": [
        "df[\"year\"] = df[\"year\"].map(lambda x: int(x > 2000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xugy7FZ8eoAd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "outputId": "cd0ed5ba-d362-4782-9eb1-65aa19f0a2b1"
      },
      "source": [
        "df.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>var1</th>\n",
              "      <th>var2</th>\n",
              "      <th>var3</th>\n",
              "      <th>var4</th>\n",
              "      <th>var5</th>\n",
              "      <th>var6</th>\n",
              "      <th>var7</th>\n",
              "      <th>var8</th>\n",
              "      <th>var9</th>\n",
              "      <th>var10</th>\n",
              "      <th>var11</th>\n",
              "      <th>var12</th>\n",
              "      <th>var13</th>\n",
              "      <th>var14</th>\n",
              "      <th>var15</th>\n",
              "      <th>var16</th>\n",
              "      <th>var17</th>\n",
              "      <th>var18</th>\n",
              "      <th>var19</th>\n",
              "      <th>var20</th>\n",
              "      <th>var21</th>\n",
              "      <th>var22</th>\n",
              "      <th>var23</th>\n",
              "      <th>var24</th>\n",
              "      <th>var25</th>\n",
              "      <th>var26</th>\n",
              "      <th>var27</th>\n",
              "      <th>var28</th>\n",
              "      <th>var29</th>\n",
              "      <th>var30</th>\n",
              "      <th>var31</th>\n",
              "      <th>var32</th>\n",
              "      <th>var33</th>\n",
              "      <th>var34</th>\n",
              "      <th>var35</th>\n",
              "      <th>var36</th>\n",
              "      <th>var37</th>\n",
              "      <th>var38</th>\n",
              "      <th>var39</th>\n",
              "      <th>...</th>\n",
              "      <th>var51</th>\n",
              "      <th>var52</th>\n",
              "      <th>var53</th>\n",
              "      <th>var54</th>\n",
              "      <th>var55</th>\n",
              "      <th>var56</th>\n",
              "      <th>var57</th>\n",
              "      <th>var58</th>\n",
              "      <th>var59</th>\n",
              "      <th>var60</th>\n",
              "      <th>var61</th>\n",
              "      <th>var62</th>\n",
              "      <th>var63</th>\n",
              "      <th>var64</th>\n",
              "      <th>var65</th>\n",
              "      <th>var66</th>\n",
              "      <th>var67</th>\n",
              "      <th>var68</th>\n",
              "      <th>var69</th>\n",
              "      <th>var70</th>\n",
              "      <th>var71</th>\n",
              "      <th>var72</th>\n",
              "      <th>var73</th>\n",
              "      <th>var74</th>\n",
              "      <th>var75</th>\n",
              "      <th>var76</th>\n",
              "      <th>var77</th>\n",
              "      <th>var78</th>\n",
              "      <th>var79</th>\n",
              "      <th>var80</th>\n",
              "      <th>var81</th>\n",
              "      <th>var82</th>\n",
              "      <th>var83</th>\n",
              "      <th>var84</th>\n",
              "      <th>var85</th>\n",
              "      <th>var86</th>\n",
              "      <th>var87</th>\n",
              "      <th>var88</th>\n",
              "      <th>var89</th>\n",
              "      <th>var90</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>49.94357</td>\n",
              "      <td>21.47114</td>\n",
              "      <td>73.07750</td>\n",
              "      <td>8.74861</td>\n",
              "      <td>-17.40628</td>\n",
              "      <td>-13.09905</td>\n",
              "      <td>-25.01202</td>\n",
              "      <td>-12.23257</td>\n",
              "      <td>7.83089</td>\n",
              "      <td>-2.46783</td>\n",
              "      <td>3.32136</td>\n",
              "      <td>-2.31521</td>\n",
              "      <td>10.20556</td>\n",
              "      <td>611.10913</td>\n",
              "      <td>951.08960</td>\n",
              "      <td>698.11428</td>\n",
              "      <td>408.98485</td>\n",
              "      <td>383.70912</td>\n",
              "      <td>326.51512</td>\n",
              "      <td>238.11327</td>\n",
              "      <td>251.42414</td>\n",
              "      <td>187.17351</td>\n",
              "      <td>100.42652</td>\n",
              "      <td>179.19498</td>\n",
              "      <td>-8.41558</td>\n",
              "      <td>-317.87038</td>\n",
              "      <td>95.86266</td>\n",
              "      <td>48.10259</td>\n",
              "      <td>-95.66303</td>\n",
              "      <td>-18.06215</td>\n",
              "      <td>1.96984</td>\n",
              "      <td>34.42438</td>\n",
              "      <td>11.72670</td>\n",
              "      <td>1.36790</td>\n",
              "      <td>7.79444</td>\n",
              "      <td>-0.36994</td>\n",
              "      <td>-133.67852</td>\n",
              "      <td>-83.26165</td>\n",
              "      <td>-37.29765</td>\n",
              "      <td>...</td>\n",
              "      <td>-25.38187</td>\n",
              "      <td>-3.90772</td>\n",
              "      <td>13.29258</td>\n",
              "      <td>41.55060</td>\n",
              "      <td>-7.26272</td>\n",
              "      <td>-21.00863</td>\n",
              "      <td>105.50848</td>\n",
              "      <td>64.29856</td>\n",
              "      <td>26.08481</td>\n",
              "      <td>-44.59110</td>\n",
              "      <td>-8.30657</td>\n",
              "      <td>7.93706</td>\n",
              "      <td>-10.73660</td>\n",
              "      <td>-95.44766</td>\n",
              "      <td>-82.03307</td>\n",
              "      <td>-35.59194</td>\n",
              "      <td>4.69525</td>\n",
              "      <td>70.95626</td>\n",
              "      <td>28.09139</td>\n",
              "      <td>6.02015</td>\n",
              "      <td>-37.13767</td>\n",
              "      <td>-41.12450</td>\n",
              "      <td>-8.40816</td>\n",
              "      <td>7.19877</td>\n",
              "      <td>-8.60176</td>\n",
              "      <td>-5.90857</td>\n",
              "      <td>-12.32437</td>\n",
              "      <td>14.68734</td>\n",
              "      <td>-54.32125</td>\n",
              "      <td>40.14786</td>\n",
              "      <td>13.01620</td>\n",
              "      <td>-54.40548</td>\n",
              "      <td>58.99367</td>\n",
              "      <td>15.37344</td>\n",
              "      <td>1.11144</td>\n",
              "      <td>-23.08793</td>\n",
              "      <td>68.40795</td>\n",
              "      <td>-1.82223</td>\n",
              "      <td>-27.46348</td>\n",
              "      <td>2.26327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>48.73215</td>\n",
              "      <td>18.42930</td>\n",
              "      <td>70.32679</td>\n",
              "      <td>12.94636</td>\n",
              "      <td>-10.32437</td>\n",
              "      <td>-24.83777</td>\n",
              "      <td>8.76630</td>\n",
              "      <td>-0.92019</td>\n",
              "      <td>18.76548</td>\n",
              "      <td>4.59210</td>\n",
              "      <td>2.21920</td>\n",
              "      <td>0.34006</td>\n",
              "      <td>44.38997</td>\n",
              "      <td>2056.93836</td>\n",
              "      <td>605.40696</td>\n",
              "      <td>457.41175</td>\n",
              "      <td>777.15347</td>\n",
              "      <td>415.64880</td>\n",
              "      <td>746.47775</td>\n",
              "      <td>366.45320</td>\n",
              "      <td>317.82946</td>\n",
              "      <td>273.07917</td>\n",
              "      <td>141.75921</td>\n",
              "      <td>317.35269</td>\n",
              "      <td>19.48271</td>\n",
              "      <td>-65.25496</td>\n",
              "      <td>162.75145</td>\n",
              "      <td>135.00765</td>\n",
              "      <td>-96.28436</td>\n",
              "      <td>-86.87955</td>\n",
              "      <td>17.38087</td>\n",
              "      <td>45.90742</td>\n",
              "      <td>32.49908</td>\n",
              "      <td>-32.85429</td>\n",
              "      <td>45.10830</td>\n",
              "      <td>26.84939</td>\n",
              "      <td>-302.57328</td>\n",
              "      <td>-41.71932</td>\n",
              "      <td>-138.85034</td>\n",
              "      <td>...</td>\n",
              "      <td>28.55107</td>\n",
              "      <td>1.52298</td>\n",
              "      <td>70.99515</td>\n",
              "      <td>-43.63073</td>\n",
              "      <td>-42.55014</td>\n",
              "      <td>129.82848</td>\n",
              "      <td>79.95420</td>\n",
              "      <td>-87.14554</td>\n",
              "      <td>-45.75446</td>\n",
              "      <td>-65.82100</td>\n",
              "      <td>-43.90031</td>\n",
              "      <td>-19.45705</td>\n",
              "      <td>12.59163</td>\n",
              "      <td>-407.64130</td>\n",
              "      <td>42.91189</td>\n",
              "      <td>12.15850</td>\n",
              "      <td>-88.37882</td>\n",
              "      <td>42.25246</td>\n",
              "      <td>46.49209</td>\n",
              "      <td>-30.17747</td>\n",
              "      <td>45.98495</td>\n",
              "      <td>130.47892</td>\n",
              "      <td>13.88281</td>\n",
              "      <td>-4.00055</td>\n",
              "      <td>17.85965</td>\n",
              "      <td>-18.32138</td>\n",
              "      <td>-87.99109</td>\n",
              "      <td>14.37524</td>\n",
              "      <td>-22.70119</td>\n",
              "      <td>-58.81266</td>\n",
              "      <td>5.66812</td>\n",
              "      <td>-19.68073</td>\n",
              "      <td>33.04964</td>\n",
              "      <td>42.87836</td>\n",
              "      <td>-9.90378</td>\n",
              "      <td>-32.22788</td>\n",
              "      <td>70.49388</td>\n",
              "      <td>12.04941</td>\n",
              "      <td>58.43453</td>\n",
              "      <td>26.92061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>50.95714</td>\n",
              "      <td>31.85602</td>\n",
              "      <td>55.81851</td>\n",
              "      <td>13.41693</td>\n",
              "      <td>-6.57898</td>\n",
              "      <td>-18.54940</td>\n",
              "      <td>-3.27872</td>\n",
              "      <td>-2.35035</td>\n",
              "      <td>16.07017</td>\n",
              "      <td>1.39518</td>\n",
              "      <td>2.73553</td>\n",
              "      <td>0.82804</td>\n",
              "      <td>7.46586</td>\n",
              "      <td>699.54544</td>\n",
              "      <td>1016.00954</td>\n",
              "      <td>594.06748</td>\n",
              "      <td>355.73663</td>\n",
              "      <td>507.39931</td>\n",
              "      <td>387.69910</td>\n",
              "      <td>287.15347</td>\n",
              "      <td>112.37152</td>\n",
              "      <td>161.68928</td>\n",
              "      <td>144.14353</td>\n",
              "      <td>199.29693</td>\n",
              "      <td>-4.24359</td>\n",
              "      <td>-297.00587</td>\n",
              "      <td>-148.36392</td>\n",
              "      <td>-7.94726</td>\n",
              "      <td>-18.71630</td>\n",
              "      <td>12.77542</td>\n",
              "      <td>-25.37725</td>\n",
              "      <td>9.71410</td>\n",
              "      <td>0.13843</td>\n",
              "      <td>26.79723</td>\n",
              "      <td>6.30760</td>\n",
              "      <td>28.70107</td>\n",
              "      <td>-74.89005</td>\n",
              "      <td>-289.19553</td>\n",
              "      <td>-166.26089</td>\n",
              "      <td>...</td>\n",
              "      <td>18.50939</td>\n",
              "      <td>16.97216</td>\n",
              "      <td>24.26629</td>\n",
              "      <td>-10.50788</td>\n",
              "      <td>-8.68412</td>\n",
              "      <td>54.75759</td>\n",
              "      <td>194.74034</td>\n",
              "      <td>7.95966</td>\n",
              "      <td>-18.22685</td>\n",
              "      <td>0.06463</td>\n",
              "      <td>-2.63069</td>\n",
              "      <td>26.02561</td>\n",
              "      <td>1.75729</td>\n",
              "      <td>-262.36917</td>\n",
              "      <td>-233.60089</td>\n",
              "      <td>-2.50502</td>\n",
              "      <td>-12.14279</td>\n",
              "      <td>81.37617</td>\n",
              "      <td>2.07554</td>\n",
              "      <td>-1.82381</td>\n",
              "      <td>183.65292</td>\n",
              "      <td>22.64797</td>\n",
              "      <td>-39.98887</td>\n",
              "      <td>43.37381</td>\n",
              "      <td>-31.56737</td>\n",
              "      <td>-4.88840</td>\n",
              "      <td>-36.53213</td>\n",
              "      <td>-23.94662</td>\n",
              "      <td>-84.19275</td>\n",
              "      <td>66.00518</td>\n",
              "      <td>3.03800</td>\n",
              "      <td>26.05866</td>\n",
              "      <td>-50.92779</td>\n",
              "      <td>10.93792</td>\n",
              "      <td>-0.07568</td>\n",
              "      <td>43.20130</td>\n",
              "      <td>-115.00698</td>\n",
              "      <td>-0.05859</td>\n",
              "      <td>39.67068</td>\n",
              "      <td>-0.66345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>48.24750</td>\n",
              "      <td>-1.89837</td>\n",
              "      <td>36.29772</td>\n",
              "      <td>2.58776</td>\n",
              "      <td>0.97170</td>\n",
              "      <td>-26.21683</td>\n",
              "      <td>5.05097</td>\n",
              "      <td>-10.34124</td>\n",
              "      <td>3.55005</td>\n",
              "      <td>-6.36304</td>\n",
              "      <td>6.63016</td>\n",
              "      <td>-3.35142</td>\n",
              "      <td>37.64085</td>\n",
              "      <td>2174.08189</td>\n",
              "      <td>697.43346</td>\n",
              "      <td>459.24587</td>\n",
              "      <td>742.78961</td>\n",
              "      <td>229.30783</td>\n",
              "      <td>387.89697</td>\n",
              "      <td>249.06662</td>\n",
              "      <td>245.89870</td>\n",
              "      <td>176.20527</td>\n",
              "      <td>98.82222</td>\n",
              "      <td>150.97286</td>\n",
              "      <td>78.49057</td>\n",
              "      <td>-62.00282</td>\n",
              "      <td>43.49659</td>\n",
              "      <td>-96.42719</td>\n",
              "      <td>-108.96608</td>\n",
              "      <td>14.22854</td>\n",
              "      <td>14.54178</td>\n",
              "      <td>-23.55608</td>\n",
              "      <td>-39.36953</td>\n",
              "      <td>-43.59209</td>\n",
              "      <td>20.83714</td>\n",
              "      <td>35.63919</td>\n",
              "      <td>-181.34947</td>\n",
              "      <td>-93.66614</td>\n",
              "      <td>-90.55616</td>\n",
              "      <td>...</td>\n",
              "      <td>4.56917</td>\n",
              "      <td>-37.32280</td>\n",
              "      <td>4.15159</td>\n",
              "      <td>12.24315</td>\n",
              "      <td>35.02697</td>\n",
              "      <td>-178.89573</td>\n",
              "      <td>82.46573</td>\n",
              "      <td>-20.49425</td>\n",
              "      <td>101.78577</td>\n",
              "      <td>-19.77808</td>\n",
              "      <td>-21.52657</td>\n",
              "      <td>3.36303</td>\n",
              "      <td>-11.63176</td>\n",
              "      <td>51.55411</td>\n",
              "      <td>-50.57576</td>\n",
              "      <td>-28.14755</td>\n",
              "      <td>-83.15795</td>\n",
              "      <td>-7.35260</td>\n",
              "      <td>-22.11505</td>\n",
              "      <td>1.18279</td>\n",
              "      <td>-122.70467</td>\n",
              "      <td>150.57360</td>\n",
              "      <td>24.37468</td>\n",
              "      <td>41.19821</td>\n",
              "      <td>-37.04318</td>\n",
              "      <td>-28.72986</td>\n",
              "      <td>162.19614</td>\n",
              "      <td>22.18309</td>\n",
              "      <td>-8.63509</td>\n",
              "      <td>85.23416</td>\n",
              "      <td>34.57337</td>\n",
              "      <td>-171.70734</td>\n",
              "      <td>-16.96705</td>\n",
              "      <td>-46.67617</td>\n",
              "      <td>-12.51516</td>\n",
              "      <td>82.58061</td>\n",
              "      <td>-72.08993</td>\n",
              "      <td>9.90558</td>\n",
              "      <td>199.62971</td>\n",
              "      <td>18.85382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50.97020</td>\n",
              "      <td>42.20998</td>\n",
              "      <td>67.09964</td>\n",
              "      <td>8.46791</td>\n",
              "      <td>-15.85279</td>\n",
              "      <td>-16.81409</td>\n",
              "      <td>-12.48207</td>\n",
              "      <td>-9.37636</td>\n",
              "      <td>12.63699</td>\n",
              "      <td>0.93609</td>\n",
              "      <td>1.60923</td>\n",
              "      <td>2.19223</td>\n",
              "      <td>47.32082</td>\n",
              "      <td>894.28471</td>\n",
              "      <td>809.86615</td>\n",
              "      <td>318.78559</td>\n",
              "      <td>435.04497</td>\n",
              "      <td>341.61467</td>\n",
              "      <td>334.30734</td>\n",
              "      <td>322.99589</td>\n",
              "      <td>190.61921</td>\n",
              "      <td>235.84715</td>\n",
              "      <td>96.89517</td>\n",
              "      <td>210.58870</td>\n",
              "      <td>5.60463</td>\n",
              "      <td>-199.63958</td>\n",
              "      <td>204.85812</td>\n",
              "      <td>-77.17695</td>\n",
              "      <td>-65.79741</td>\n",
              "      <td>-6.95097</td>\n",
              "      <td>-12.15262</td>\n",
              "      <td>-3.85410</td>\n",
              "      <td>20.68990</td>\n",
              "      <td>-20.30480</td>\n",
              "      <td>37.15045</td>\n",
              "      <td>11.20673</td>\n",
              "      <td>-124.09519</td>\n",
              "      <td>-295.98542</td>\n",
              "      <td>-33.31169</td>\n",
              "      <td>...</td>\n",
              "      <td>45.25506</td>\n",
              "      <td>10.42226</td>\n",
              "      <td>27.88782</td>\n",
              "      <td>-17.12676</td>\n",
              "      <td>-31.54772</td>\n",
              "      <td>-76.86293</td>\n",
              "      <td>41.17343</td>\n",
              "      <td>-138.32535</td>\n",
              "      <td>-53.96905</td>\n",
              "      <td>-21.30266</td>\n",
              "      <td>-24.87362</td>\n",
              "      <td>-2.46595</td>\n",
              "      <td>-4.05003</td>\n",
              "      <td>-56.51161</td>\n",
              "      <td>-34.56445</td>\n",
              "      <td>-5.07092</td>\n",
              "      <td>-47.75605</td>\n",
              "      <td>64.81513</td>\n",
              "      <td>-97.42948</td>\n",
              "      <td>-12.59418</td>\n",
              "      <td>55.23699</td>\n",
              "      <td>28.85657</td>\n",
              "      <td>54.53513</td>\n",
              "      <td>-31.97077</td>\n",
              "      <td>20.03279</td>\n",
              "      <td>-8.07892</td>\n",
              "      <td>-55.12617</td>\n",
              "      <td>26.58961</td>\n",
              "      <td>-10.27183</td>\n",
              "      <td>-30.64232</td>\n",
              "      <td>9.92661</td>\n",
              "      <td>-55.95724</td>\n",
              "      <td>64.92712</td>\n",
              "      <td>-17.72522</td>\n",
              "      <td>-1.49237</td>\n",
              "      <td>-7.50035</td>\n",
              "      <td>51.76631</td>\n",
              "      <td>7.88713</td>\n",
              "      <td>55.66926</td>\n",
              "      <td>28.74903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>50.54767</td>\n",
              "      <td>0.31568</td>\n",
              "      <td>92.35066</td>\n",
              "      <td>22.38696</td>\n",
              "      <td>-25.51870</td>\n",
              "      <td>-19.04928</td>\n",
              "      <td>20.67345</td>\n",
              "      <td>-5.19943</td>\n",
              "      <td>3.63566</td>\n",
              "      <td>-4.69088</td>\n",
              "      <td>2.49578</td>\n",
              "      <td>-3.02468</td>\n",
              "      <td>7.69273</td>\n",
              "      <td>1004.95615</td>\n",
              "      <td>785.06709</td>\n",
              "      <td>591.99232</td>\n",
              "      <td>495.75332</td>\n",
              "      <td>291.38165</td>\n",
              "      <td>434.08355</td>\n",
              "      <td>291.55265</td>\n",
              "      <td>303.58860</td>\n",
              "      <td>216.12189</td>\n",
              "      <td>126.10703</td>\n",
              "      <td>147.28090</td>\n",
              "      <td>6.17712</td>\n",
              "      <td>-133.67424</td>\n",
              "      <td>8.69259</td>\n",
              "      <td>-13.76138</td>\n",
              "      <td>-52.72072</td>\n",
              "      <td>-24.00961</td>\n",
              "      <td>-10.82297</td>\n",
              "      <td>11.42039</td>\n",
              "      <td>32.10442</td>\n",
              "      <td>-26.26130</td>\n",
              "      <td>-4.98856</td>\n",
              "      <td>20.84154</td>\n",
              "      <td>-129.69145</td>\n",
              "      <td>-157.91059</td>\n",
              "      <td>-43.29252</td>\n",
              "      <td>...</td>\n",
              "      <td>45.07251</td>\n",
              "      <td>-6.20682</td>\n",
              "      <td>17.53456</td>\n",
              "      <td>43.66313</td>\n",
              "      <td>-4.80024</td>\n",
              "      <td>-33.62226</td>\n",
              "      <td>-15.01731</td>\n",
              "      <td>-33.74416</td>\n",
              "      <td>2.12072</td>\n",
              "      <td>-46.83225</td>\n",
              "      <td>19.99596</td>\n",
              "      <td>26.31683</td>\n",
              "      <td>0.51657</td>\n",
              "      <td>-285.36622</td>\n",
              "      <td>-52.26245</td>\n",
              "      <td>-13.00341</td>\n",
              "      <td>-9.41185</td>\n",
              "      <td>69.69108</td>\n",
              "      <td>33.54907</td>\n",
              "      <td>-11.39665</td>\n",
              "      <td>93.61103</td>\n",
              "      <td>163.39892</td>\n",
              "      <td>5.00362</td>\n",
              "      <td>15.23807</td>\n",
              "      <td>-13.48394</td>\n",
              "      <td>-6.37431</td>\n",
              "      <td>-37.31287</td>\n",
              "      <td>92.47370</td>\n",
              "      <td>-90.00149</td>\n",
              "      <td>47.25143</td>\n",
              "      <td>6.59753</td>\n",
              "      <td>-50.69577</td>\n",
              "      <td>26.02574</td>\n",
              "      <td>18.94430</td>\n",
              "      <td>-0.33730</td>\n",
              "      <td>6.09352</td>\n",
              "      <td>35.18381</td>\n",
              "      <td>5.00283</td>\n",
              "      <td>-11.02257</td>\n",
              "      <td>0.02263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>50.57546</td>\n",
              "      <td>33.17843</td>\n",
              "      <td>50.53517</td>\n",
              "      <td>11.55217</td>\n",
              "      <td>-27.24764</td>\n",
              "      <td>-8.78206</td>\n",
              "      <td>-12.04282</td>\n",
              "      <td>-9.53930</td>\n",
              "      <td>28.61811</td>\n",
              "      <td>8.25435</td>\n",
              "      <td>-0.43743</td>\n",
              "      <td>5.66265</td>\n",
              "      <td>11.07787</td>\n",
              "      <td>1080.98902</td>\n",
              "      <td>1230.78393</td>\n",
              "      <td>1301.63542</td>\n",
              "      <td>952.84686</td>\n",
              "      <td>783.02498</td>\n",
              "      <td>560.79536</td>\n",
              "      <td>696.19620</td>\n",
              "      <td>253.36266</td>\n",
              "      <td>316.92697</td>\n",
              "      <td>151.75689</td>\n",
              "      <td>144.07059</td>\n",
              "      <td>-3.02894</td>\n",
              "      <td>-111.65251</td>\n",
              "      <td>-56.64580</td>\n",
              "      <td>464.86598</td>\n",
              "      <td>150.52166</td>\n",
              "      <td>84.69609</td>\n",
              "      <td>-91.71196</td>\n",
              "      <td>89.31272</td>\n",
              "      <td>16.49867</td>\n",
              "      <td>-4.47074</td>\n",
              "      <td>-2.02539</td>\n",
              "      <td>13.27637</td>\n",
              "      <td>-153.73456</td>\n",
              "      <td>199.01552</td>\n",
              "      <td>-278.79072</td>\n",
              "      <td>...</td>\n",
              "      <td>0.05909</td>\n",
              "      <td>-92.07551</td>\n",
              "      <td>7.80480</td>\n",
              "      <td>-46.15966</td>\n",
              "      <td>-39.03309</td>\n",
              "      <td>32.52065</td>\n",
              "      <td>164.15989</td>\n",
              "      <td>-247.22025</td>\n",
              "      <td>-100.28773</td>\n",
              "      <td>-55.58712</td>\n",
              "      <td>8.38343</td>\n",
              "      <td>-4.57294</td>\n",
              "      <td>-20.08525</td>\n",
              "      <td>-357.00069</td>\n",
              "      <td>-232.78978</td>\n",
              "      <td>-112.81679</td>\n",
              "      <td>-66.16128</td>\n",
              "      <td>43.25003</td>\n",
              "      <td>18.48417</td>\n",
              "      <td>-2.50274</td>\n",
              "      <td>3.25927</td>\n",
              "      <td>94.57509</td>\n",
              "      <td>-24.31254</td>\n",
              "      <td>62.97582</td>\n",
              "      <td>-19.41809</td>\n",
              "      <td>10.35282</td>\n",
              "      <td>-91.89392</td>\n",
              "      <td>10.51922</td>\n",
              "      <td>-74.98521</td>\n",
              "      <td>12.29948</td>\n",
              "      <td>11.63681</td>\n",
              "      <td>25.44182</td>\n",
              "      <td>134.62382</td>\n",
              "      <td>21.51982</td>\n",
              "      <td>8.17570</td>\n",
              "      <td>35.46251</td>\n",
              "      <td>11.57736</td>\n",
              "      <td>4.50056</td>\n",
              "      <td>-4.62739</td>\n",
              "      <td>1.40192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>48.26892</td>\n",
              "      <td>8.97526</td>\n",
              "      <td>75.23158</td>\n",
              "      <td>24.04945</td>\n",
              "      <td>-16.02105</td>\n",
              "      <td>-14.09491</td>\n",
              "      <td>8.11871</td>\n",
              "      <td>-1.87566</td>\n",
              "      <td>7.46701</td>\n",
              "      <td>1.18189</td>\n",
              "      <td>1.46625</td>\n",
              "      <td>-6.34226</td>\n",
              "      <td>8.40470</td>\n",
              "      <td>1619.74629</td>\n",
              "      <td>1762.43083</td>\n",
              "      <td>714.83843</td>\n",
              "      <td>1115.90792</td>\n",
              "      <td>525.85703</td>\n",
              "      <td>576.66300</td>\n",
              "      <td>350.41961</td>\n",
              "      <td>315.44672</td>\n",
              "      <td>267.94363</td>\n",
              "      <td>198.28158</td>\n",
              "      <td>201.97524</td>\n",
              "      <td>17.14701</td>\n",
              "      <td>-517.47978</td>\n",
              "      <td>-11.33396</td>\n",
              "      <td>59.52820</td>\n",
              "      <td>-25.10400</td>\n",
              "      <td>23.48782</td>\n",
              "      <td>12.63888</td>\n",
              "      <td>40.85580</td>\n",
              "      <td>-3.72243</td>\n",
              "      <td>-16.97392</td>\n",
              "      <td>0.04284</td>\n",
              "      <td>59.45956</td>\n",
              "      <td>-191.92216</td>\n",
              "      <td>445.36223</td>\n",
              "      <td>-120.62667</td>\n",
              "      <td>...</td>\n",
              "      <td>63.71442</td>\n",
              "      <td>3.70732</td>\n",
              "      <td>-9.36662</td>\n",
              "      <td>-25.75461</td>\n",
              "      <td>35.16677</td>\n",
              "      <td>-33.17382</td>\n",
              "      <td>13.80469</td>\n",
              "      <td>-107.14403</td>\n",
              "      <td>140.04250</td>\n",
              "      <td>-124.16153</td>\n",
              "      <td>-18.33032</td>\n",
              "      <td>-9.99397</td>\n",
              "      <td>8.96011</td>\n",
              "      <td>-411.27991</td>\n",
              "      <td>-99.75061</td>\n",
              "      <td>-75.51735</td>\n",
              "      <td>-88.57128</td>\n",
              "      <td>22.90222</td>\n",
              "      <td>4.14618</td>\n",
              "      <td>-16.83238</td>\n",
              "      <td>142.14168</td>\n",
              "      <td>326.91932</td>\n",
              "      <td>-3.49405</td>\n",
              "      <td>7.58991</td>\n",
              "      <td>-32.60725</td>\n",
              "      <td>-4.44469</td>\n",
              "      <td>-56.48952</td>\n",
              "      <td>-31.19491</td>\n",
              "      <td>-32.75384</td>\n",
              "      <td>-52.97111</td>\n",
              "      <td>18.03989</td>\n",
              "      <td>-58.46192</td>\n",
              "      <td>-65.56438</td>\n",
              "      <td>46.99856</td>\n",
              "      <td>-4.09602</td>\n",
              "      <td>56.37650</td>\n",
              "      <td>-18.29975</td>\n",
              "      <td>-0.30633</td>\n",
              "      <td>3.98364</td>\n",
              "      <td>-3.72556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>49.75468</td>\n",
              "      <td>33.99581</td>\n",
              "      <td>56.73846</td>\n",
              "      <td>2.89581</td>\n",
              "      <td>-2.92429</td>\n",
              "      <td>-26.44413</td>\n",
              "      <td>1.71392</td>\n",
              "      <td>-0.55644</td>\n",
              "      <td>22.08594</td>\n",
              "      <td>7.43847</td>\n",
              "      <td>-0.03578</td>\n",
              "      <td>1.66534</td>\n",
              "      <td>46.02060</td>\n",
              "      <td>789.58109</td>\n",
              "      <td>607.78514</td>\n",
              "      <td>248.54603</td>\n",
              "      <td>288.44004</td>\n",
              "      <td>330.16459</td>\n",
              "      <td>356.34405</td>\n",
              "      <td>194.21792</td>\n",
              "      <td>194.68297</td>\n",
              "      <td>158.43568</td>\n",
              "      <td>104.05610</td>\n",
              "      <td>183.10695</td>\n",
              "      <td>-39.54223</td>\n",
              "      <td>-225.39832</td>\n",
              "      <td>78.57149</td>\n",
              "      <td>20.62209</td>\n",
              "      <td>-9.44189</td>\n",
              "      <td>15.94754</td>\n",
              "      <td>51.24174</td>\n",
              "      <td>-4.36054</td>\n",
              "      <td>17.60516</td>\n",
              "      <td>9.03638</td>\n",
              "      <td>16.69044</td>\n",
              "      <td>42.70944</td>\n",
              "      <td>-77.62818</td>\n",
              "      <td>46.71905</td>\n",
              "      <td>-109.71028</td>\n",
              "      <td>...</td>\n",
              "      <td>36.17475</td>\n",
              "      <td>3.44547</td>\n",
              "      <td>46.40983</td>\n",
              "      <td>-21.52684</td>\n",
              "      <td>-10.50872</td>\n",
              "      <td>-8.62787</td>\n",
              "      <td>55.23069</td>\n",
              "      <td>-41.74452</td>\n",
              "      <td>-20.24522</td>\n",
              "      <td>21.78558</td>\n",
              "      <td>-8.69348</td>\n",
              "      <td>-1.85679</td>\n",
              "      <td>3.60117</td>\n",
              "      <td>-53.94252</td>\n",
              "      <td>-54.66970</td>\n",
              "      <td>-15.14957</td>\n",
              "      <td>-46.61675</td>\n",
              "      <td>48.45009</td>\n",
              "      <td>2.77737</td>\n",
              "      <td>-7.80854</td>\n",
              "      <td>38.29390</td>\n",
              "      <td>120.35575</td>\n",
              "      <td>23.84978</td>\n",
              "      <td>14.87696</td>\n",
              "      <td>-41.76961</td>\n",
              "      <td>-21.05519</td>\n",
              "      <td>-45.79645</td>\n",
              "      <td>9.16222</td>\n",
              "      <td>-21.48052</td>\n",
              "      <td>-9.70822</td>\n",
              "      <td>18.70812</td>\n",
              "      <td>5.20391</td>\n",
              "      <td>-27.75192</td>\n",
              "      <td>17.22100</td>\n",
              "      <td>-0.85210</td>\n",
              "      <td>-15.67150</td>\n",
              "      <td>-26.36257</td>\n",
              "      <td>5.48708</td>\n",
              "      <td>-9.13495</td>\n",
              "      <td>6.08680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>45.17809</td>\n",
              "      <td>46.34234</td>\n",
              "      <td>-40.65357</td>\n",
              "      <td>-2.47909</td>\n",
              "      <td>1.21253</td>\n",
              "      <td>-0.65302</td>\n",
              "      <td>-6.95536</td>\n",
              "      <td>-12.20040</td>\n",
              "      <td>17.02512</td>\n",
              "      <td>2.00002</td>\n",
              "      <td>-1.87785</td>\n",
              "      <td>9.85499</td>\n",
              "      <td>25.59837</td>\n",
              "      <td>1905.18577</td>\n",
              "      <td>3676.09074</td>\n",
              "      <td>1976.85531</td>\n",
              "      <td>913.11216</td>\n",
              "      <td>1957.52415</td>\n",
              "      <td>955.98525</td>\n",
              "      <td>942.72667</td>\n",
              "      <td>439.85991</td>\n",
              "      <td>591.66138</td>\n",
              "      <td>493.40770</td>\n",
              "      <td>496.38516</td>\n",
              "      <td>33.94285</td>\n",
              "      <td>-255.90134</td>\n",
              "      <td>-762.28079</td>\n",
              "      <td>-66.10935</td>\n",
              "      <td>-128.02217</td>\n",
              "      <td>198.12908</td>\n",
              "      <td>-34.44957</td>\n",
              "      <td>176.00397</td>\n",
              "      <td>-140.80069</td>\n",
              "      <td>-22.56380</td>\n",
              "      <td>12.77945</td>\n",
              "      <td>193.30164</td>\n",
              "      <td>314.20949</td>\n",
              "      <td>576.29519</td>\n",
              "      <td>-429.58643</td>\n",
              "      <td>...</td>\n",
              "      <td>-17.48938</td>\n",
              "      <td>75.58779</td>\n",
              "      <td>93.29243</td>\n",
              "      <td>85.83507</td>\n",
              "      <td>47.13972</td>\n",
              "      <td>312.85482</td>\n",
              "      <td>135.50478</td>\n",
              "      <td>-32.47886</td>\n",
              "      <td>49.67063</td>\n",
              "      <td>-214.73180</td>\n",
              "      <td>-77.83503</td>\n",
              "      <td>-47.26902</td>\n",
              "      <td>7.58366</td>\n",
              "      <td>-352.56581</td>\n",
              "      <td>-36.15655</td>\n",
              "      <td>-53.39933</td>\n",
              "      <td>-98.60417</td>\n",
              "      <td>-82.37799</td>\n",
              "      <td>45.81588</td>\n",
              "      <td>-16.91676</td>\n",
              "      <td>18.35888</td>\n",
              "      <td>-315.68965</td>\n",
              "      <td>-3.14554</td>\n",
              "      <td>125.45269</td>\n",
              "      <td>-130.18808</td>\n",
              "      <td>-3.06337</td>\n",
              "      <td>42.26602</td>\n",
              "      <td>-9.04929</td>\n",
              "      <td>26.41570</td>\n",
              "      <td>23.36165</td>\n",
              "      <td>-4.36742</td>\n",
              "      <td>-87.55285</td>\n",
              "      <td>-70.79677</td>\n",
              "      <td>76.57355</td>\n",
              "      <td>-7.71727</td>\n",
              "      <td>3.26926</td>\n",
              "      <td>-298.49845</td>\n",
              "      <td>11.49326</td>\n",
              "      <td>-89.21804</td>\n",
              "      <td>-15.09719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>39.13076</td>\n",
              "      <td>-23.01763</td>\n",
              "      <td>-36.20583</td>\n",
              "      <td>1.67519</td>\n",
              "      <td>-4.27101</td>\n",
              "      <td>13.01158</td>\n",
              "      <td>8.05718</td>\n",
              "      <td>-8.41088</td>\n",
              "      <td>6.27370</td>\n",
              "      <td>-7.81564</td>\n",
              "      <td>-12.29472</td>\n",
              "      <td>-12.26186</td>\n",
              "      <td>45.05025</td>\n",
              "      <td>2022.36720</td>\n",
              "      <td>3860.79421</td>\n",
              "      <td>3186.91395</td>\n",
              "      <td>849.65196</td>\n",
              "      <td>2835.16969</td>\n",
              "      <td>847.01876</td>\n",
              "      <td>1001.27685</td>\n",
              "      <td>347.33791</td>\n",
              "      <td>500.59470</td>\n",
              "      <td>536.16777</td>\n",
              "      <td>318.73821</td>\n",
              "      <td>50.13600</td>\n",
              "      <td>451.14001</td>\n",
              "      <td>-589.91962</td>\n",
              "      <td>-95.42003</td>\n",
              "      <td>-99.51192</td>\n",
              "      <td>-28.43500</td>\n",
              "      <td>22.34786</td>\n",
              "      <td>132.68163</td>\n",
              "      <td>-111.84550</td>\n",
              "      <td>106.94141</td>\n",
              "      <td>-9.94676</td>\n",
              "      <td>269.57001</td>\n",
              "      <td>416.04429</td>\n",
              "      <td>3.08594</td>\n",
              "      <td>-312.96128</td>\n",
              "      <td>...</td>\n",
              "      <td>364.86126</td>\n",
              "      <td>4.89096</td>\n",
              "      <td>-110.07105</td>\n",
              "      <td>19.43169</td>\n",
              "      <td>-13.69554</td>\n",
              "      <td>464.30985</td>\n",
              "      <td>203.55456</td>\n",
              "      <td>-450.84974</td>\n",
              "      <td>9.54696</td>\n",
              "      <td>-433.98556</td>\n",
              "      <td>40.33083</td>\n",
              "      <td>60.29120</td>\n",
              "      <td>66.28236</td>\n",
              "      <td>-398.01020</td>\n",
              "      <td>582.88308</td>\n",
              "      <td>-93.75781</td>\n",
              "      <td>-31.61288</td>\n",
              "      <td>-311.99559</td>\n",
              "      <td>106.91372</td>\n",
              "      <td>-8.56906</td>\n",
              "      <td>-42.26640</td>\n",
              "      <td>269.83186</td>\n",
              "      <td>10.39815</td>\n",
              "      <td>-14.56199</td>\n",
              "      <td>36.15556</td>\n",
              "      <td>51.77120</td>\n",
              "      <td>23.70949</td>\n",
              "      <td>-15.79585</td>\n",
              "      <td>216.13271</td>\n",
              "      <td>100.04021</td>\n",
              "      <td>32.86051</td>\n",
              "      <td>-26.08461</td>\n",
              "      <td>-186.82429</td>\n",
              "      <td>113.58176</td>\n",
              "      <td>9.28727</td>\n",
              "      <td>44.60282</td>\n",
              "      <td>158.00425</td>\n",
              "      <td>-2.59543</td>\n",
              "      <td>109.19723</td>\n",
              "      <td>23.36143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>37.66498</td>\n",
              "      <td>-34.05910</td>\n",
              "      <td>-17.36060</td>\n",
              "      <td>-26.77781</td>\n",
              "      <td>-39.95119</td>\n",
              "      <td>-20.75000</td>\n",
              "      <td>-0.10231</td>\n",
              "      <td>-0.89972</td>\n",
              "      <td>-1.30205</td>\n",
              "      <td>-0.93041</td>\n",
              "      <td>-3.30157</td>\n",
              "      <td>-2.37522</td>\n",
              "      <td>35.42988</td>\n",
              "      <td>1166.91594</td>\n",
              "      <td>1373.01959</td>\n",
              "      <td>409.04286</td>\n",
              "      <td>609.84543</td>\n",
              "      <td>271.33121</td>\n",
              "      <td>392.43089</td>\n",
              "      <td>180.98525</td>\n",
              "      <td>215.37174</td>\n",
              "      <td>137.27208</td>\n",
              "      <td>69.71585</td>\n",
              "      <td>187.80590</td>\n",
              "      <td>-12.67805</td>\n",
              "      <td>-347.02236</td>\n",
              "      <td>271.33219</td>\n",
              "      <td>40.08570</td>\n",
              "      <td>42.13962</td>\n",
              "      <td>10.70729</td>\n",
              "      <td>36.75105</td>\n",
              "      <td>6.28685</td>\n",
              "      <td>3.24624</td>\n",
              "      <td>-3.85517</td>\n",
              "      <td>10.67336</td>\n",
              "      <td>-9.47190</td>\n",
              "      <td>-62.45325</td>\n",
              "      <td>212.55872</td>\n",
              "      <td>-33.45944</td>\n",
              "      <td>...</td>\n",
              "      <td>14.26269</td>\n",
              "      <td>12.13975</td>\n",
              "      <td>17.85889</td>\n",
              "      <td>16.82677</td>\n",
              "      <td>-73.67298</td>\n",
              "      <td>30.33815</td>\n",
              "      <td>-101.70001</td>\n",
              "      <td>-46.13208</td>\n",
              "      <td>14.26704</td>\n",
              "      <td>4.31515</td>\n",
              "      <td>-25.67264</td>\n",
              "      <td>8.70269</td>\n",
              "      <td>11.69122</td>\n",
              "      <td>-59.19425</td>\n",
              "      <td>-43.59348</td>\n",
              "      <td>-81.06458</td>\n",
              "      <td>-8.27943</td>\n",
              "      <td>-16.76813</td>\n",
              "      <td>0.83299</td>\n",
              "      <td>47.83962</td>\n",
              "      <td>-50.41094</td>\n",
              "      <td>-146.83861</td>\n",
              "      <td>37.05135</td>\n",
              "      <td>9.58587</td>\n",
              "      <td>11.61329</td>\n",
              "      <td>-11.13671</td>\n",
              "      <td>86.66011</td>\n",
              "      <td>-21.11909</td>\n",
              "      <td>-4.36777</td>\n",
              "      <td>44.53390</td>\n",
              "      <td>11.18909</td>\n",
              "      <td>45.20614</td>\n",
              "      <td>53.83925</td>\n",
              "      <td>2.59467</td>\n",
              "      <td>-4.00958</td>\n",
              "      <td>-47.74886</td>\n",
              "      <td>-170.92864</td>\n",
              "      <td>-5.19009</td>\n",
              "      <td>8.83617</td>\n",
              "      <td>-7.16056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>26.51957</td>\n",
              "      <td>-148.15762</td>\n",
              "      <td>-13.30095</td>\n",
              "      <td>-7.25851</td>\n",
              "      <td>17.22029</td>\n",
              "      <td>-21.99439</td>\n",
              "      <td>5.51947</td>\n",
              "      <td>3.48418</td>\n",
              "      <td>2.61738</td>\n",
              "      <td>2.51194</td>\n",
              "      <td>-0.53980</td>\n",
              "      <td>4.94747</td>\n",
              "      <td>55.79019</td>\n",
              "      <td>5492.46406</td>\n",
              "      <td>1704.58482</td>\n",
              "      <td>953.13106</td>\n",
              "      <td>959.38535</td>\n",
              "      <td>788.92858</td>\n",
              "      <td>365.45762</td>\n",
              "      <td>270.37477</td>\n",
              "      <td>524.61443</td>\n",
              "      <td>194.81728</td>\n",
              "      <td>139.44778</td>\n",
              "      <td>375.02904</td>\n",
              "      <td>-434.18365</td>\n",
              "      <td>-627.01684</td>\n",
              "      <td>642.48227</td>\n",
              "      <td>-440.32465</td>\n",
              "      <td>-319.81435</td>\n",
              "      <td>10.13236</td>\n",
              "      <td>38.64956</td>\n",
              "      <td>-30.14092</td>\n",
              "      <td>75.22352</td>\n",
              "      <td>-48.15860</td>\n",
              "      <td>80.88233</td>\n",
              "      <td>183.14023</td>\n",
              "      <td>-178.08073</td>\n",
              "      <td>-594.06429</td>\n",
              "      <td>185.11781</td>\n",
              "      <td>...</td>\n",
              "      <td>137.58951</td>\n",
              "      <td>38.38606</td>\n",
              "      <td>-3.31309</td>\n",
              "      <td>5.48498</td>\n",
              "      <td>-128.84776</td>\n",
              "      <td>-303.86613</td>\n",
              "      <td>188.82297</td>\n",
              "      <td>-108.38722</td>\n",
              "      <td>-69.68996</td>\n",
              "      <td>84.70685</td>\n",
              "      <td>-54.19731</td>\n",
              "      <td>-112.09276</td>\n",
              "      <td>85.47803</td>\n",
              "      <td>38.20818</td>\n",
              "      <td>-277.12066</td>\n",
              "      <td>132.27890</td>\n",
              "      <td>91.74732</td>\n",
              "      <td>-11.84666</td>\n",
              "      <td>-28.23002</td>\n",
              "      <td>-21.30369</td>\n",
              "      <td>205.87882</td>\n",
              "      <td>-22.13147</td>\n",
              "      <td>-52.71243</td>\n",
              "      <td>-122.98466</td>\n",
              "      <td>-0.77068</td>\n",
              "      <td>-56.79478</td>\n",
              "      <td>91.28164</td>\n",
              "      <td>-2.31187</td>\n",
              "      <td>49.34151</td>\n",
              "      <td>-243.95844</td>\n",
              "      <td>23.80442</td>\n",
              "      <td>251.76360</td>\n",
              "      <td>18.81642</td>\n",
              "      <td>157.09656</td>\n",
              "      <td>-27.79449</td>\n",
              "      <td>-137.72740</td>\n",
              "      <td>115.28414</td>\n",
              "      <td>23.00230</td>\n",
              "      <td>-164.02536</td>\n",
              "      <td>51.54138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>37.68491</td>\n",
              "      <td>-26.84185</td>\n",
              "      <td>-27.10566</td>\n",
              "      <td>-14.95883</td>\n",
              "      <td>-5.87200</td>\n",
              "      <td>-21.68979</td>\n",
              "      <td>4.87374</td>\n",
              "      <td>-18.01800</td>\n",
              "      <td>1.52141</td>\n",
              "      <td>-6.81668</td>\n",
              "      <td>6.80117</td>\n",
              "      <td>21.17530</td>\n",
              "      <td>50.35368</td>\n",
              "      <td>6431.63159</td>\n",
              "      <td>3755.88724</td>\n",
              "      <td>850.19745</td>\n",
              "      <td>2540.53952</td>\n",
              "      <td>400.64901</td>\n",
              "      <td>614.21009</td>\n",
              "      <td>324.55934</td>\n",
              "      <td>395.25844</td>\n",
              "      <td>241.66513</td>\n",
              "      <td>99.66852</td>\n",
              "      <td>489.65963</td>\n",
              "      <td>-466.60181</td>\n",
              "      <td>4015.57689</td>\n",
              "      <td>1042.51072</td>\n",
              "      <td>787.79078</td>\n",
              "      <td>-240.53556</td>\n",
              "      <td>-82.21473</td>\n",
              "      <td>92.62933</td>\n",
              "      <td>25.79866</td>\n",
              "      <td>47.82510</td>\n",
              "      <td>-24.31114</td>\n",
              "      <td>39.59818</td>\n",
              "      <td>-318.96984</td>\n",
              "      <td>1174.17699</td>\n",
              "      <td>2574.00913</td>\n",
              "      <td>-116.86438</td>\n",
              "      <td>...</td>\n",
              "      <td>-10.44655</td>\n",
              "      <td>-86.37776</td>\n",
              "      <td>-2.66989</td>\n",
              "      <td>-150.73054</td>\n",
              "      <td>-309.01020</td>\n",
              "      <td>-263.88605</td>\n",
              "      <td>-511.63129</td>\n",
              "      <td>-331.45866</td>\n",
              "      <td>524.10757</td>\n",
              "      <td>-103.81583</td>\n",
              "      <td>-11.11616</td>\n",
              "      <td>146.64710</td>\n",
              "      <td>47.03819</td>\n",
              "      <td>-555.49233</td>\n",
              "      <td>-312.62275</td>\n",
              "      <td>17.44093</td>\n",
              "      <td>114.07544</td>\n",
              "      <td>30.33500</td>\n",
              "      <td>233.32721</td>\n",
              "      <td>36.70535</td>\n",
              "      <td>-449.22124</td>\n",
              "      <td>507.86020</td>\n",
              "      <td>179.49985</td>\n",
              "      <td>-62.12860</td>\n",
              "      <td>20.81610</td>\n",
              "      <td>37.22555</td>\n",
              "      <td>821.44873</td>\n",
              "      <td>179.59958</td>\n",
              "      <td>-37.21579</td>\n",
              "      <td>-632.61945</td>\n",
              "      <td>-67.57637</td>\n",
              "      <td>234.27192</td>\n",
              "      <td>-72.34557</td>\n",
              "      <td>-362.25101</td>\n",
              "      <td>-25.55019</td>\n",
              "      <td>-89.08971</td>\n",
              "      <td>-891.58937</td>\n",
              "      <td>14.11648</td>\n",
              "      <td>-1030.99180</td>\n",
              "      <td>99.28967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>39.11695</td>\n",
              "      <td>-8.29767</td>\n",
              "      <td>-51.37966</td>\n",
              "      <td>-4.42668</td>\n",
              "      <td>-30.06506</td>\n",
              "      <td>-11.95916</td>\n",
              "      <td>-0.85322</td>\n",
              "      <td>-8.86179</td>\n",
              "      <td>11.36680</td>\n",
              "      <td>3.78199</td>\n",
              "      <td>1.54568</td>\n",
              "      <td>0.58662</td>\n",
              "      <td>28.49070</td>\n",
              "      <td>7965.81458</td>\n",
              "      <td>1411.06042</td>\n",
              "      <td>1218.84885</td>\n",
              "      <td>645.93064</td>\n",
              "      <td>1138.49365</td>\n",
              "      <td>552.35786</td>\n",
              "      <td>652.69173</td>\n",
              "      <td>281.26048</td>\n",
              "      <td>396.15845</td>\n",
              "      <td>231.01221</td>\n",
              "      <td>215.80169</td>\n",
              "      <td>345.50690</td>\n",
              "      <td>-1163.24259</td>\n",
              "      <td>-117.88194</td>\n",
              "      <td>162.42114</td>\n",
              "      <td>339.56477</td>\n",
              "      <td>32.54661</td>\n",
              "      <td>-78.76608</td>\n",
              "      <td>9.22956</td>\n",
              "      <td>-7.94960</td>\n",
              "      <td>-15.24124</td>\n",
              "      <td>29.36270</td>\n",
              "      <td>-19.91118</td>\n",
              "      <td>530.29303</td>\n",
              "      <td>284.81573</td>\n",
              "      <td>2.50910</td>\n",
              "      <td>...</td>\n",
              "      <td>50.89571</td>\n",
              "      <td>18.59393</td>\n",
              "      <td>53.83297</td>\n",
              "      <td>-89.69260</td>\n",
              "      <td>-31.45442</td>\n",
              "      <td>188.56576</td>\n",
              "      <td>70.85815</td>\n",
              "      <td>-259.86825</td>\n",
              "      <td>65.62430</td>\n",
              "      <td>-208.96960</td>\n",
              "      <td>-50.55450</td>\n",
              "      <td>1.06368</td>\n",
              "      <td>0.31427</td>\n",
              "      <td>396.93348</td>\n",
              "      <td>105.80580</td>\n",
              "      <td>72.06757</td>\n",
              "      <td>-160.48858</td>\n",
              "      <td>-97.33616</td>\n",
              "      <td>-69.36746</td>\n",
              "      <td>37.07706</td>\n",
              "      <td>-113.27781</td>\n",
              "      <td>-95.78902</td>\n",
              "      <td>155.13377</td>\n",
              "      <td>-22.10761</td>\n",
              "      <td>-1.08949</td>\n",
              "      <td>13.36146</td>\n",
              "      <td>833.00787</td>\n",
              "      <td>-88.78803</td>\n",
              "      <td>30.70543</td>\n",
              "      <td>-63.16836</td>\n",
              "      <td>42.22923</td>\n",
              "      <td>478.26580</td>\n",
              "      <td>-10.33823</td>\n",
              "      <td>-103.76858</td>\n",
              "      <td>39.19511</td>\n",
              "      <td>-98.76636</td>\n",
              "      <td>-122.81061</td>\n",
              "      <td>-2.14942</td>\n",
              "      <td>-211.48202</td>\n",
              "      <td>-12.81569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>35.05129</td>\n",
              "      <td>-67.97714</td>\n",
              "      <td>-14.20239</td>\n",
              "      <td>-6.68696</td>\n",
              "      <td>-0.61230</td>\n",
              "      <td>-18.70341</td>\n",
              "      <td>-1.31928</td>\n",
              "      <td>-9.46370</td>\n",
              "      <td>5.53492</td>\n",
              "      <td>2.79989</td>\n",
              "      <td>3.34150</td>\n",
              "      <td>18.01445</td>\n",
              "      <td>48.14418</td>\n",
              "      <td>1938.39116</td>\n",
              "      <td>755.44238</td>\n",
              "      <td>1350.57299</td>\n",
              "      <td>793.09536</td>\n",
              "      <td>793.43819</td>\n",
              "      <td>585.72478</td>\n",
              "      <td>280.00734</td>\n",
              "      <td>260.63960</td>\n",
              "      <td>168.98085</td>\n",
              "      <td>148.49783</td>\n",
              "      <td>539.22389</td>\n",
              "      <td>-99.68273</td>\n",
              "      <td>198.55553</td>\n",
              "      <td>332.84941</td>\n",
              "      <td>-139.15915</td>\n",
              "      <td>-166.48695</td>\n",
              "      <td>-186.65004</td>\n",
              "      <td>143.44962</td>\n",
              "      <td>-22.08680</td>\n",
              "      <td>37.34160</td>\n",
              "      <td>-30.72572</td>\n",
              "      <td>64.79269</td>\n",
              "      <td>57.94387</td>\n",
              "      <td>332.16642</td>\n",
              "      <td>77.96230</td>\n",
              "      <td>312.90695</td>\n",
              "      <td>...</td>\n",
              "      <td>52.35627</td>\n",
              "      <td>13.93583</td>\n",
              "      <td>-2.03342</td>\n",
              "      <td>-107.12775</td>\n",
              "      <td>-6.42999</td>\n",
              "      <td>215.24319</td>\n",
              "      <td>122.33200</td>\n",
              "      <td>-183.75334</td>\n",
              "      <td>89.84912</td>\n",
              "      <td>3.34699</td>\n",
              "      <td>-33.62856</td>\n",
              "      <td>38.22842</td>\n",
              "      <td>77.13977</td>\n",
              "      <td>150.36511</td>\n",
              "      <td>-56.21045</td>\n",
              "      <td>34.03026</td>\n",
              "      <td>-34.86760</td>\n",
              "      <td>60.25658</td>\n",
              "      <td>2.52359</td>\n",
              "      <td>-56.10479</td>\n",
              "      <td>-21.25331</td>\n",
              "      <td>77.13640</td>\n",
              "      <td>134.26121</td>\n",
              "      <td>26.21428</td>\n",
              "      <td>-152.23191</td>\n",
              "      <td>-52.85864</td>\n",
              "      <td>-101.18125</td>\n",
              "      <td>55.52082</td>\n",
              "      <td>-64.97701</td>\n",
              "      <td>227.31886</td>\n",
              "      <td>10.25585</td>\n",
              "      <td>94.90539</td>\n",
              "      <td>15.95689</td>\n",
              "      <td>-98.15732</td>\n",
              "      <td>-9.64859</td>\n",
              "      <td>-93.52834</td>\n",
              "      <td>-95.82981</td>\n",
              "      <td>20.73063</td>\n",
              "      <td>-562.07671</td>\n",
              "      <td>43.44696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>33.63129</td>\n",
              "      <td>-96.14912</td>\n",
              "      <td>-89.38216</td>\n",
              "      <td>-12.11699</td>\n",
              "      <td>13.77252</td>\n",
              "      <td>-6.69377</td>\n",
              "      <td>-33.36843</td>\n",
              "      <td>-24.81437</td>\n",
              "      <td>21.22757</td>\n",
              "      <td>0.26310</td>\n",
              "      <td>0.42982</td>\n",
              "      <td>-6.59226</td>\n",
              "      <td>27.25596</td>\n",
              "      <td>2407.95516</td>\n",
              "      <td>1257.41135</td>\n",
              "      <td>795.17898</td>\n",
              "      <td>645.83254</td>\n",
              "      <td>1014.07214</td>\n",
              "      <td>474.67866</td>\n",
              "      <td>697.26135</td>\n",
              "      <td>334.85298</td>\n",
              "      <td>358.30744</td>\n",
              "      <td>324.45833</td>\n",
              "      <td>165.58489</td>\n",
              "      <td>-8.08451</td>\n",
              "      <td>101.52431</td>\n",
              "      <td>39.60959</td>\n",
              "      <td>7.06185</td>\n",
              "      <td>-78.21043</td>\n",
              "      <td>88.00470</td>\n",
              "      <td>129.65276</td>\n",
              "      <td>50.90538</td>\n",
              "      <td>-21.26991</td>\n",
              "      <td>32.76996</td>\n",
              "      <td>-29.96947</td>\n",
              "      <td>48.47300</td>\n",
              "      <td>441.40686</td>\n",
              "      <td>454.01182</td>\n",
              "      <td>95.66968</td>\n",
              "      <td>...</td>\n",
              "      <td>55.84917</td>\n",
              "      <td>92.63264</td>\n",
              "      <td>30.35791</td>\n",
              "      <td>-79.20043</td>\n",
              "      <td>-7.46621</td>\n",
              "      <td>602.37381</td>\n",
              "      <td>188.96249</td>\n",
              "      <td>-98.71438</td>\n",
              "      <td>176.37440</td>\n",
              "      <td>-248.00977</td>\n",
              "      <td>44.62138</td>\n",
              "      <td>24.37125</td>\n",
              "      <td>30.40357</td>\n",
              "      <td>79.40089</td>\n",
              "      <td>230.05627</td>\n",
              "      <td>-2.13554</td>\n",
              "      <td>30.01898</td>\n",
              "      <td>-41.89611</td>\n",
              "      <td>-1.77960</td>\n",
              "      <td>46.71421</td>\n",
              "      <td>149.76135</td>\n",
              "      <td>177.92434</td>\n",
              "      <td>-8.49394</td>\n",
              "      <td>47.67341</td>\n",
              "      <td>85.99877</td>\n",
              "      <td>6.63650</td>\n",
              "      <td>-213.70857</td>\n",
              "      <td>90.57614</td>\n",
              "      <td>-15.13552</td>\n",
              "      <td>-99.22940</td>\n",
              "      <td>49.93249</td>\n",
              "      <td>-14.47489</td>\n",
              "      <td>40.70590</td>\n",
              "      <td>58.63692</td>\n",
              "      <td>8.81522</td>\n",
              "      <td>27.28474</td>\n",
              "      <td>5.78046</td>\n",
              "      <td>3.44539</td>\n",
              "      <td>259.10825</td>\n",
              "      <td>10.28525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>41.38639</td>\n",
              "      <td>-20.78665</td>\n",
              "      <td>51.80155</td>\n",
              "      <td>17.21415</td>\n",
              "      <td>-36.44189</td>\n",
              "      <td>-11.53169</td>\n",
              "      <td>11.75252</td>\n",
              "      <td>-7.62428</td>\n",
              "      <td>-3.65488</td>\n",
              "      <td>-5.08109</td>\n",
              "      <td>4.37624</td>\n",
              "      <td>-1.39493</td>\n",
              "      <td>18.28400</td>\n",
              "      <td>3157.88796</td>\n",
              "      <td>1116.07117</td>\n",
              "      <td>913.19211</td>\n",
              "      <td>638.12946</td>\n",
              "      <td>535.61444</td>\n",
              "      <td>440.68379</td>\n",
              "      <td>435.75048</td>\n",
              "      <td>545.13836</td>\n",
              "      <td>286.93019</td>\n",
              "      <td>154.24744</td>\n",
              "      <td>278.14609</td>\n",
              "      <td>168.02465</td>\n",
              "      <td>-392.26915</td>\n",
              "      <td>-109.59025</td>\n",
              "      <td>-243.33016</td>\n",
              "      <td>57.76966</td>\n",
              "      <td>7.51054</td>\n",
              "      <td>84.23430</td>\n",
              "      <td>-67.00385</td>\n",
              "      <td>80.72070</td>\n",
              "      <td>-0.00321</td>\n",
              "      <td>2.12590</td>\n",
              "      <td>41.51370</td>\n",
              "      <td>-389.17834</td>\n",
              "      <td>-421.90682</td>\n",
              "      <td>-294.54854</td>\n",
              "      <td>...</td>\n",
              "      <td>127.18184</td>\n",
              "      <td>-106.70486</td>\n",
              "      <td>-18.10968</td>\n",
              "      <td>19.19753</td>\n",
              "      <td>-2.79115</td>\n",
              "      <td>31.93573</td>\n",
              "      <td>10.40156</td>\n",
              "      <td>-226.50662</td>\n",
              "      <td>-2.38144</td>\n",
              "      <td>-157.93284</td>\n",
              "      <td>0.46577</td>\n",
              "      <td>27.78523</td>\n",
              "      <td>6.41002</td>\n",
              "      <td>-173.66782</td>\n",
              "      <td>29.73562</td>\n",
              "      <td>-44.29195</td>\n",
              "      <td>-81.53220</td>\n",
              "      <td>50.49506</td>\n",
              "      <td>65.00208</td>\n",
              "      <td>-17.76363</td>\n",
              "      <td>-37.10280</td>\n",
              "      <td>264.10009</td>\n",
              "      <td>100.74257</td>\n",
              "      <td>-57.74383</td>\n",
              "      <td>-22.25492</td>\n",
              "      <td>-17.44555</td>\n",
              "      <td>335.82434</td>\n",
              "      <td>80.63635</td>\n",
              "      <td>-37.20103</td>\n",
              "      <td>7.30588</td>\n",
              "      <td>50.37614</td>\n",
              "      <td>-40.48205</td>\n",
              "      <td>48.07805</td>\n",
              "      <td>-7.62399</td>\n",
              "      <td>6.51934</td>\n",
              "      <td>-30.46090</td>\n",
              "      <td>-53.87264</td>\n",
              "      <td>4.44627</td>\n",
              "      <td>58.16913</td>\n",
              "      <td>-0.02409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>37.45034</td>\n",
              "      <td>11.42615</td>\n",
              "      <td>56.28982</td>\n",
              "      <td>19.58426</td>\n",
              "      <td>-16.43530</td>\n",
              "      <td>2.22457</td>\n",
              "      <td>1.02668</td>\n",
              "      <td>-7.34736</td>\n",
              "      <td>-0.01184</td>\n",
              "      <td>1.24013</td>\n",
              "      <td>2.57660</td>\n",
              "      <td>2.79598</td>\n",
              "      <td>30.02393</td>\n",
              "      <td>1249.33039</td>\n",
              "      <td>3438.98500</td>\n",
              "      <td>962.85885</td>\n",
              "      <td>1654.99981</td>\n",
              "      <td>1066.80390</td>\n",
              "      <td>606.24732</td>\n",
              "      <td>278.63327</td>\n",
              "      <td>273.36684</td>\n",
              "      <td>250.97765</td>\n",
              "      <td>257.04632</td>\n",
              "      <td>294.90282</td>\n",
              "      <td>41.74146</td>\n",
              "      <td>-455.47604</td>\n",
              "      <td>473.68747</td>\n",
              "      <td>-72.16130</td>\n",
              "      <td>409.83317</td>\n",
              "      <td>111.23583</td>\n",
              "      <td>98.74929</td>\n",
              "      <td>19.15393</td>\n",
              "      <td>-38.69791</td>\n",
              "      <td>-20.10176</td>\n",
              "      <td>57.44465</td>\n",
              "      <td>-127.58760</td>\n",
              "      <td>-189.37100</td>\n",
              "      <td>1126.01208</td>\n",
              "      <td>-98.48301</td>\n",
              "      <td>...</td>\n",
              "      <td>55.86703</td>\n",
              "      <td>-15.58939</td>\n",
              "      <td>-40.62299</td>\n",
              "      <td>-45.18282</td>\n",
              "      <td>-85.17021</td>\n",
              "      <td>180.09138</td>\n",
              "      <td>491.26688</td>\n",
              "      <td>6.42139</td>\n",
              "      <td>263.30124</td>\n",
              "      <td>-152.86190</td>\n",
              "      <td>-16.74493</td>\n",
              "      <td>-33.13223</td>\n",
              "      <td>-10.64964</td>\n",
              "      <td>-367.08218</td>\n",
              "      <td>49.57986</td>\n",
              "      <td>17.60102</td>\n",
              "      <td>-112.39761</td>\n",
              "      <td>79.62965</td>\n",
              "      <td>-92.92839</td>\n",
              "      <td>-49.77861</td>\n",
              "      <td>-53.65950</td>\n",
              "      <td>184.29601</td>\n",
              "      <td>-37.85258</td>\n",
              "      <td>-218.50833</td>\n",
              "      <td>-37.55140</td>\n",
              "      <td>-17.84213</td>\n",
              "      <td>-59.35940</td>\n",
              "      <td>-168.74190</td>\n",
              "      <td>-48.89748</td>\n",
              "      <td>-99.69609</td>\n",
              "      <td>-22.46207</td>\n",
              "      <td>-25.77228</td>\n",
              "      <td>-322.42841</td>\n",
              "      <td>-146.57408</td>\n",
              "      <td>13.61588</td>\n",
              "      <td>92.22918</td>\n",
              "      <td>-439.80259</td>\n",
              "      <td>25.73235</td>\n",
              "      <td>157.22967</td>\n",
              "      <td>38.70617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>39.71092</td>\n",
              "      <td>-4.92800</td>\n",
              "      <td>12.88590</td>\n",
              "      <td>-11.87773</td>\n",
              "      <td>2.48031</td>\n",
              "      <td>-16.11028</td>\n",
              "      <td>-16.40421</td>\n",
              "      <td>-8.29657</td>\n",
              "      <td>9.86817</td>\n",
              "      <td>-0.17431</td>\n",
              "      <td>0.98765</td>\n",
              "      <td>7.37903</td>\n",
              "      <td>13.84987</td>\n",
              "      <td>1256.34345</td>\n",
              "      <td>800.61127</td>\n",
              "      <td>715.08117</td>\n",
              "      <td>632.19829</td>\n",
              "      <td>357.08486</td>\n",
              "      <td>218.48245</td>\n",
              "      <td>278.90104</td>\n",
              "      <td>229.11644</td>\n",
              "      <td>228.51202</td>\n",
              "      <td>87.35304</td>\n",
              "      <td>144.36923</td>\n",
              "      <td>34.96307</td>\n",
              "      <td>-123.85672</td>\n",
              "      <td>-10.33970</td>\n",
              "      <td>-171.19156</td>\n",
              "      <td>-89.00293</td>\n",
              "      <td>39.72671</td>\n",
              "      <td>-17.78437</td>\n",
              "      <td>4.56124</td>\n",
              "      <td>17.07687</td>\n",
              "      <td>-20.75794</td>\n",
              "      <td>16.49367</td>\n",
              "      <td>63.67926</td>\n",
              "      <td>-113.39747</td>\n",
              "      <td>12.27230</td>\n",
              "      <td>-188.87545</td>\n",
              "      <td>...</td>\n",
              "      <td>-15.69508</td>\n",
              "      <td>1.68706</td>\n",
              "      <td>17.69997</td>\n",
              "      <td>-3.35888</td>\n",
              "      <td>4.21699</td>\n",
              "      <td>25.45729</td>\n",
              "      <td>147.84361</td>\n",
              "      <td>-69.50808</td>\n",
              "      <td>81.47487</td>\n",
              "      <td>-91.89773</td>\n",
              "      <td>9.59723</td>\n",
              "      <td>2.52910</td>\n",
              "      <td>-9.48278</td>\n",
              "      <td>-81.54172</td>\n",
              "      <td>-30.46621</td>\n",
              "      <td>8.10179</td>\n",
              "      <td>9.51480</td>\n",
              "      <td>25.88937</td>\n",
              "      <td>28.29212</td>\n",
              "      <td>5.73829</td>\n",
              "      <td>158.30039</td>\n",
              "      <td>96.20428</td>\n",
              "      <td>55.04618</td>\n",
              "      <td>18.25457</td>\n",
              "      <td>-18.37851</td>\n",
              "      <td>1.06499</td>\n",
              "      <td>-76.40237</td>\n",
              "      <td>111.81246</td>\n",
              "      <td>-57.71450</td>\n",
              "      <td>29.55411</td>\n",
              "      <td>11.92816</td>\n",
              "      <td>-73.72412</td>\n",
              "      <td>16.19039</td>\n",
              "      <td>9.79606</td>\n",
              "      <td>9.71693</td>\n",
              "      <td>-9.90907</td>\n",
              "      <td>-20.65851</td>\n",
              "      <td>2.34002</td>\n",
              "      <td>-31.57015</td>\n",
              "      <td>1.58400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows Ã— 91 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    year      var1       var2  ...     var88       var89     var90\n",
              "0      1  49.94357   21.47114  ...  -1.82223   -27.46348   2.26327\n",
              "1      1  48.73215   18.42930  ...  12.04941    58.43453  26.92061\n",
              "2      1  50.95714   31.85602  ...  -0.05859    39.67068  -0.66345\n",
              "3      1  48.24750   -1.89837  ...   9.90558   199.62971  18.85382\n",
              "4      1  50.97020   42.20998  ...   7.88713    55.66926  28.74903\n",
              "5      1  50.54767    0.31568  ...   5.00283   -11.02257   0.02263\n",
              "6      1  50.57546   33.17843  ...   4.50056    -4.62739   1.40192\n",
              "7      1  48.26892    8.97526  ...  -0.30633     3.98364  -3.72556\n",
              "8      1  49.75468   33.99581  ...   5.48708    -9.13495   6.08680\n",
              "9      1  45.17809   46.34234  ...  11.49326   -89.21804 -15.09719\n",
              "10     1  39.13076  -23.01763  ...  -2.59543   109.19723  23.36143\n",
              "11     1  37.66498  -34.05910  ...  -5.19009     8.83617  -7.16056\n",
              "12     1  26.51957 -148.15762  ...  23.00230  -164.02536  51.54138\n",
              "13     1  37.68491  -26.84185  ...  14.11648 -1030.99180  99.28967\n",
              "14     0  39.11695   -8.29767  ...  -2.14942  -211.48202 -12.81569\n",
              "15     1  35.05129  -67.97714  ...  20.73063  -562.07671  43.44696\n",
              "16     1  33.63129  -96.14912  ...   3.44539   259.10825  10.28525\n",
              "17     0  41.38639  -20.78665  ...   4.44627    58.16913  -0.02409\n",
              "18     0  37.45034   11.42615  ...  25.73235   157.22967  38.70617\n",
              "19     0  39.71092   -4.92800  ...   2.34002   -31.57015   1.58400\n",
              "\n",
              "[20 rows x 91 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncjxI4WdzGrA"
      },
      "source": [
        "### Part (a) -- 7%\n",
        "\n",
        "The data set description text asks us to respect the below train/test split to\n",
        "avoid the \"producer effect\". That is, we want to make sure that no song from a single artist\n",
        "ends up in both the training and test set.\n",
        "\n",
        "Explain why it would be problematic to have\n",
        "some songs from an artist in the training set, and other songs from the same artist in the\n",
        "test set. (Hint: Remember that we want our test accuracy to predict how well the model\n",
        "will perform in practice on a song it hasn't learned about.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NiYlxpFzGrB"
      },
      "source": [
        "df_train = df[:463715]\n",
        "df_test = df[463715:]\n",
        "\n",
        "# convert to numpy\n",
        "train_xs = df_train[x_labels].to_numpy()\n",
        "train_ts = df_train[t_label].to_numpy()\n",
        "test_xs = df_test[x_labels].to_numpy()\n",
        "test_ts = df_test[t_label].to_numpy()\n",
        "\n",
        "# Answer:\n",
        "# Usualy, differnt songs from the same artist will have a messure of similarity, therofre having songs from the same artist both on train and test\n",
        "# may encourage overffiting in our trained model. Moreover, recalling the NN task is identifing the song century, most of the artisit are active in only one century, and so if we use songs from\n",
        "# the same artist both on train and test we may harm the accuracy results on test when dealing with new songs that were never seen on train.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYSzd4XUzGrB"
      },
      "source": [
        "### Part (b) -- 7%\n",
        "\n",
        "It can be beneficial to **normalize** the columns, so that each column (feature)\n",
        "has the *same* mean and standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPuWLksJzGrB"
      },
      "source": [
        "feature_means = df_train.mean()[1:].to_numpy() # the [1:] removes the mean of the \"year\" field\n",
        "feature_stds  = df_train.std()[1:].to_numpy()\n",
        "\n",
        "train_norm_xs = (train_xs - feature_means) / feature_stds\n",
        "test_norm_xs = (test_xs - feature_means) / feature_stds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4zmZk6ezGrC"
      },
      "source": [
        "Notice how in our code, we normalized the test set using the *training data means and standard deviations*.\n",
        "This is *not* a bug.\n",
        "\n",
        "Explain why it would be improper to compute and use test set means\n",
        "and standard deviations. (Hint: Remember what we want to use the test accuracy to measure.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxZy6brwzGrC"
      },
      "source": [
        "# Answer:\n",
        "#Since the test dataset is unknown and will be presented to the model for in the inference step,\n",
        "# dealing with real world application, it cannot be assumed that all the test data will be presented to the model at once.\n",
        "# Therefore, it is invalid to normalized all the test dataset in advance. \n",
        "# Under the reasonable assumption that the test will have similar distribution to the train dataset,\n",
        "# we can normalize the test dataset with the train mean and std which will be a good estimation for the test mean and std."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4GqL5J_zGrC"
      },
      "source": [
        "### Part (c) -- 7%\n",
        "\n",
        "Finally, we'll move some of the data in our training set into a validation set.\n",
        "\n",
        "Explain why we should limit how many times we use the test set, and that we should use the validation\n",
        "set during the model building process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsXv1U3gzGrC"
      },
      "source": [
        "# shuffle the training set\n",
        "reindex = np.random.permutation(len(train_xs))\n",
        "train_xs = train_xs[reindex]\n",
        "train_norm_xs = train_norm_xs[reindex]\n",
        "train_ts = train_ts[reindex]\n",
        "train_size = 50000 #50000\n",
        "# use the first 50000 elements of `train_xs` as the validation set\n",
        "train_xs, val_xs           = train_xs[train_size:], train_xs[:train_size]\n",
        "train_norm_xs, val_norm_xs = train_norm_xs[train_size:], train_norm_xs[:train_size]\n",
        "train_ts, val_ts           = train_ts[train_size:], train_ts[:train_size]\n",
        "\n",
        "# Answer:\n",
        "# Since the test dataset will be introduced to the model only on the inference step,\n",
        "# we can not evaluate our model and test its accuracy on the test dataset.\n",
        "# Checking accuracy in the train step is crucial for the evaluation and understanding of the trained model,\n",
        "# thatâ€™s why we take a random small portion from the train dataset which will be used as the validation dataset.\n",
        "# The validation dataset will not be used for the weight training, instead it will be used to check the model accuracy on data that\n",
        "# were never introduced to the model for accuracy check in the training step.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy4lt445zGrD"
      },
      "source": [
        "## Part 2. Classification (79%)\n",
        "\n",
        "We will first build a *classification* model to perform decade classification.\n",
        "These helper functions are written for you. All other code that you write in this section should be vectorized whenever possible (i.e., avoid unnecessary loops)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6BA_s-kzGrD"
      },
      "source": [
        "def sigmoid(z):\n",
        "  return 1 / (1 + np.exp(-z))\n",
        "    \n",
        "def cross_entropy(t, y):\n",
        "  return -t * np.log(y) - (1 - t) * np.log(1 - y)\n",
        "\n",
        "def cost(y, t):\n",
        "  return np.mean(cross_entropy(t, y))\n",
        "\n",
        "def get_accuracy(y, t):\n",
        "  acc = 0\n",
        "  N = 0\n",
        "  for i in range(len(y)):\n",
        "    N += 1\n",
        "    if (y[i] >= 0.5 and t[i] == 1) or (y[i] < 0.5 and t[i] == 0):\n",
        "      acc += 1\n",
        "  return acc / N"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8ZIfooBzGrD"
      },
      "source": [
        "### Part (a) -- 7%\n",
        "\n",
        "Write a function `pred` that computes the prediction `y` based on logistic regression, i.e., a single layer with weights `w` and bias `b`. The output is given by: \n",
        "\\begin{equation}\n",
        "y = \\sigma({\\bf w}^T {\\bf x} + b),\n",
        "\\end{equation}\n",
        "where the value of $y$ is an estimate of the probability that the song is released in the current century, namely ${\\rm year} =1$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naY5mT4_zGrD"
      },
      "source": [
        "def pred(w, b, X):\n",
        "  \"\"\"\n",
        "  Returns the prediction `y` of the target based on the weights `w` and scalar bias `b`.\n",
        "\n",
        "  Preconditions: np.shape(w) == (90,)\n",
        "                 type(b) == float\n",
        "                 np.shape(X) = (N, 90) for some N\n",
        "\n",
        "  >>> pred(np.zeros(90), 1, np.ones([2, 90]))\n",
        "  array([0.73105858, 0.73105858]) # It's okay if your output differs in the last decimals\n",
        "  \"\"\"\n",
        " \n",
        "  return sigmoid(X @ w + b)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAlJZzxKlNFf"
      },
      "source": [
        "Test pred:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgFI0Mc_lBi4",
        "outputId": "bc88208a-c61e-4b82-dab0-b5e86adf1efc"
      },
      "source": [
        ">>> pred(np.zeros(90), 1, np.ones([2, 90]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.73105858, 0.73105858])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxNdmSd3zGrE"
      },
      "source": [
        "### Part (b) -- 7%\n",
        "\n",
        "Write a function `derivative_cost` that computes and returns the gradients \n",
        "$\\frac{\\partial\\mathcal{L}}{\\partial {\\bf w}}$ and\n",
        "$\\frac{\\partial\\mathcal{L}}{\\partial b}$. Here, `X` is the input, `y` is the prediction, and `t` is the true label.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P80bu7qmzGrE"
      },
      "source": [
        "def derivative_cost(X, y, t):\n",
        "  \"\"\"\n",
        "  Returns a tuple containing the gradients dLdw and dLdb.\n",
        "\n",
        "  Precondition: np.shape(X) == (N, 90) for some N\n",
        "                np.shape(y) == (N,)\n",
        "                np.shape(t) == (N,)\n",
        "\n",
        "  Postcondition: np.shape(dLdw) = (90,)\n",
        "           type(dLdb) = float\n",
        "  \"\"\"\n",
        "  # Based On analytical expression from text cell below\n",
        "  # Dims  \n",
        "  N, d = X.shape\n",
        "\n",
        "  phi = y-t \n",
        "  dLdw = X.T @ phi / N\n",
        "  dLdb = np.mean(phi)\n",
        "\n",
        "  return dLdw, dLdb\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okPRGM3BjKe2"
      },
      "source": [
        "# **Explenation on Gradients**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUCT0LWhgGMD"
      },
      "source": [
        "We will use the chain law to find $\\frac{\\partial \\mathcal{L}}{db}, \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{w}}$. That is:\n",
        "$$ \\frac{d\\mathcal{L}}{db} = \\sum_{n=1}^{N}\\frac{d\\mathcal{L}(\\mathbf{y,t})}{dy_n}\\frac{dy_n}{db}$$\n",
        "$$ \\frac{d\\mathcal{L}}{d\\mathbf{w}} = \\sum_{n=1}^{N}\\frac{d\\mathcal{L}(\\mathbf{y,t})}{dy_n}\\frac{dy_n}{d\\mathbf{w}}$$\n",
        "\n",
        "First we will find $\\frac{d\\mathcal{L}}{dy_n}$ where the cost function $\\mathcal{L}$ is the empirical mean of the cross entropy funcion.\n",
        "$$ \\frac{d\\mathcal{L}(\\mathbf{y,t})}{dy_n} = \\frac{d}{dy_n}\\left(\\frac{1}{N} \\sum_{k=1}^{N}\\left(-t_k\\log(y_k)-(1-t_k)\\log(1-y_k)\\right)\\right) \n",
        "= \\frac{y_n-t_n}{Ny_n(1-y_n)}$$\n",
        "\n",
        "Next we will find $\\frac{dy_n}{db}, \\frac{dy_n}{d\\mathbf{w}}$ using the chain rule agian:\n",
        "$$ \\frac{dy_n}{db} = \\sigma'(z_n) \\frac{dz_n}{db}$$\n",
        "$$ \\frac{dy_n}{d\\mathbf{w}} = \\sigma'(z_n) \\frac{dz_n}{d\\mathbf{w}}$$\n",
        "where $z_k = \\mathbf{w}^T\\mathbf{x}_k +b$.\n",
        "\n",
        "We know that the derivative of Sigmoid function satisfies:\n",
        "$$ \\sigma'(z_n) = \\sigma(z_n)(1-\\sigma(z_n)) = y_n(1-y_n)$$\n",
        "\n",
        "Recalling $y_n$:\n",
        "$$ y_n = \\sigma(z_k)$$\n",
        "The derivites of $z_n$ are:\n",
        "$$ \\frac{dz_n}{db} = 1$$\n",
        "$$ \\frac{dz_n}{d\\mathbf{w}} = \\mathbf{x}_n$$\n",
        "\n",
        "Pulgining all together we get:\n",
        "$$ \\frac{d\\mathcal{L}}{db} = \\sum_{n=1}^{N} \\left(\\frac{y_n-t_n}{Ny_n(1-y_n)}y_n(1-y_n)\\right) =   \\frac{1}{N}\\sum_{n=1}^{N}y_n-t_n$$\n",
        "\n",
        "$$ \\frac{d\\mathcal{L}}{d\\mathbf{w}} = \\sum_{n=1}^{N} \\left(\\frac{y_n-t_n}{Ny_n(1-y_n)}y_n(1-y_n)\\mathbf{x}_n\\right) =   \\frac{1}{N}\\sum_{n=1}^{N}(y_n-t_n)\\mathbf{x}_n$$\n",
        "\n",
        "\n",
        "By defining $\\boldsymbol{\\varphi}= \\mathbf{y-t}$ and $\\mathbf{X} = [\\mathbf{x_1},\\dots , \\mathbf{x}_n]$ , we can write:\n",
        "\n",
        "$$\\frac{d\\mathcal{L}}{db} = \\frac{1}{N}\\boldsymbol{\\varphi}^T\\mathbf{1} $$ \n",
        "$$\\frac{d\\mathcal{L}}{db} = \\frac{1}{N}\\mathbf{X}\\boldsymbol{\\varphi} $$ \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhQXAKd4zGrE"
      },
      "source": [
        "### Part (c) -- 7%\n",
        "\n",
        "We can check that our derivative is implemented correctly using the finite difference rule. In 1D, the\n",
        "finite difference rule tells us that for small $h$, we should have\n",
        "\n",
        "$$\\frac{f(x+h) - f(x)}{h} \\approx f'(x)$$\n",
        "\n",
        "Show that $\\frac{\\partial\\mathcal{L}}{\\partial b}$  is implement correctly\n",
        "by comparing the result from `derivative_cost` with the empirical cost derivative computed using the above numerical approximation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpRTD-fozGrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff379ec4-5615-4789-f86f-59d593a6d1ed"
      },
      "source": [
        "# Your code goes here\n",
        "\n",
        "#Data, labels\n",
        "bs = 100\n",
        "X = train_norm_xs[:bs,:]\n",
        "t = train_ts[:bs].flatten()\n",
        "# Weights for example\n",
        "w = np.zeros(90)\n",
        "b = 1\n",
        "#Create Cost\n",
        "y = pred(w, b, X)\n",
        "cost_func = cost(y, t)\n",
        "\n",
        "#Create values with infinitesimal diff\n",
        "delta = 1e-6\n",
        "y_delta = pred(w, b + delta, X)\n",
        "cost_delta = cost(y_delta, t)\n",
        "\n",
        "#Create derivetives\n",
        "_, r1 = derivative_cost(X, y, t)\n",
        "r2 = (cost_delta - cost_func) / delta\n",
        "\n",
        "#Prints\n",
        "print(\"The analytical results is -\", r1)\n",
        "print(\"The algorithm results is - \", r2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The analytical results is - 0.20105857863000487\n",
            "The algorithm results is -  0.20105867704067748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTiplTPhzGrF"
      },
      "source": [
        "### Part (d) -- 7%\n",
        "\n",
        "Show that $\\frac{\\partial\\mathcal{L}}{\\partial {\\bf w}}$  is implement correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVTsHgnPzGrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52e34f66-7098-4f52-860d-b4bef779c736"
      },
      "source": [
        "# Your code goes here. You might find this below code helpful: but it's\n",
        "# up to you to figure out how/why, and how to modify the code\n",
        "\n",
        "#Create values with infinitesimal diff\n",
        "delta = 1e-6\n",
        "ei = np.zeros(90); ei[0] = 1\n",
        "cost_delta = np.array([cost(pred(w + delta * np.roll(ei,i),b,X),t) for i in range(90)])\n",
        "\n",
        "#Create derivetives\n",
        "r1, _ = derivative_cost(X, y, t)\n",
        "r2 = (cost_delta - cost_func) / delta\n",
        "\n",
        "#Prints\n",
        "print(\"The analytical results is -\", r1)\n",
        "print(\"The algorithm results is - \", r2)\n",
        "print(\"Norm Diff - \", np.linalg.norm(r1-r2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The analytical results is - [-0.1766488   0.0587784  -0.02777683 -0.05053766 -0.00073406  0.08746245\n",
            " -0.04491561 -0.01535708 -0.00279043  0.04957525 -0.04313581  0.04487651\n",
            " -0.0042727  -0.09193621 -0.00953821  0.0074573  -0.02026908 -0.00345954\n",
            "  0.02565653 -0.01371859 -0.05835509 -0.00755168  0.01074138 -0.04519269\n",
            " -0.08900419 -0.01461646 -0.0336323  -0.02562888  0.0558745  -0.02804914\n",
            "  0.01267931  0.07659419 -0.06196433 -0.02563857 -0.04609733 -0.00663775\n",
            " -0.03848326  0.09790356 -0.06861164 -0.01036716  0.02238052  0.03525389\n",
            " -0.06009674 -0.02937883  0.02396044  0.09172294 -0.10061652  0.07076747\n",
            " -0.04134646  0.0335404  -0.03122046  0.06656809 -0.05798216 -0.02487997\n",
            "  0.0487576  -0.02538004  0.05827587  0.06749868  0.02173589  0.07968763\n",
            " -0.00152445  0.01822238  0.08850806  0.07109869  0.03143603 -0.00270556\n",
            "  0.06384109 -0.10434483  0.01274905  0.01555724  0.0312428  -0.05783697\n",
            " -0.03942598 -0.00817863  0.06084759  0.07094968 -0.0386386  -0.00050697\n",
            " -0.01229933 -0.02836065 -0.01488342 -0.02748698 -0.02187758 -0.00984211\n",
            "  0.0572165   0.12155107 -0.0269101   0.00252241 -0.04768475  0.05874064]\n",
            "The algorithm results is -  [-0.17664869  0.0587785  -0.02777675 -0.05053752 -0.00073395  0.08746256\n",
            " -0.04491548 -0.015357   -0.0027903   0.04957537 -0.04313569  0.04487665\n",
            " -0.00427262 -0.09193613 -0.00953813  0.00745739 -0.02026894 -0.00345946\n",
            "  0.02565663 -0.01371837 -0.05835497 -0.00755158  0.01074148 -0.04519259\n",
            " -0.08900408 -0.01461637 -0.03363221 -0.0256287   0.05587457 -0.02804907\n",
            "  0.01267947  0.0765943  -0.06196422 -0.02563847 -0.04609717 -0.00663767\n",
            " -0.03848319  0.09790367 -0.06861157 -0.01036702  0.02238064  0.03525397\n",
            " -0.06009659 -0.02937875  0.02396056  0.09172303 -0.10061643  0.07076753\n",
            " -0.04134634  0.03354068 -0.03122038  0.06656819 -0.05798197 -0.02487984\n",
            "  0.04875776 -0.02537995  0.05827593  0.06749891  0.021736    0.07968771\n",
            " -0.00152432  0.01822252  0.08850815  0.0710988   0.03143613 -0.00270546\n",
            "  0.06384117 -0.10434474  0.01274917  0.01555734  0.03124286 -0.0578369\n",
            " -0.03942589 -0.00817852  0.06084768  0.07094993 -0.03863851 -0.00050683\n",
            " -0.01229923 -0.02836047 -0.01488334 -0.02748688 -0.02187747 -0.00984198\n",
            "  0.05721661  0.12155115 -0.02691004  0.0025225  -0.04768464  0.05874077]\n",
            "Norm Diff -  1.127112343422638e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgBTPF_2zGrG"
      },
      "source": [
        "### Part (e) -- 7%\n",
        "\n",
        "Now that you have a gradient function that works, we can actually run gradient descent. \n",
        "Complete the following code that will run stochastic: gradient descent training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW4DEuuPzGrG"
      },
      "source": [
        "def run_gradient_descent(train_norm_xs, train_ts, val_norm_xs, val_ts, w0, b0, mu=0.1, batch_size=100, max_iters=100):\n",
        "  \"\"\"Return the values of (w, b) after running gradient descent for max_iters.\n",
        "  We use:\n",
        "    - train_norm_xs and train_ts as the training set\n",
        "    - val_norm_xs and val_ts as the test set\n",
        "    - mu as the learning rate\n",
        "    - (w0, b0) as the initial values of (w, b)\n",
        "\n",
        "  Precondition: np.shape(w0) == (90,)\n",
        "                type(b0) == float\n",
        " \n",
        "  Postcondition: np.shape(w) == (90,)\n",
        "                 type(b) == float\n",
        "  \"\"\"\n",
        "  w = w0\n",
        "  b = b0\n",
        "  iter = 0\n",
        "  train_loss_arr = []\n",
        "  val_loss_arr = []\n",
        "  val_acc_arr = []\n",
        "  trian_acc_arr = []\n",
        "  \n",
        "\n",
        "  while iter < max_iters:\n",
        "    # shuffle the training set (there is code above for how to do this)\n",
        "    reindex = np.random.permutation(len(train_norm_xs))\n",
        "    train_norm_xs = train_norm_xs[reindex]\n",
        "    train_ts = train_ts[reindex]\n",
        "    \n",
        "\n",
        "    for i in range(0, len(train_norm_xs), batch_size): # iterate over each minibatch\n",
        "      # minibatch that we are working with:\n",
        "      X = train_norm_xs[i:(i + batch_size)]\n",
        "      t = train_ts[i:(i + batch_size), 0]\n",
        "\n",
        "      # since len(train_norm_xs) does not divide batch_size evenly, we will skip over\n",
        "      # the \"last\" minibatch\n",
        "      if np.shape(X)[0] != batch_size:\n",
        "        continue\n",
        "\n",
        "      # compute the prediction\n",
        "      predictions = pred(w, b, X)\n",
        "\n",
        "      # update w and b\n",
        "      grad_w, grad_b = derivative_cost(X, predictions, t)\n",
        "      w = w - mu * grad_w\n",
        "      b = b - mu * grad_b\n",
        "\n",
        "      # increment the iteration count\n",
        "      iter += 1\n",
        "      # compute and print the *validation* loss and accuracy\n",
        "      if (iter % 10 == 0):\n",
        "        pred_val = pred(w, b, val_norm_xs)\n",
        "        pred_train = pred(w, b, X)\n",
        "        val_cost = cost(pred_val, val_ts)\n",
        "        val_acc = get_accuracy(pred_val, val_ts)\n",
        "        train_acc = get_accuracy(pred_train, t)\n",
        "        train_loss = cost(pred_train, t)\n",
        "\n",
        "        train_loss_arr.append(train_loss)\n",
        "        trian_acc_arr.append(train_acc)\n",
        "        val_loss_arr.append(val_cost)\n",
        "        val_acc_arr.append(val_acc)\n",
        "\n",
        "        \n",
        "        print(\"Iter %4d. [Train Loss %f, Val Loss %f, Train Acc %.0f%%, Val Acc %.0f%%]\" % (\n",
        "                iter, train_loss, val_cost, train_acc*100, val_acc * 100))\n",
        "        \n",
        "\n",
        "      if iter >= max_iters:\n",
        "        break\n",
        "\n",
        "\n",
        "  analysis_dict = {'Train_Loss': np.array(train_loss_arr),\n",
        "                  'Val_Loss':np.array(val_loss_arr),\n",
        "                  'Train_acc':np.array(trian_acc_arr),\n",
        "                  'Val_acc':np.array(val_acc_arr)}\n",
        "\n",
        "        \n",
        "  return w, b, analysis_dict\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MqzT0jGzGrH"
      },
      "source": [
        "### Part (f) -- 7%\n",
        "\n",
        "Call `run_gradient_descent` with the weights and biases all initialized to zero.\n",
        "Show that if the learning rate $\\mu$ is too small, then convergence is slow.\n",
        "Also, show that if $\\mu$ is too large, then the optimization algorirthm does not converge. The demonstration should be made using plots showing these effects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE32Iqo6zGrH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a90aa87-8a6c-417a-c7fb-1ce7ba77a40d"
      },
      "source": [
        "# w0 = np.random.randn(90)\n",
        "# b0 = np.random.randn(1)[0]\n",
        "w0 = np.zeros(90)\n",
        "b0 = 0 \n",
        "\n",
        "\n",
        "w, b, analysis_dict = run_gradient_descent(train_norm_xs, train_ts, val_norm_xs, val_ts.flatten(), w0, b0, max_iters=1e4,mu=0.1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter   10. [Train Loss 0.621754, Val Loss 0.655428, Train Acc 71%, Val Acc 64%]\n",
            "Iter   20. [Train Loss 0.627396, Val Loss 0.635829, Train Acc 67%, Val Acc 68%]\n",
            "Iter   30. [Train Loss 0.597054, Val Loss 0.620719, Train Acc 70%, Val Acc 69%]\n",
            "Iter   40. [Train Loss 0.543125, Val Loss 0.611234, Train Acc 74%, Val Acc 70%]\n",
            "Iter   50. [Train Loss 0.646492, Val Loss 0.605768, Train Acc 73%, Val Acc 69%]\n",
            "Iter   60. [Train Loss 0.541447, Val Loss 0.600210, Train Acc 81%, Val Acc 70%]\n",
            "Iter   70. [Train Loss 0.598489, Val Loss 0.595635, Train Acc 69%, Val Acc 70%]\n",
            "Iter   80. [Train Loss 0.589415, Val Loss 0.593851, Train Acc 71%, Val Acc 71%]\n",
            "Iter   90. [Train Loss 0.570954, Val Loss 0.589759, Train Acc 75%, Val Acc 71%]\n",
            "Iter  100. [Train Loss 0.547033, Val Loss 0.587472, Train Acc 81%, Val Acc 71%]\n",
            "Iter  110. [Train Loss 0.589324, Val Loss 0.584061, Train Acc 68%, Val Acc 71%]\n",
            "Iter  120. [Train Loss 0.552943, Val Loss 0.584162, Train Acc 74%, Val Acc 71%]\n",
            "Iter  130. [Train Loss 0.520673, Val Loss 0.580452, Train Acc 70%, Val Acc 72%]\n",
            "Iter  140. [Train Loss 0.566100, Val Loss 0.579432, Train Acc 69%, Val Acc 72%]\n",
            "Iter  150. [Train Loss 0.569910, Val Loss 0.577876, Train Acc 73%, Val Acc 72%]\n",
            "Iter  160. [Train Loss 0.513585, Val Loss 0.575976, Train Acc 75%, Val Acc 72%]\n",
            "Iter  170. [Train Loss 0.542296, Val Loss 0.575644, Train Acc 75%, Val Acc 72%]\n",
            "Iter  180. [Train Loss 0.582424, Val Loss 0.575282, Train Acc 65%, Val Acc 72%]\n",
            "Iter  190. [Train Loss 0.600533, Val Loss 0.574699, Train Acc 65%, Val Acc 72%]\n",
            "Iter  200. [Train Loss 0.539125, Val Loss 0.575139, Train Acc 78%, Val Acc 72%]\n",
            "Iter  210. [Train Loss 0.591098, Val Loss 0.572581, Train Acc 67%, Val Acc 72%]\n",
            "Iter  220. [Train Loss 0.527119, Val Loss 0.575237, Train Acc 77%, Val Acc 73%]\n",
            "Iter  230. [Train Loss 0.549346, Val Loss 0.569590, Train Acc 73%, Val Acc 73%]\n",
            "Iter  240. [Train Loss 0.558094, Val Loss 0.571253, Train Acc 71%, Val Acc 72%]\n",
            "Iter  250. [Train Loss 0.532227, Val Loss 0.569194, Train Acc 77%, Val Acc 72%]\n",
            "Iter  260. [Train Loss 0.648408, Val Loss 0.567570, Train Acc 66%, Val Acc 73%]\n",
            "Iter  270. [Train Loss 0.629668, Val Loss 0.568793, Train Acc 63%, Val Acc 73%]\n",
            "Iter  280. [Train Loss 0.460395, Val Loss 0.567411, Train Acc 85%, Val Acc 73%]\n",
            "Iter  290. [Train Loss 0.565877, Val Loss 0.566886, Train Acc 71%, Val Acc 73%]\n",
            "Iter  300. [Train Loss 0.533879, Val Loss 0.566704, Train Acc 73%, Val Acc 73%]\n",
            "Iter  310. [Train Loss 0.487553, Val Loss 0.566814, Train Acc 75%, Val Acc 73%]\n",
            "Iter  320. [Train Loss 0.474703, Val Loss 0.570546, Train Acc 79%, Val Acc 72%]\n",
            "Iter  330. [Train Loss 0.543290, Val Loss 0.568432, Train Acc 77%, Val Acc 73%]\n",
            "Iter  340. [Train Loss 0.530344, Val Loss 0.564897, Train Acc 74%, Val Acc 73%]\n",
            "Iter  350. [Train Loss 0.502167, Val Loss 0.565665, Train Acc 77%, Val Acc 73%]\n",
            "Iter  360. [Train Loss 0.548031, Val Loss 0.565086, Train Acc 79%, Val Acc 72%]\n",
            "Iter  370. [Train Loss 0.583011, Val Loss 0.567652, Train Acc 75%, Val Acc 72%]\n",
            "Iter  380. [Train Loss 0.521639, Val Loss 0.566929, Train Acc 74%, Val Acc 72%]\n",
            "Iter  390. [Train Loss 0.636452, Val Loss 0.564124, Train Acc 67%, Val Acc 73%]\n",
            "Iter  400. [Train Loss 0.570983, Val Loss 0.565303, Train Acc 75%, Val Acc 73%]\n",
            "Iter  410. [Train Loss 0.559973, Val Loss 0.564137, Train Acc 69%, Val Acc 73%]\n",
            "Iter  420. [Train Loss 0.602662, Val Loss 0.565407, Train Acc 73%, Val Acc 73%]\n",
            "Iter  430. [Train Loss 0.608319, Val Loss 0.565678, Train Acc 70%, Val Acc 72%]\n",
            "Iter  440. [Train Loss 0.524927, Val Loss 0.564740, Train Acc 77%, Val Acc 73%]\n",
            "Iter  450. [Train Loss 0.592104, Val Loss 0.564753, Train Acc 68%, Val Acc 73%]\n",
            "Iter  460. [Train Loss 0.587276, Val Loss 0.563604, Train Acc 73%, Val Acc 73%]\n",
            "Iter  470. [Train Loss 0.526032, Val Loss 0.564356, Train Acc 78%, Val Acc 73%]\n",
            "Iter  480. [Train Loss 0.462691, Val Loss 0.565647, Train Acc 79%, Val Acc 72%]\n",
            "Iter  490. [Train Loss 0.494040, Val Loss 0.565304, Train Acc 79%, Val Acc 73%]\n",
            "Iter  500. [Train Loss 0.597061, Val Loss 0.565628, Train Acc 66%, Val Acc 73%]\n",
            "Iter  510. [Train Loss 0.559959, Val Loss 0.565072, Train Acc 69%, Val Acc 73%]\n",
            "Iter  520. [Train Loss 0.528967, Val Loss 0.563792, Train Acc 77%, Val Acc 73%]\n",
            "Iter  530. [Train Loss 0.530925, Val Loss 0.563294, Train Acc 78%, Val Acc 73%]\n",
            "Iter  540. [Train Loss 0.552157, Val Loss 0.565087, Train Acc 75%, Val Acc 73%]\n",
            "Iter  550. [Train Loss 0.599410, Val Loss 0.563751, Train Acc 71%, Val Acc 73%]\n",
            "Iter  560. [Train Loss 0.552035, Val Loss 0.561632, Train Acc 65%, Val Acc 73%]\n",
            "Iter  570. [Train Loss 0.587542, Val Loss 0.562898, Train Acc 69%, Val Acc 73%]\n",
            "Iter  580. [Train Loss 0.503642, Val Loss 0.563365, Train Acc 74%, Val Acc 73%]\n",
            "Iter  590. [Train Loss 0.576295, Val Loss 0.563255, Train Acc 72%, Val Acc 73%]\n",
            "Iter  600. [Train Loss 0.586813, Val Loss 0.565690, Train Acc 70%, Val Acc 73%]\n",
            "Iter  610. [Train Loss 0.517252, Val Loss 0.564345, Train Acc 76%, Val Acc 73%]\n",
            "Iter  620. [Train Loss 0.561642, Val Loss 0.564082, Train Acc 73%, Val Acc 73%]\n",
            "Iter  630. [Train Loss 0.517454, Val Loss 0.565677, Train Acc 73%, Val Acc 73%]\n",
            "Iter  640. [Train Loss 0.626578, Val Loss 0.564117, Train Acc 66%, Val Acc 73%]\n",
            "Iter  650. [Train Loss 0.560053, Val Loss 0.563929, Train Acc 76%, Val Acc 73%]\n",
            "Iter  660. [Train Loss 0.525214, Val Loss 0.562480, Train Acc 80%, Val Acc 73%]\n",
            "Iter  670. [Train Loss 0.605846, Val Loss 0.562710, Train Acc 72%, Val Acc 73%]\n",
            "Iter  680. [Train Loss 0.510535, Val Loss 0.561688, Train Acc 74%, Val Acc 73%]\n",
            "Iter  690. [Train Loss 0.543064, Val Loss 0.566775, Train Acc 75%, Val Acc 72%]\n",
            "Iter  700. [Train Loss 0.519795, Val Loss 0.564222, Train Acc 77%, Val Acc 73%]\n",
            "Iter  710. [Train Loss 0.496067, Val Loss 0.564136, Train Acc 83%, Val Acc 73%]\n",
            "Iter  720. [Train Loss 0.563410, Val Loss 0.563371, Train Acc 77%, Val Acc 73%]\n",
            "Iter  730. [Train Loss 0.559641, Val Loss 0.561038, Train Acc 71%, Val Acc 73%]\n",
            "Iter  740. [Train Loss 0.625193, Val Loss 0.562555, Train Acc 69%, Val Acc 73%]\n",
            "Iter  750. [Train Loss 0.572375, Val Loss 0.563501, Train Acc 69%, Val Acc 73%]\n",
            "Iter  760. [Train Loss 0.562799, Val Loss 0.560817, Train Acc 68%, Val Acc 73%]\n",
            "Iter  770. [Train Loss 0.505197, Val Loss 0.562805, Train Acc 75%, Val Acc 73%]\n",
            "Iter  780. [Train Loss 0.540487, Val Loss 0.562333, Train Acc 80%, Val Acc 73%]\n",
            "Iter  790. [Train Loss 0.509956, Val Loss 0.572328, Train Acc 80%, Val Acc 72%]\n",
            "Iter  800. [Train Loss 0.598833, Val Loss 0.562754, Train Acc 71%, Val Acc 73%]\n",
            "Iter  810. [Train Loss 0.485721, Val Loss 0.561520, Train Acc 81%, Val Acc 73%]\n",
            "Iter  820. [Train Loss 0.571222, Val Loss 0.561722, Train Acc 72%, Val Acc 73%]\n",
            "Iter  830. [Train Loss 0.492491, Val Loss 0.562794, Train Acc 75%, Val Acc 73%]\n",
            "Iter  840. [Train Loss 0.524407, Val Loss 0.564216, Train Acc 75%, Val Acc 73%]\n",
            "Iter  850. [Train Loss 0.489584, Val Loss 0.562551, Train Acc 75%, Val Acc 73%]\n",
            "Iter  860. [Train Loss 0.603429, Val Loss 0.561586, Train Acc 66%, Val Acc 73%]\n",
            "Iter  870. [Train Loss 0.526677, Val Loss 0.561111, Train Acc 77%, Val Acc 73%]\n",
            "Iter  880. [Train Loss 0.479007, Val Loss 0.561032, Train Acc 81%, Val Acc 73%]\n",
            "Iter  890. [Train Loss 0.508964, Val Loss 0.567546, Train Acc 76%, Val Acc 73%]\n",
            "Iter  900. [Train Loss 0.601068, Val Loss 0.565271, Train Acc 63%, Val Acc 73%]\n",
            "Iter  910. [Train Loss 0.552680, Val Loss 0.564832, Train Acc 77%, Val Acc 73%]\n",
            "Iter  920. [Train Loss 0.563863, Val Loss 0.562883, Train Acc 77%, Val Acc 73%]\n",
            "Iter  930. [Train Loss 0.643491, Val Loss 0.563769, Train Acc 71%, Val Acc 73%]\n",
            "Iter  940. [Train Loss 0.570636, Val Loss 0.562976, Train Acc 75%, Val Acc 73%]\n",
            "Iter  950. [Train Loss 0.472530, Val Loss 0.562330, Train Acc 76%, Val Acc 73%]\n",
            "Iter  960. [Train Loss 0.543120, Val Loss 0.563309, Train Acc 75%, Val Acc 73%]\n",
            "Iter  970. [Train Loss 0.584230, Val Loss 0.563964, Train Acc 71%, Val Acc 73%]\n",
            "Iter  980. [Train Loss 0.545616, Val Loss 0.561686, Train Acc 75%, Val Acc 73%]\n",
            "Iter  990. [Train Loss 0.479776, Val Loss 0.565197, Train Acc 81%, Val Acc 73%]\n",
            "Iter 1000. [Train Loss 0.486640, Val Loss 0.563095, Train Acc 79%, Val Acc 73%]\n",
            "Iter 1010. [Train Loss 0.570353, Val Loss 0.562434, Train Acc 73%, Val Acc 73%]\n",
            "Iter 1020. [Train Loss 0.493135, Val Loss 0.561310, Train Acc 79%, Val Acc 73%]\n",
            "Iter 1030. [Train Loss 0.494530, Val Loss 0.562202, Train Acc 79%, Val Acc 73%]\n",
            "Iter 1040. [Train Loss 0.514749, Val Loss 0.561655, Train Acc 77%, Val Acc 73%]\n",
            "Iter 1050. [Train Loss 0.549403, Val Loss 0.561726, Train Acc 76%, Val Acc 73%]\n",
            "Iter 1060. [Train Loss 0.494815, Val Loss 0.561448, Train Acc 80%, Val Acc 73%]\n",
            "Iter 1070. [Train Loss 0.632399, Val Loss 0.564548, Train Acc 70%, Val Acc 73%]\n",
            "Iter 1080. [Train Loss 0.614457, Val Loss 0.561169, Train Acc 71%, Val Acc 73%]\n",
            "Iter 1090. [Train Loss 0.566646, Val Loss 0.562178, Train Acc 75%, Val Acc 73%]\n",
            "Iter 1100. [Train Loss 0.514214, Val Loss 0.561261, Train Acc 74%, Val Acc 73%]\n",
            "Iter 1110. [Train Loss 0.582348, Val Loss 0.561907, Train Acc 71%, Val Acc 73%]\n",
            "Iter 1120. [Train Loss 0.660415, Val Loss 0.561544, Train Acc 74%, Val Acc 73%]\n",
            "Iter 1130. [Train Loss 0.577768, Val Loss 0.562919, Train Acc 75%, Val Acc 73%]\n",
            "Iter 1140. [Train Loss 0.534640, Val Loss 0.560974, Train Acc 73%, Val Acc 73%]\n",
            "Iter 1150. [Train Loss 0.508875, Val Loss 0.562471, Train Acc 77%, Val Acc 73%]\n",
            "Iter 1160. [Train Loss 0.559787, Val Loss 0.561598, Train Acc 71%, Val Acc 73%]\n",
            "Iter 1170. [Train Loss 0.554265, Val Loss 0.560763, Train Acc 76%, Val Acc 73%]\n",
            "Iter 1180. [Train Loss 0.453395, Val Loss 0.562682, Train Acc 83%, Val Acc 73%]\n",
            "Iter 1190. [Train Loss 0.529483, Val Loss 0.560849, Train Acc 79%, Val Acc 73%]\n",
            "Iter 1200. [Train Loss 0.583983, Val Loss 0.566122, Train Acc 70%, Val Acc 72%]\n",
            "Iter 1210. [Train Loss 0.569909, Val Loss 0.561791, Train Acc 68%, Val Acc 73%]\n",
            "Iter 1220. [Train Loss 0.513329, Val Loss 0.561123, Train Acc 73%, Val Acc 73%]\n",
            "Iter 1230. [Train Loss 0.525501, Val Loss 0.562388, Train Acc 78%, Val Acc 73%]\n",
            "Iter 1240. [Train Loss 0.603225, Val Loss 0.561061, Train Acc 70%, Val Acc 73%]\n",
            "Iter 1250. [Train Loss 0.568724, Val Loss 0.560978, Train Acc 70%, Val Acc 73%]\n",
            "Iter 1260. [Train Loss 0.541840, Val Loss 0.562388, Train Acc 70%, Val Acc 73%]\n",
            "Iter 1270. [Train Loss 0.515824, Val Loss 0.564716, Train Acc 73%, Val Acc 73%]\n",
            "Iter 1280. [Train Loss 0.509088, Val Loss 0.563510, Train Acc 78%, Val Acc 73%]\n",
            "Iter 1290. [Train Loss 0.472385, Val Loss 0.562975, Train Acc 77%, Val Acc 73%]\n",
            "Iter 1300. [Train Loss 0.642469, Val Loss 0.560690, Train Acc 64%, Val Acc 73%]\n",
            "Iter 1310. [Train Loss 0.559477, Val Loss 0.562802, Train Acc 71%, Val Acc 73%]\n",
            "Iter 1320. [Train Loss 0.517856, Val Loss 0.561116, Train Acc 72%, Val Acc 73%]\n",
            "Iter 1330. [Train Loss 0.573897, Val Loss 0.561659, Train Acc 69%, Val Acc 73%]\n",
            "Iter 1340. [Train Loss 0.586603, Val Loss 0.563822, Train Acc 73%, Val Acc 73%]\n",
            "Iter 1350. [Train Loss 0.580407, Val Loss 0.563509, Train Acc 74%, Val Acc 73%]\n",
            "Iter 1360. [Train Loss 0.637989, Val Loss 0.562594, Train Acc 61%, Val Acc 73%]\n",
            "Iter 1370. [Train Loss 0.559962, Val Loss 0.561005, Train Acc 75%, Val Acc 73%]\n",
            "Iter 1380. [Train Loss 0.519626, Val Loss 0.561259, Train Acc 73%, Val Acc 73%]\n",
            "Iter 1390. [Train Loss 0.519060, Val Loss 0.562722, Train Acc 74%, Val Acc 73%]\n",
            "Iter 1400. [Train Loss 0.503672, Val Loss 0.560166, Train Acc 74%, Val Acc 73%]\n",
            "Iter 1410. [Train Loss 0.533749, Val Loss 0.561300, Train Acc 74%, Val Acc 73%]\n",
            "Iter 1420. [Train Loss 0.559144, Val Loss 0.561798, Train Acc 70%, Val Acc 73%]\n",
            "Iter 1430. [Train Loss 0.503688, Val Loss 0.562578, Train Acc 74%, Val Acc 73%]\n",
            "Iter 1440. [Train Loss 0.604301, Val Loss 0.562488, Train Acc 69%, Val Acc 73%]\n",
            "Iter 1450. [Train Loss 0.533545, Val Loss 0.562473, Train Acc 76%, Val Acc 73%]\n",
            "Iter 1460. [Train Loss 0.580846, Val Loss 0.562345, Train Acc 70%, Val Acc 73%]\n",
            "Iter 1470. [Train Loss 0.601313, Val Loss 0.561362, Train Acc 68%, Val Acc 73%]\n",
            "Iter 1480. [Train Loss 0.514550, Val Loss 0.562068, Train Acc 74%, Val Acc 73%]\n",
            "Iter 1490. [Train Loss 0.511366, Val Loss 0.561850, Train Acc 78%, Val Acc 73%]\n",
            "Iter 1500. [Train Loss 0.544036, Val Loss 0.560577, Train Acc 73%, Val Acc 73%]\n",
            "Iter 1510. [Train Loss 0.569792, Val Loss 0.560305, Train Acc 71%, Val Acc 73%]\n",
            "Iter 1520. [Train Loss 0.522077, Val Loss 0.561800, Train Acc 78%, Val Acc 73%]\n",
            "Iter 1530. [Train Loss 0.619410, Val Loss 0.561817, Train Acc 64%, Val Acc 73%]\n",
            "Iter 1540. [Train Loss 0.613751, Val Loss 0.561582, Train Acc 68%, Val Acc 73%]\n",
            "Iter 1550. [Train Loss 0.537572, Val Loss 0.565104, Train Acc 73%, Val Acc 73%]\n",
            "Iter 1560. [Train Loss 0.543138, Val Loss 0.562529, Train Acc 78%, Val Acc 73%]\n",
            "Iter 1570. [Train Loss 0.488246, Val Loss 0.561154, Train Acc 76%, Val Acc 73%]\n",
            "Iter 1580. [Train Loss 0.504407, Val Loss 0.561000, Train Acc 78%, Val Acc 73%]\n",
            "Iter 1590. [Train Loss 0.534370, Val Loss 0.562438, Train Acc 76%, Val Acc 73%]\n",
            "Iter 1600. [Train Loss 0.561211, Val Loss 0.562664, Train Acc 74%, Val Acc 73%]\n",
            "Iter 1610. [Train Loss 0.627507, Val Loss 0.561809, Train Acc 67%, Val Acc 73%]\n",
            "Iter 1620. [Train Loss 0.459728, Val Loss 0.562528, Train Acc 78%, Val Acc 73%]\n",
            "Iter 1630. [Train Loss 0.606620, Val Loss 0.562830, Train Acc 67%, Val Acc 73%]\n",
            "Iter 1640. [Train Loss 0.535368, Val Loss 0.564965, Train Acc 77%, Val Acc 73%]\n",
            "Iter 1650. [Train Loss 0.605494, Val Loss 0.564639, Train Acc 70%, Val Acc 73%]\n",
            "Iter 1660. [Train Loss 0.612250, Val Loss 0.563497, Train Acc 70%, Val Acc 73%]\n",
            "Iter 1670. [Train Loss 0.535011, Val Loss 0.563071, Train Acc 76%, Val Acc 73%]\n",
            "Iter 1680. [Train Loss 0.494867, Val Loss 0.564202, Train Acc 75%, Val Acc 73%]\n",
            "Iter 1690. [Train Loss 0.555671, Val Loss 0.561890, Train Acc 71%, Val Acc 73%]\n",
            "Iter 1700. [Train Loss 0.513002, Val Loss 0.562169, Train Acc 79%, Val Acc 73%]\n",
            "Iter 1710. [Train Loss 0.598185, Val Loss 0.564974, Train Acc 67%, Val Acc 73%]\n",
            "Iter 1720. [Train Loss 0.585080, Val Loss 0.561022, Train Acc 68%, Val Acc 73%]\n",
            "Iter 1730. [Train Loss 0.540542, Val Loss 0.563181, Train Acc 73%, Val Acc 73%]\n",
            "Iter 1740. [Train Loss 0.570626, Val Loss 0.562236, Train Acc 79%, Val Acc 73%]\n",
            "Iter 1750. [Train Loss 0.475314, Val Loss 0.561713, Train Acc 78%, Val Acc 73%]\n",
            "Iter 1760. [Train Loss 0.557888, Val Loss 0.561433, Train Acc 70%, Val Acc 73%]\n",
            "Iter 1770. [Train Loss 0.454417, Val Loss 0.561710, Train Acc 79%, Val Acc 73%]\n",
            "Iter 1780. [Train Loss 0.557939, Val Loss 0.561216, Train Acc 75%, Val Acc 73%]\n",
            "Iter 1790. [Train Loss 0.600020, Val Loss 0.559981, Train Acc 69%, Val Acc 73%]\n",
            "Iter 1800. [Train Loss 0.503862, Val Loss 0.560789, Train Acc 78%, Val Acc 73%]\n",
            "Iter 1810. [Train Loss 0.571800, Val Loss 0.561250, Train Acc 75%, Val Acc 73%]\n",
            "Iter 1820. [Train Loss 0.494196, Val Loss 0.562000, Train Acc 73%, Val Acc 73%]\n",
            "Iter 1830. [Train Loss 0.466807, Val Loss 0.563160, Train Acc 80%, Val Acc 73%]\n",
            "Iter 1840. [Train Loss 0.560097, Val Loss 0.561311, Train Acc 75%, Val Acc 73%]\n",
            "Iter 1850. [Train Loss 0.583563, Val Loss 0.563085, Train Acc 76%, Val Acc 73%]\n",
            "Iter 1860. [Train Loss 0.523283, Val Loss 0.562631, Train Acc 79%, Val Acc 73%]\n",
            "Iter 1870. [Train Loss 0.473770, Val Loss 0.563788, Train Acc 80%, Val Acc 73%]\n",
            "Iter 1880. [Train Loss 0.488842, Val Loss 0.563933, Train Acc 77%, Val Acc 73%]\n",
            "Iter 1890. [Train Loss 0.501240, Val Loss 0.561504, Train Acc 74%, Val Acc 73%]\n",
            "Iter 1900. [Train Loss 0.669621, Val Loss 0.562384, Train Acc 57%, Val Acc 73%]\n",
            "Iter 1910. [Train Loss 0.574406, Val Loss 0.563270, Train Acc 74%, Val Acc 73%]\n",
            "Iter 1920. [Train Loss 0.517028, Val Loss 0.560759, Train Acc 78%, Val Acc 73%]\n",
            "Iter 1930. [Train Loss 0.621618, Val Loss 0.564272, Train Acc 67%, Val Acc 73%]\n",
            "Iter 1940. [Train Loss 0.586896, Val Loss 0.563122, Train Acc 68%, Val Acc 73%]\n",
            "Iter 1950. [Train Loss 0.555615, Val Loss 0.561708, Train Acc 71%, Val Acc 73%]\n",
            "Iter 1960. [Train Loss 0.561858, Val Loss 0.563156, Train Acc 74%, Val Acc 73%]\n",
            "Iter 1970. [Train Loss 0.549374, Val Loss 0.561469, Train Acc 68%, Val Acc 73%]\n",
            "Iter 1980. [Train Loss 0.663110, Val Loss 0.561166, Train Acc 62%, Val Acc 73%]\n",
            "Iter 1990. [Train Loss 0.536505, Val Loss 0.561072, Train Acc 79%, Val Acc 73%]\n",
            "Iter 2000. [Train Loss 0.578056, Val Loss 0.564879, Train Acc 69%, Val Acc 73%]\n",
            "Iter 2010. [Train Loss 0.578969, Val Loss 0.564779, Train Acc 68%, Val Acc 73%]\n",
            "Iter 2020. [Train Loss 0.565779, Val Loss 0.565005, Train Acc 70%, Val Acc 73%]\n",
            "Iter 2030. [Train Loss 0.513469, Val Loss 0.563277, Train Acc 76%, Val Acc 73%]\n",
            "Iter 2040. [Train Loss 0.546364, Val Loss 0.563512, Train Acc 78%, Val Acc 73%]\n",
            "Iter 2050. [Train Loss 0.515601, Val Loss 0.564521, Train Acc 77%, Val Acc 73%]\n",
            "Iter 2060. [Train Loss 0.573597, Val Loss 0.565713, Train Acc 69%, Val Acc 73%]\n",
            "Iter 2070. [Train Loss 0.483500, Val Loss 0.560924, Train Acc 79%, Val Acc 73%]\n",
            "Iter 2080. [Train Loss 0.516077, Val Loss 0.563034, Train Acc 81%, Val Acc 73%]\n",
            "Iter 2090. [Train Loss 0.630461, Val Loss 0.562923, Train Acc 70%, Val Acc 73%]\n",
            "Iter 2100. [Train Loss 0.526344, Val Loss 0.562703, Train Acc 76%, Val Acc 73%]\n",
            "Iter 2110. [Train Loss 0.692383, Val Loss 0.563680, Train Acc 63%, Val Acc 73%]\n",
            "Iter 2120. [Train Loss 0.584226, Val Loss 0.560762, Train Acc 63%, Val Acc 73%]\n",
            "Iter 2130. [Train Loss 0.532189, Val Loss 0.562520, Train Acc 76%, Val Acc 73%]\n",
            "Iter 2140. [Train Loss 0.494407, Val Loss 0.563708, Train Acc 82%, Val Acc 73%]\n",
            "Iter 2150. [Train Loss 0.545909, Val Loss 0.564773, Train Acc 74%, Val Acc 73%]\n",
            "Iter 2160. [Train Loss 0.684818, Val Loss 0.569440, Train Acc 65%, Val Acc 72%]\n",
            "Iter 2170. [Train Loss 0.495867, Val Loss 0.564538, Train Acc 76%, Val Acc 73%]\n",
            "Iter 2180. [Train Loss 0.484529, Val Loss 0.563905, Train Acc 82%, Val Acc 73%]\n",
            "Iter 2190. [Train Loss 0.625828, Val Loss 0.564502, Train Acc 73%, Val Acc 73%]\n",
            "Iter 2200. [Train Loss 0.535206, Val Loss 0.566647, Train Acc 75%, Val Acc 73%]\n",
            "Iter 2210. [Train Loss 0.690621, Val Loss 0.564335, Train Acc 64%, Val Acc 73%]\n",
            "Iter 2220. [Train Loss 0.502816, Val Loss 0.563757, Train Acc 75%, Val Acc 73%]\n",
            "Iter 2230. [Train Loss 0.533589, Val Loss 0.562930, Train Acc 72%, Val Acc 73%]\n",
            "Iter 2240. [Train Loss 0.608344, Val Loss 0.562678, Train Acc 71%, Val Acc 73%]\n",
            "Iter 2250. [Train Loss 0.560479, Val Loss 0.563422, Train Acc 65%, Val Acc 73%]\n",
            "Iter 2260. [Train Loss 0.580490, Val Loss 0.562594, Train Acc 65%, Val Acc 73%]\n",
            "Iter 2270. [Train Loss 0.618226, Val Loss 0.564386, Train Acc 67%, Val Acc 73%]\n",
            "Iter 2280. [Train Loss 0.569492, Val Loss 0.561673, Train Acc 77%, Val Acc 73%]\n",
            "Iter 2290. [Train Loss 0.512374, Val Loss 0.561794, Train Acc 76%, Val Acc 73%]\n",
            "Iter 2300. [Train Loss 0.478781, Val Loss 0.561830, Train Acc 75%, Val Acc 73%]\n",
            "Iter 2310. [Train Loss 0.628587, Val Loss 0.562095, Train Acc 70%, Val Acc 73%]\n",
            "Iter 2320. [Train Loss 0.538649, Val Loss 0.562748, Train Acc 73%, Val Acc 73%]\n",
            "Iter 2330. [Train Loss 0.537588, Val Loss 0.564625, Train Acc 80%, Val Acc 73%]\n",
            "Iter 2340. [Train Loss 0.476636, Val Loss 0.563901, Train Acc 81%, Val Acc 73%]\n",
            "Iter 2350. [Train Loss 0.576322, Val Loss 0.561368, Train Acc 73%, Val Acc 73%]\n",
            "Iter 2360. [Train Loss 0.603970, Val Loss 0.561656, Train Acc 69%, Val Acc 73%]\n",
            "Iter 2370. [Train Loss 0.461869, Val Loss 0.563072, Train Acc 77%, Val Acc 73%]\n",
            "Iter 2380. [Train Loss 0.698375, Val Loss 0.562419, Train Acc 68%, Val Acc 73%]\n",
            "Iter 2390. [Train Loss 0.532804, Val Loss 0.562354, Train Acc 76%, Val Acc 73%]\n",
            "Iter 2400. [Train Loss 0.532681, Val Loss 0.562264, Train Acc 75%, Val Acc 73%]\n",
            "Iter 2410. [Train Loss 0.488669, Val Loss 0.565235, Train Acc 78%, Val Acc 73%]\n",
            "Iter 2420. [Train Loss 0.565627, Val Loss 0.565169, Train Acc 72%, Val Acc 73%]\n",
            "Iter 2430. [Train Loss 0.520518, Val Loss 0.563820, Train Acc 74%, Val Acc 73%]\n",
            "Iter 2440. [Train Loss 0.565523, Val Loss 0.561077, Train Acc 72%, Val Acc 73%]\n",
            "Iter 2450. [Train Loss 0.565537, Val Loss 0.561325, Train Acc 70%, Val Acc 73%]\n",
            "Iter 2460. [Train Loss 0.562201, Val Loss 0.563195, Train Acc 77%, Val Acc 73%]\n",
            "Iter 2470. [Train Loss 0.561075, Val Loss 0.561833, Train Acc 71%, Val Acc 73%]\n",
            "Iter 2480. [Train Loss 0.514807, Val Loss 0.561789, Train Acc 74%, Val Acc 73%]\n",
            "Iter 2490. [Train Loss 0.579597, Val Loss 0.560663, Train Acc 70%, Val Acc 73%]\n",
            "Iter 2500. [Train Loss 0.530423, Val Loss 0.560979, Train Acc 80%, Val Acc 73%]\n",
            "Iter 2510. [Train Loss 0.563882, Val Loss 0.560424, Train Acc 72%, Val Acc 73%]\n",
            "Iter 2520. [Train Loss 0.558102, Val Loss 0.560730, Train Acc 72%, Val Acc 73%]\n",
            "Iter 2530. [Train Loss 0.481315, Val Loss 0.563317, Train Acc 75%, Val Acc 73%]\n",
            "Iter 2540. [Train Loss 0.526163, Val Loss 0.562402, Train Acc 78%, Val Acc 73%]\n",
            "Iter 2550. [Train Loss 0.593539, Val Loss 0.562975, Train Acc 72%, Val Acc 73%]\n",
            "Iter 2560. [Train Loss 0.608404, Val Loss 0.562371, Train Acc 68%, Val Acc 73%]\n",
            "Iter 2570. [Train Loss 0.554780, Val Loss 0.561136, Train Acc 80%, Val Acc 73%]\n",
            "Iter 2580. [Train Loss 0.548619, Val Loss 0.563257, Train Acc 81%, Val Acc 73%]\n",
            "Iter 2590. [Train Loss 0.568392, Val Loss 0.566273, Train Acc 75%, Val Acc 73%]\n",
            "Iter 2600. [Train Loss 0.627075, Val Loss 0.562362, Train Acc 70%, Val Acc 73%]\n",
            "Iter 2610. [Train Loss 0.524290, Val Loss 0.563011, Train Acc 77%, Val Acc 73%]\n",
            "Iter 2620. [Train Loss 0.486219, Val Loss 0.561488, Train Acc 72%, Val Acc 73%]\n",
            "Iter 2630. [Train Loss 0.578278, Val Loss 0.563332, Train Acc 72%, Val Acc 73%]\n",
            "Iter 2640. [Train Loss 0.498091, Val Loss 0.562646, Train Acc 78%, Val Acc 73%]\n",
            "Iter 2650. [Train Loss 0.506353, Val Loss 0.564319, Train Acc 74%, Val Acc 73%]\n",
            "Iter 2660. [Train Loss 0.563351, Val Loss 0.563007, Train Acc 74%, Val Acc 73%]\n",
            "Iter 2670. [Train Loss 0.525604, Val Loss 0.563603, Train Acc 76%, Val Acc 73%]\n",
            "Iter 2680. [Train Loss 0.497467, Val Loss 0.565941, Train Acc 77%, Val Acc 73%]\n",
            "Iter 2690. [Train Loss 0.599366, Val Loss 0.562305, Train Acc 68%, Val Acc 73%]\n",
            "Iter 2700. [Train Loss 0.491329, Val Loss 0.562117, Train Acc 80%, Val Acc 73%]\n",
            "Iter 2710. [Train Loss 0.659177, Val Loss 0.561542, Train Acc 61%, Val Acc 73%]\n",
            "Iter 2720. [Train Loss 0.610821, Val Loss 0.568204, Train Acc 72%, Val Acc 72%]\n",
            "Iter 2730. [Train Loss 0.620127, Val Loss 0.561801, Train Acc 72%, Val Acc 73%]\n",
            "Iter 2740. [Train Loss 0.574486, Val Loss 0.561910, Train Acc 72%, Val Acc 73%]\n",
            "Iter 2750. [Train Loss 0.529748, Val Loss 0.562903, Train Acc 75%, Val Acc 73%]\n",
            "Iter 2760. [Train Loss 0.564289, Val Loss 0.562913, Train Acc 73%, Val Acc 73%]\n",
            "Iter 2770. [Train Loss 0.557468, Val Loss 0.564108, Train Acc 69%, Val Acc 73%]\n",
            "Iter 2780. [Train Loss 0.666545, Val Loss 0.563470, Train Acc 71%, Val Acc 73%]\n",
            "Iter 2790. [Train Loss 0.467497, Val Loss 0.562597, Train Acc 79%, Val Acc 73%]\n",
            "Iter 2800. [Train Loss 0.524504, Val Loss 0.563456, Train Acc 76%, Val Acc 73%]\n",
            "Iter 2810. [Train Loss 0.533043, Val Loss 0.563571, Train Acc 75%, Val Acc 73%]\n",
            "Iter 2820. [Train Loss 0.548087, Val Loss 0.562300, Train Acc 80%, Val Acc 73%]\n",
            "Iter 2830. [Train Loss 0.508816, Val Loss 0.563142, Train Acc 79%, Val Acc 73%]\n",
            "Iter 2840. [Train Loss 0.453878, Val Loss 0.563342, Train Acc 86%, Val Acc 73%]\n",
            "Iter 2850. [Train Loss 0.495202, Val Loss 0.561830, Train Acc 74%, Val Acc 73%]\n",
            "Iter 2860. [Train Loss 0.531269, Val Loss 0.561340, Train Acc 78%, Val Acc 73%]\n",
            "Iter 2870. [Train Loss 0.485558, Val Loss 0.562852, Train Acc 74%, Val Acc 73%]\n",
            "Iter 2880. [Train Loss 0.554052, Val Loss 0.561690, Train Acc 73%, Val Acc 73%]\n",
            "Iter 2890. [Train Loss 0.602314, Val Loss 0.560806, Train Acc 73%, Val Acc 73%]\n",
            "Iter 2900. [Train Loss 0.575032, Val Loss 0.561425, Train Acc 73%, Val Acc 73%]\n",
            "Iter 2910. [Train Loss 0.513361, Val Loss 0.563734, Train Acc 75%, Val Acc 73%]\n",
            "Iter 2920. [Train Loss 0.510044, Val Loss 0.562136, Train Acc 79%, Val Acc 73%]\n",
            "Iter 2930. [Train Loss 0.538768, Val Loss 0.560969, Train Acc 77%, Val Acc 73%]\n",
            "Iter 2940. [Train Loss 0.578278, Val Loss 0.562505, Train Acc 70%, Val Acc 73%]\n",
            "Iter 2950. [Train Loss 0.556444, Val Loss 0.561674, Train Acc 72%, Val Acc 73%]\n",
            "Iter 2960. [Train Loss 0.548663, Val Loss 0.560347, Train Acc 71%, Val Acc 73%]\n",
            "Iter 2970. [Train Loss 0.534148, Val Loss 0.564119, Train Acc 72%, Val Acc 73%]\n",
            "Iter 2980. [Train Loss 0.567936, Val Loss 0.561375, Train Acc 70%, Val Acc 73%]\n",
            "Iter 2990. [Train Loss 0.489901, Val Loss 0.561559, Train Acc 81%, Val Acc 73%]\n",
            "Iter 3000. [Train Loss 0.583464, Val Loss 0.562367, Train Acc 71%, Val Acc 73%]\n",
            "Iter 3010. [Train Loss 0.522180, Val Loss 0.564313, Train Acc 77%, Val Acc 73%]\n",
            "Iter 3020. [Train Loss 0.567210, Val Loss 0.562639, Train Acc 72%, Val Acc 73%]\n",
            "Iter 3030. [Train Loss 0.518322, Val Loss 0.562593, Train Acc 73%, Val Acc 73%]\n",
            "Iter 3040. [Train Loss 0.625109, Val Loss 0.560614, Train Acc 69%, Val Acc 73%]\n",
            "Iter 3050. [Train Loss 0.598296, Val Loss 0.561877, Train Acc 69%, Val Acc 73%]\n",
            "Iter 3060. [Train Loss 0.491226, Val Loss 0.561838, Train Acc 81%, Val Acc 73%]\n",
            "Iter 3070. [Train Loss 0.523490, Val Loss 0.560778, Train Acc 75%, Val Acc 73%]\n",
            "Iter 3080. [Train Loss 0.507994, Val Loss 0.561467, Train Acc 75%, Val Acc 73%]\n",
            "Iter 3090. [Train Loss 0.566063, Val Loss 0.560998, Train Acc 68%, Val Acc 73%]\n",
            "Iter 3100. [Train Loss 0.540116, Val Loss 0.561252, Train Acc 71%, Val Acc 73%]\n",
            "Iter 3110. [Train Loss 0.536507, Val Loss 0.560549, Train Acc 74%, Val Acc 73%]\n",
            "Iter 3120. [Train Loss 0.590722, Val Loss 0.562567, Train Acc 75%, Val Acc 73%]\n",
            "Iter 3130. [Train Loss 0.452654, Val Loss 0.559475, Train Acc 80%, Val Acc 73%]\n",
            "Iter 3140. [Train Loss 0.553759, Val Loss 0.559576, Train Acc 73%, Val Acc 73%]\n",
            "Iter 3150. [Train Loss 0.506620, Val Loss 0.560792, Train Acc 77%, Val Acc 73%]\n",
            "Iter 3160. [Train Loss 0.466594, Val Loss 0.560539, Train Acc 79%, Val Acc 73%]\n",
            "Iter 3170. [Train Loss 0.470784, Val Loss 0.560642, Train Acc 79%, Val Acc 73%]\n",
            "Iter 3180. [Train Loss 0.517407, Val Loss 0.561059, Train Acc 73%, Val Acc 73%]\n",
            "Iter 3190. [Train Loss 0.551082, Val Loss 0.563691, Train Acc 74%, Val Acc 73%]\n",
            "Iter 3200. [Train Loss 0.470879, Val Loss 0.561591, Train Acc 80%, Val Acc 73%]\n",
            "Iter 3210. [Train Loss 0.554450, Val Loss 0.562609, Train Acc 79%, Val Acc 73%]\n",
            "Iter 3220. [Train Loss 0.524785, Val Loss 0.560863, Train Acc 74%, Val Acc 73%]\n",
            "Iter 3230. [Train Loss 0.527556, Val Loss 0.561929, Train Acc 75%, Val Acc 73%]\n",
            "Iter 3240. [Train Loss 0.519332, Val Loss 0.562201, Train Acc 72%, Val Acc 73%]\n",
            "Iter 3250. [Train Loss 0.491550, Val Loss 0.561030, Train Acc 77%, Val Acc 73%]\n",
            "Iter 3260. [Train Loss 0.562358, Val Loss 0.560668, Train Acc 76%, Val Acc 73%]\n",
            "Iter 3270. [Train Loss 0.589652, Val Loss 0.561904, Train Acc 70%, Val Acc 73%]\n",
            "Iter 3280. [Train Loss 0.495074, Val Loss 0.562232, Train Acc 79%, Val Acc 73%]\n",
            "Iter 3290. [Train Loss 0.484016, Val Loss 0.564946, Train Acc 79%, Val Acc 73%]\n",
            "Iter 3300. [Train Loss 0.590640, Val Loss 0.563019, Train Acc 74%, Val Acc 73%]\n",
            "Iter 3310. [Train Loss 0.598541, Val Loss 0.561576, Train Acc 69%, Val Acc 73%]\n",
            "Iter 3320. [Train Loss 0.563375, Val Loss 0.563572, Train Acc 71%, Val Acc 73%]\n",
            "Iter 3330. [Train Loss 0.548281, Val Loss 0.562306, Train Acc 72%, Val Acc 73%]\n",
            "Iter 3340. [Train Loss 0.477671, Val Loss 0.561974, Train Acc 78%, Val Acc 73%]\n",
            "Iter 3350. [Train Loss 0.525479, Val Loss 0.559880, Train Acc 75%, Val Acc 73%]\n",
            "Iter 3360. [Train Loss 0.539365, Val Loss 0.562080, Train Acc 75%, Val Acc 73%]\n",
            "Iter 3370. [Train Loss 0.591435, Val Loss 0.560355, Train Acc 63%, Val Acc 73%]\n",
            "Iter 3380. [Train Loss 0.557486, Val Loss 0.560533, Train Acc 74%, Val Acc 73%]\n",
            "Iter 3390. [Train Loss 0.622902, Val Loss 0.559911, Train Acc 76%, Val Acc 73%]\n",
            "Iter 3400. [Train Loss 0.573596, Val Loss 0.559786, Train Acc 71%, Val Acc 73%]\n",
            "Iter 3410. [Train Loss 0.504583, Val Loss 0.562141, Train Acc 76%, Val Acc 73%]\n",
            "Iter 3420. [Train Loss 0.475505, Val Loss 0.560167, Train Acc 77%, Val Acc 73%]\n",
            "Iter 3430. [Train Loss 0.473522, Val Loss 0.562079, Train Acc 78%, Val Acc 73%]\n",
            "Iter 3440. [Train Loss 0.567900, Val Loss 0.561381, Train Acc 77%, Val Acc 73%]\n",
            "Iter 3450. [Train Loss 0.518791, Val Loss 0.561378, Train Acc 74%, Val Acc 73%]\n",
            "Iter 3460. [Train Loss 0.556498, Val Loss 0.564296, Train Acc 73%, Val Acc 73%]\n",
            "Iter 3470. [Train Loss 0.597818, Val Loss 0.567018, Train Acc 73%, Val Acc 73%]\n",
            "Iter 3480. [Train Loss 0.602557, Val Loss 0.564643, Train Acc 75%, Val Acc 73%]\n",
            "Iter 3490. [Train Loss 0.544738, Val Loss 0.562222, Train Acc 71%, Val Acc 73%]\n",
            "Iter 3500. [Train Loss 0.595936, Val Loss 0.564357, Train Acc 67%, Val Acc 73%]\n",
            "Iter 3510. [Train Loss 0.566624, Val Loss 0.563345, Train Acc 73%, Val Acc 73%]\n",
            "Iter 3520. [Train Loss 0.584232, Val Loss 0.562775, Train Acc 68%, Val Acc 73%]\n",
            "Iter 3530. [Train Loss 0.506109, Val Loss 0.563200, Train Acc 76%, Val Acc 73%]\n",
            "Iter 3540. [Train Loss 0.506187, Val Loss 0.562683, Train Acc 79%, Val Acc 73%]\n",
            "Iter 3550. [Train Loss 0.563749, Val Loss 0.561817, Train Acc 68%, Val Acc 73%]\n",
            "Iter 3560. [Train Loss 0.557836, Val Loss 0.561132, Train Acc 68%, Val Acc 73%]\n",
            "Iter 3570. [Train Loss 0.528675, Val Loss 0.561008, Train Acc 72%, Val Acc 73%]\n",
            "Iter 3580. [Train Loss 0.552253, Val Loss 0.562532, Train Acc 77%, Val Acc 73%]\n",
            "Iter 3590. [Train Loss 0.521209, Val Loss 0.569066, Train Acc 79%, Val Acc 72%]\n",
            "Iter 3600. [Train Loss 0.489872, Val Loss 0.565103, Train Acc 83%, Val Acc 73%]\n",
            "Iter 3610. [Train Loss 0.697951, Val Loss 0.563600, Train Acc 68%, Val Acc 73%]\n",
            "Iter 3620. [Train Loss 0.472423, Val Loss 0.559878, Train Acc 81%, Val Acc 73%]\n",
            "Iter 3630. [Train Loss 0.623747, Val Loss 0.565012, Train Acc 75%, Val Acc 73%]\n",
            "Iter 3640. [Train Loss 0.477529, Val Loss 0.561811, Train Acc 76%, Val Acc 73%]\n",
            "Iter 3650. [Train Loss 0.650211, Val Loss 0.562992, Train Acc 69%, Val Acc 73%]\n",
            "Iter 3660. [Train Loss 0.609690, Val Loss 0.561591, Train Acc 77%, Val Acc 73%]\n",
            "Iter 3670. [Train Loss 0.562123, Val Loss 0.562511, Train Acc 72%, Val Acc 73%]\n",
            "Iter 3680. [Train Loss 0.543058, Val Loss 0.559754, Train Acc 69%, Val Acc 73%]\n",
            "Iter 3690. [Train Loss 0.582730, Val Loss 0.559786, Train Acc 73%, Val Acc 73%]\n",
            "Iter 3700. [Train Loss 0.587564, Val Loss 0.560346, Train Acc 74%, Val Acc 73%]\n",
            "Iter 3710. [Train Loss 0.618707, Val Loss 0.560644, Train Acc 66%, Val Acc 73%]\n",
            "Iter 3720. [Train Loss 0.563068, Val Loss 0.561063, Train Acc 71%, Val Acc 73%]\n",
            "Iter 3730. [Train Loss 0.590669, Val Loss 0.561784, Train Acc 68%, Val Acc 73%]\n",
            "Iter 3740. [Train Loss 0.531277, Val Loss 0.564130, Train Acc 74%, Val Acc 73%]\n",
            "Iter 3750. [Train Loss 0.513575, Val Loss 0.561807, Train Acc 74%, Val Acc 73%]\n",
            "Iter 3760. [Train Loss 0.533715, Val Loss 0.562646, Train Acc 76%, Val Acc 73%]\n",
            "Iter 3770. [Train Loss 0.611745, Val Loss 0.567296, Train Acc 65%, Val Acc 73%]\n",
            "Iter 3780. [Train Loss 0.469038, Val Loss 0.562498, Train Acc 80%, Val Acc 73%]\n",
            "Iter 3790. [Train Loss 0.560993, Val Loss 0.562115, Train Acc 74%, Val Acc 73%]\n",
            "Iter 3800. [Train Loss 0.494800, Val Loss 0.560656, Train Acc 73%, Val Acc 73%]\n",
            "Iter 3810. [Train Loss 0.581970, Val Loss 0.561068, Train Acc 69%, Val Acc 73%]\n",
            "Iter 3820. [Train Loss 0.544256, Val Loss 0.566281, Train Acc 73%, Val Acc 73%]\n",
            "Iter 3830. [Train Loss 0.548006, Val Loss 0.562491, Train Acc 73%, Val Acc 73%]\n",
            "Iter 3840. [Train Loss 0.562956, Val Loss 0.562078, Train Acc 73%, Val Acc 73%]\n",
            "Iter 3850. [Train Loss 0.464003, Val Loss 0.561767, Train Acc 81%, Val Acc 73%]\n",
            "Iter 3860. [Train Loss 0.571897, Val Loss 0.564755, Train Acc 70%, Val Acc 73%]\n",
            "Iter 3870. [Train Loss 0.549328, Val Loss 0.562431, Train Acc 75%, Val Acc 73%]\n",
            "Iter 3880. [Train Loss 0.572697, Val Loss 0.561145, Train Acc 75%, Val Acc 73%]\n",
            "Iter 3890. [Train Loss 0.514757, Val Loss 0.564215, Train Acc 76%, Val Acc 73%]\n",
            "Iter 3900. [Train Loss 0.561112, Val Loss 0.564459, Train Acc 73%, Val Acc 73%]\n",
            "Iter 3910. [Train Loss 0.574937, Val Loss 0.563057, Train Acc 69%, Val Acc 73%]\n",
            "Iter 3920. [Train Loss 0.493286, Val Loss 0.562128, Train Acc 78%, Val Acc 73%]\n",
            "Iter 3930. [Train Loss 0.540519, Val Loss 0.560611, Train Acc 72%, Val Acc 73%]\n",
            "Iter 3940. [Train Loss 0.520263, Val Loss 0.564282, Train Acc 77%, Val Acc 73%]\n",
            "Iter 3950. [Train Loss 0.504933, Val Loss 0.563117, Train Acc 74%, Val Acc 73%]\n",
            "Iter 3960. [Train Loss 0.537753, Val Loss 0.562040, Train Acc 76%, Val Acc 73%]\n",
            "Iter 3970. [Train Loss 0.522843, Val Loss 0.560917, Train Acc 79%, Val Acc 73%]\n",
            "Iter 3980. [Train Loss 0.444942, Val Loss 0.561822, Train Acc 82%, Val Acc 73%]\n",
            "Iter 3990. [Train Loss 0.580472, Val Loss 0.561726, Train Acc 69%, Val Acc 73%]\n",
            "Iter 4000. [Train Loss 0.577709, Val Loss 0.561522, Train Acc 74%, Val Acc 73%]\n",
            "Iter 4010. [Train Loss 0.524495, Val Loss 0.561520, Train Acc 77%, Val Acc 73%]\n",
            "Iter 4020. [Train Loss 0.493253, Val Loss 0.561506, Train Acc 81%, Val Acc 73%]\n",
            "Iter 4030. [Train Loss 0.543031, Val Loss 0.562711, Train Acc 74%, Val Acc 73%]\n",
            "Iter 4040. [Train Loss 0.544312, Val Loss 0.561955, Train Acc 73%, Val Acc 73%]\n",
            "Iter 4050. [Train Loss 0.497891, Val Loss 0.561945, Train Acc 79%, Val Acc 73%]\n",
            "Iter 4060. [Train Loss 0.559544, Val Loss 0.560656, Train Acc 78%, Val Acc 73%]\n",
            "Iter 4070. [Train Loss 0.630572, Val Loss 0.562015, Train Acc 71%, Val Acc 73%]\n",
            "Iter 4080. [Train Loss 0.588103, Val Loss 0.560896, Train Acc 70%, Val Acc 73%]\n",
            "Iter 4090. [Train Loss 0.466190, Val Loss 0.561149, Train Acc 78%, Val Acc 73%]\n",
            "Iter 4100. [Train Loss 0.632558, Val Loss 0.563411, Train Acc 69%, Val Acc 73%]\n",
            "Iter 4110. [Train Loss 0.529989, Val Loss 0.561813, Train Acc 75%, Val Acc 73%]\n",
            "Iter 4120. [Train Loss 0.475239, Val Loss 0.561616, Train Acc 84%, Val Acc 73%]\n",
            "Iter 4130. [Train Loss 0.507237, Val Loss 0.565305, Train Acc 73%, Val Acc 72%]\n",
            "Iter 4140. [Train Loss 0.553690, Val Loss 0.563510, Train Acc 70%, Val Acc 73%]\n",
            "Iter 4150. [Train Loss 0.580549, Val Loss 0.566150, Train Acc 69%, Val Acc 73%]\n",
            "Iter 4160. [Train Loss 0.534937, Val Loss 0.560450, Train Acc 73%, Val Acc 73%]\n",
            "Iter 4170. [Train Loss 0.629594, Val Loss 0.561925, Train Acc 66%, Val Acc 73%]\n",
            "Iter 4180. [Train Loss 0.594862, Val Loss 0.562474, Train Acc 66%, Val Acc 73%]\n",
            "Iter 4190. [Train Loss 0.483665, Val Loss 0.563657, Train Acc 76%, Val Acc 73%]\n",
            "Iter 4200. [Train Loss 0.590324, Val Loss 0.567579, Train Acc 70%, Val Acc 72%]\n",
            "Iter 4210. [Train Loss 0.536769, Val Loss 0.561758, Train Acc 75%, Val Acc 73%]\n",
            "Iter 4220. [Train Loss 0.534256, Val Loss 0.561864, Train Acc 74%, Val Acc 73%]\n",
            "Iter 4230. [Train Loss 0.526000, Val Loss 0.562040, Train Acc 80%, Val Acc 73%]\n",
            "Iter 4240. [Train Loss 0.577767, Val Loss 0.563306, Train Acc 75%, Val Acc 73%]\n",
            "Iter 4250. [Train Loss 0.518887, Val Loss 0.563331, Train Acc 78%, Val Acc 73%]\n",
            "Iter 4260. [Train Loss 0.486782, Val Loss 0.562028, Train Acc 76%, Val Acc 73%]\n",
            "Iter 4270. [Train Loss 0.552586, Val Loss 0.561472, Train Acc 74%, Val Acc 73%]\n",
            "Iter 4280. [Train Loss 0.583633, Val Loss 0.560875, Train Acc 73%, Val Acc 73%]\n",
            "Iter 4290. [Train Loss 0.545610, Val Loss 0.561875, Train Acc 74%, Val Acc 73%]\n",
            "Iter 4300. [Train Loss 0.566524, Val Loss 0.560581, Train Acc 73%, Val Acc 73%]\n",
            "Iter 4310. [Train Loss 0.542329, Val Loss 0.559823, Train Acc 72%, Val Acc 73%]\n",
            "Iter 4320. [Train Loss 0.519137, Val Loss 0.560592, Train Acc 75%, Val Acc 73%]\n",
            "Iter 4330. [Train Loss 0.510462, Val Loss 0.560950, Train Acc 74%, Val Acc 73%]\n",
            "Iter 4340. [Train Loss 0.539615, Val Loss 0.560657, Train Acc 73%, Val Acc 73%]\n",
            "Iter 4350. [Train Loss 0.545984, Val Loss 0.560481, Train Acc 70%, Val Acc 73%]\n",
            "Iter 4360. [Train Loss 0.523333, Val Loss 0.562419, Train Acc 76%, Val Acc 73%]\n",
            "Iter 4370. [Train Loss 0.468518, Val Loss 0.563698, Train Acc 79%, Val Acc 73%]\n",
            "Iter 4380. [Train Loss 0.562754, Val Loss 0.563321, Train Acc 74%, Val Acc 73%]\n",
            "Iter 4390. [Train Loss 0.521602, Val Loss 0.564723, Train Acc 76%, Val Acc 73%]\n",
            "Iter 4400. [Train Loss 0.450468, Val Loss 0.564141, Train Acc 77%, Val Acc 73%]\n",
            "Iter 4410. [Train Loss 0.521465, Val Loss 0.562782, Train Acc 79%, Val Acc 73%]\n",
            "Iter 4420. [Train Loss 0.555828, Val Loss 0.561803, Train Acc 72%, Val Acc 73%]\n",
            "Iter 4430. [Train Loss 0.554877, Val Loss 0.563420, Train Acc 72%, Val Acc 73%]\n",
            "Iter 4440. [Train Loss 0.566901, Val Loss 0.561235, Train Acc 76%, Val Acc 73%]\n",
            "Iter 4450. [Train Loss 0.595657, Val Loss 0.563255, Train Acc 78%, Val Acc 73%]\n",
            "Iter 4460. [Train Loss 0.511174, Val Loss 0.560708, Train Acc 80%, Val Acc 73%]\n",
            "Iter 4470. [Train Loss 0.512099, Val Loss 0.560047, Train Acc 75%, Val Acc 73%]\n",
            "Iter 4480. [Train Loss 0.578263, Val Loss 0.561411, Train Acc 73%, Val Acc 73%]\n",
            "Iter 4490. [Train Loss 0.511839, Val Loss 0.560829, Train Acc 79%, Val Acc 73%]\n",
            "Iter 4500. [Train Loss 0.505062, Val Loss 0.560488, Train Acc 79%, Val Acc 73%]\n",
            "Iter 4510. [Train Loss 0.507930, Val Loss 0.560881, Train Acc 74%, Val Acc 74%]\n",
            "Iter 4520. [Train Loss 0.521394, Val Loss 0.561274, Train Acc 78%, Val Acc 73%]\n",
            "Iter 4530. [Train Loss 0.573685, Val Loss 0.560819, Train Acc 72%, Val Acc 73%]\n",
            "Iter 4540. [Train Loss 0.484097, Val Loss 0.561687, Train Acc 82%, Val Acc 73%]\n",
            "Iter 4550. [Train Loss 0.544544, Val Loss 0.563606, Train Acc 66%, Val Acc 73%]\n",
            "Iter 4560. [Train Loss 0.470969, Val Loss 0.562792, Train Acc 83%, Val Acc 73%]\n",
            "Iter 4570. [Train Loss 0.437552, Val Loss 0.562111, Train Acc 82%, Val Acc 73%]\n",
            "Iter 4580. [Train Loss 0.493082, Val Loss 0.561528, Train Acc 77%, Val Acc 73%]\n",
            "Iter 4590. [Train Loss 0.588407, Val Loss 0.561919, Train Acc 75%, Val Acc 73%]\n",
            "Iter 4600. [Train Loss 0.576642, Val Loss 0.561352, Train Acc 74%, Val Acc 73%]\n",
            "Iter 4610. [Train Loss 0.607324, Val Loss 0.560894, Train Acc 71%, Val Acc 73%]\n",
            "Iter 4620. [Train Loss 0.552352, Val Loss 0.561949, Train Acc 70%, Val Acc 73%]\n",
            "Iter 4630. [Train Loss 0.521698, Val Loss 0.565542, Train Acc 75%, Val Acc 73%]\n",
            "Iter 4640. [Train Loss 0.501648, Val Loss 0.564173, Train Acc 78%, Val Acc 73%]\n",
            "Iter 4650. [Train Loss 0.502592, Val Loss 0.562134, Train Acc 81%, Val Acc 73%]\n",
            "Iter 4660. [Train Loss 0.544260, Val Loss 0.562693, Train Acc 75%, Val Acc 73%]\n",
            "Iter 4670. [Train Loss 0.541263, Val Loss 0.561396, Train Acc 74%, Val Acc 73%]\n",
            "Iter 4680. [Train Loss 0.566884, Val Loss 0.563240, Train Acc 75%, Val Acc 73%]\n",
            "Iter 4690. [Train Loss 0.536095, Val Loss 0.562481, Train Acc 72%, Val Acc 73%]\n",
            "Iter 4700. [Train Loss 0.505513, Val Loss 0.562855, Train Acc 81%, Val Acc 73%]\n",
            "Iter 4710. [Train Loss 0.577604, Val Loss 0.560598, Train Acc 67%, Val Acc 73%]\n",
            "Iter 4720. [Train Loss 0.555154, Val Loss 0.561244, Train Acc 78%, Val Acc 73%]\n",
            "Iter 4730. [Train Loss 0.601036, Val Loss 0.564613, Train Acc 66%, Val Acc 73%]\n",
            "Iter 4740. [Train Loss 0.605308, Val Loss 0.560711, Train Acc 65%, Val Acc 73%]\n",
            "Iter 4750. [Train Loss 0.574842, Val Loss 0.561563, Train Acc 77%, Val Acc 73%]\n",
            "Iter 4760. [Train Loss 0.625415, Val Loss 0.561739, Train Acc 64%, Val Acc 73%]\n",
            "Iter 4770. [Train Loss 0.468802, Val Loss 0.563400, Train Acc 77%, Val Acc 73%]\n",
            "Iter 4780. [Train Loss 0.475639, Val Loss 0.561530, Train Acc 78%, Val Acc 73%]\n",
            "Iter 4790. [Train Loss 0.536001, Val Loss 0.561549, Train Acc 70%, Val Acc 73%]\n",
            "Iter 4800. [Train Loss 0.513277, Val Loss 0.561024, Train Acc 78%, Val Acc 73%]\n",
            "Iter 4810. [Train Loss 0.472445, Val Loss 0.562038, Train Acc 76%, Val Acc 73%]\n",
            "Iter 4820. [Train Loss 0.539167, Val Loss 0.561285, Train Acc 78%, Val Acc 73%]\n",
            "Iter 4830. [Train Loss 0.497538, Val Loss 0.561994, Train Acc 79%, Val Acc 73%]\n",
            "Iter 4840. [Train Loss 0.504630, Val Loss 0.560729, Train Acc 76%, Val Acc 73%]\n",
            "Iter 4850. [Train Loss 0.493045, Val Loss 0.561249, Train Acc 78%, Val Acc 73%]\n",
            "Iter 4860. [Train Loss 0.511916, Val Loss 0.560721, Train Acc 77%, Val Acc 73%]\n",
            "Iter 4870. [Train Loss 0.446209, Val Loss 0.562264, Train Acc 85%, Val Acc 73%]\n",
            "Iter 4880. [Train Loss 0.428203, Val Loss 0.564139, Train Acc 84%, Val Acc 74%]\n",
            "Iter 4890. [Train Loss 0.550847, Val Loss 0.563089, Train Acc 76%, Val Acc 74%]\n",
            "Iter 4900. [Train Loss 0.469483, Val Loss 0.562498, Train Acc 86%, Val Acc 73%]\n",
            "Iter 4910. [Train Loss 0.539056, Val Loss 0.563460, Train Acc 78%, Val Acc 73%]\n",
            "Iter 4920. [Train Loss 0.549743, Val Loss 0.563882, Train Acc 75%, Val Acc 73%]\n",
            "Iter 4930. [Train Loss 0.623155, Val Loss 0.562828, Train Acc 67%, Val Acc 73%]\n",
            "Iter 4940. [Train Loss 0.488629, Val Loss 0.561253, Train Acc 78%, Val Acc 73%]\n",
            "Iter 4950. [Train Loss 0.530110, Val Loss 0.561091, Train Acc 74%, Val Acc 73%]\n",
            "Iter 4960. [Train Loss 0.486026, Val Loss 0.560824, Train Acc 81%, Val Acc 73%]\n",
            "Iter 4970. [Train Loss 0.589281, Val Loss 0.560540, Train Acc 69%, Val Acc 73%]\n",
            "Iter 4980. [Train Loss 0.547019, Val Loss 0.561827, Train Acc 78%, Val Acc 73%]\n",
            "Iter 4990. [Train Loss 0.533157, Val Loss 0.562294, Train Acc 78%, Val Acc 73%]\n",
            "Iter 5000. [Train Loss 0.541930, Val Loss 0.563471, Train Acc 73%, Val Acc 73%]\n",
            "Iter 5010. [Train Loss 0.472757, Val Loss 0.563569, Train Acc 81%, Val Acc 73%]\n",
            "Iter 5020. [Train Loss 0.517525, Val Loss 0.562925, Train Acc 74%, Val Acc 73%]\n",
            "Iter 5030. [Train Loss 0.444599, Val Loss 0.561450, Train Acc 82%, Val Acc 73%]\n",
            "Iter 5040. [Train Loss 0.534803, Val Loss 0.563692, Train Acc 72%, Val Acc 73%]\n",
            "Iter 5050. [Train Loss 0.620729, Val Loss 0.561128, Train Acc 70%, Val Acc 73%]\n",
            "Iter 5060. [Train Loss 0.500715, Val Loss 0.561055, Train Acc 77%, Val Acc 73%]\n",
            "Iter 5070. [Train Loss 0.473341, Val Loss 0.562095, Train Acc 79%, Val Acc 73%]\n",
            "Iter 5080. [Train Loss 0.601587, Val Loss 0.562687, Train Acc 71%, Val Acc 73%]\n",
            "Iter 5090. [Train Loss 0.534787, Val Loss 0.561520, Train Acc 73%, Val Acc 73%]\n",
            "Iter 5100. [Train Loss 0.505731, Val Loss 0.561339, Train Acc 71%, Val Acc 73%]\n",
            "Iter 5110. [Train Loss 0.510234, Val Loss 0.561948, Train Acc 79%, Val Acc 73%]\n",
            "Iter 5120. [Train Loss 0.573434, Val Loss 0.560931, Train Acc 72%, Val Acc 73%]\n",
            "Iter 5130. [Train Loss 0.563348, Val Loss 0.561415, Train Acc 68%, Val Acc 73%]\n",
            "Iter 5140. [Train Loss 0.625602, Val Loss 0.562884, Train Acc 69%, Val Acc 73%]\n",
            "Iter 5150. [Train Loss 0.463024, Val Loss 0.561268, Train Acc 80%, Val Acc 73%]\n",
            "Iter 5160. [Train Loss 0.446679, Val Loss 0.561265, Train Acc 81%, Val Acc 73%]\n",
            "Iter 5170. [Train Loss 0.573241, Val Loss 0.563856, Train Acc 71%, Val Acc 73%]\n",
            "Iter 5180. [Train Loss 0.500066, Val Loss 0.564931, Train Acc 81%, Val Acc 73%]\n",
            "Iter 5190. [Train Loss 0.591382, Val Loss 0.561621, Train Acc 69%, Val Acc 73%]\n",
            "Iter 5200. [Train Loss 0.468544, Val Loss 0.563996, Train Acc 82%, Val Acc 73%]\n",
            "Iter 5210. [Train Loss 0.632915, Val Loss 0.560331, Train Acc 73%, Val Acc 73%]\n",
            "Iter 5220. [Train Loss 0.540388, Val Loss 0.560120, Train Acc 73%, Val Acc 73%]\n",
            "Iter 5230. [Train Loss 0.503448, Val Loss 0.561335, Train Acc 77%, Val Acc 73%]\n",
            "Iter 5240. [Train Loss 0.522893, Val Loss 0.560605, Train Acc 79%, Val Acc 73%]\n",
            "Iter 5250. [Train Loss 0.487751, Val Loss 0.560965, Train Acc 79%, Val Acc 73%]\n",
            "Iter 5260. [Train Loss 0.518550, Val Loss 0.563624, Train Acc 75%, Val Acc 73%]\n",
            "Iter 5270. [Train Loss 0.511456, Val Loss 0.562021, Train Acc 78%, Val Acc 73%]\n",
            "Iter 5280. [Train Loss 0.491674, Val Loss 0.561380, Train Acc 76%, Val Acc 73%]\n",
            "Iter 5290. [Train Loss 0.592339, Val Loss 0.561332, Train Acc 65%, Val Acc 73%]\n",
            "Iter 5300. [Train Loss 0.678286, Val Loss 0.563797, Train Acc 72%, Val Acc 73%]\n",
            "Iter 5310. [Train Loss 0.501495, Val Loss 0.562171, Train Acc 74%, Val Acc 73%]\n",
            "Iter 5320. [Train Loss 0.553730, Val Loss 0.560936, Train Acc 75%, Val Acc 73%]\n",
            "Iter 5330. [Train Loss 0.595060, Val Loss 0.561707, Train Acc 70%, Val Acc 73%]\n",
            "Iter 5340. [Train Loss 0.556670, Val Loss 0.563160, Train Acc 74%, Val Acc 73%]\n",
            "Iter 5350. [Train Loss 0.563203, Val Loss 0.561019, Train Acc 70%, Val Acc 73%]\n",
            "Iter 5360. [Train Loss 0.561928, Val Loss 0.561592, Train Acc 68%, Val Acc 73%]\n",
            "Iter 5370. [Train Loss 0.503735, Val Loss 0.561956, Train Acc 77%, Val Acc 73%]\n",
            "Iter 5380. [Train Loss 0.509842, Val Loss 0.561908, Train Acc 76%, Val Acc 73%]\n",
            "Iter 5390. [Train Loss 0.527174, Val Loss 0.564292, Train Acc 73%, Val Acc 73%]\n",
            "Iter 5400. [Train Loss 0.536345, Val Loss 0.560802, Train Acc 75%, Val Acc 73%]\n",
            "Iter 5410. [Train Loss 0.529560, Val Loss 0.561107, Train Acc 76%, Val Acc 73%]\n",
            "Iter 5420. [Train Loss 0.567799, Val Loss 0.564146, Train Acc 67%, Val Acc 73%]\n",
            "Iter 5430. [Train Loss 0.531563, Val Loss 0.561947, Train Acc 73%, Val Acc 73%]\n",
            "Iter 5440. [Train Loss 0.475246, Val Loss 0.560234, Train Acc 77%, Val Acc 73%]\n",
            "Iter 5450. [Train Loss 0.512790, Val Loss 0.561047, Train Acc 75%, Val Acc 73%]\n",
            "Iter 5460. [Train Loss 0.555856, Val Loss 0.562061, Train Acc 71%, Val Acc 73%]\n",
            "Iter 5470. [Train Loss 0.621401, Val Loss 0.564961, Train Acc 71%, Val Acc 73%]\n",
            "Iter 5480. [Train Loss 0.565402, Val Loss 0.562187, Train Acc 72%, Val Acc 73%]\n",
            "Iter 5490. [Train Loss 0.633099, Val Loss 0.562552, Train Acc 68%, Val Acc 73%]\n",
            "Iter 5500. [Train Loss 0.552494, Val Loss 0.565119, Train Acc 74%, Val Acc 73%]\n",
            "Iter 5510. [Train Loss 0.587251, Val Loss 0.562411, Train Acc 71%, Val Acc 73%]\n",
            "Iter 5520. [Train Loss 0.573407, Val Loss 0.561824, Train Acc 70%, Val Acc 73%]\n",
            "Iter 5530. [Train Loss 0.538554, Val Loss 0.565406, Train Acc 77%, Val Acc 73%]\n",
            "Iter 5540. [Train Loss 0.573338, Val Loss 0.562073, Train Acc 75%, Val Acc 73%]\n",
            "Iter 5550. [Train Loss 0.571574, Val Loss 0.561114, Train Acc 66%, Val Acc 73%]\n",
            "Iter 5560. [Train Loss 0.618934, Val Loss 0.561335, Train Acc 70%, Val Acc 73%]\n",
            "Iter 5570. [Train Loss 0.567557, Val Loss 0.562466, Train Acc 72%, Val Acc 73%]\n",
            "Iter 5580. [Train Loss 0.606757, Val Loss 0.563251, Train Acc 76%, Val Acc 73%]\n",
            "Iter 5590. [Train Loss 0.521081, Val Loss 0.562351, Train Acc 75%, Val Acc 73%]\n",
            "Iter 5600. [Train Loss 0.519179, Val Loss 0.563819, Train Acc 73%, Val Acc 73%]\n",
            "Iter 5610. [Train Loss 0.574309, Val Loss 0.563119, Train Acc 68%, Val Acc 73%]\n",
            "Iter 5620. [Train Loss 0.546504, Val Loss 0.562046, Train Acc 74%, Val Acc 73%]\n",
            "Iter 5630. [Train Loss 0.629417, Val Loss 0.560671, Train Acc 67%, Val Acc 73%]\n",
            "Iter 5640. [Train Loss 0.553048, Val Loss 0.562709, Train Acc 81%, Val Acc 73%]\n",
            "Iter 5650. [Train Loss 0.498666, Val Loss 0.561796, Train Acc 75%, Val Acc 73%]\n",
            "Iter 5660. [Train Loss 0.565928, Val Loss 0.561213, Train Acc 75%, Val Acc 73%]\n",
            "Iter 5670. [Train Loss 0.507333, Val Loss 0.564286, Train Acc 79%, Val Acc 73%]\n",
            "Iter 5680. [Train Loss 0.537661, Val Loss 0.563857, Train Acc 72%, Val Acc 73%]\n",
            "Iter 5690. [Train Loss 0.530512, Val Loss 0.563739, Train Acc 76%, Val Acc 73%]\n",
            "Iter 5700. [Train Loss 0.493393, Val Loss 0.563918, Train Acc 79%, Val Acc 73%]\n",
            "Iter 5710. [Train Loss 0.692645, Val Loss 0.562995, Train Acc 64%, Val Acc 73%]\n",
            "Iter 5720. [Train Loss 0.553377, Val Loss 0.564127, Train Acc 78%, Val Acc 73%]\n",
            "Iter 5730. [Train Loss 0.623856, Val Loss 0.561910, Train Acc 67%, Val Acc 73%]\n",
            "Iter 5740. [Train Loss 0.556755, Val Loss 0.562919, Train Acc 74%, Val Acc 73%]\n",
            "Iter 5750. [Train Loss 0.489739, Val Loss 0.562642, Train Acc 79%, Val Acc 73%]\n",
            "Iter 5760. [Train Loss 0.550080, Val Loss 0.560879, Train Acc 75%, Val Acc 73%]\n",
            "Iter 5770. [Train Loss 0.496011, Val Loss 0.561668, Train Acc 80%, Val Acc 73%]\n",
            "Iter 5780. [Train Loss 0.544328, Val Loss 0.561565, Train Acc 74%, Val Acc 73%]\n",
            "Iter 5790. [Train Loss 0.450882, Val Loss 0.561245, Train Acc 87%, Val Acc 73%]\n",
            "Iter 5800. [Train Loss 0.561011, Val Loss 0.561176, Train Acc 75%, Val Acc 73%]\n",
            "Iter 5810. [Train Loss 0.610470, Val Loss 0.559851, Train Acc 69%, Val Acc 73%]\n",
            "Iter 5820. [Train Loss 0.485125, Val Loss 0.559374, Train Acc 78%, Val Acc 73%]\n",
            "Iter 5830. [Train Loss 0.478848, Val Loss 0.561670, Train Acc 74%, Val Acc 73%]\n",
            "Iter 5840. [Train Loss 0.504290, Val Loss 0.563234, Train Acc 78%, Val Acc 73%]\n",
            "Iter 5850. [Train Loss 0.506874, Val Loss 0.560750, Train Acc 78%, Val Acc 73%]\n",
            "Iter 5860. [Train Loss 0.563479, Val Loss 0.561776, Train Acc 67%, Val Acc 73%]\n",
            "Iter 5870. [Train Loss 0.571235, Val Loss 0.561494, Train Acc 68%, Val Acc 73%]\n",
            "Iter 5880. [Train Loss 0.600008, Val Loss 0.565256, Train Acc 70%, Val Acc 73%]\n",
            "Iter 5890. [Train Loss 0.555665, Val Loss 0.562586, Train Acc 74%, Val Acc 73%]\n",
            "Iter 5900. [Train Loss 0.521680, Val Loss 0.561482, Train Acc 80%, Val Acc 73%]\n",
            "Iter 5910. [Train Loss 0.503046, Val Loss 0.563662, Train Acc 71%, Val Acc 73%]\n",
            "Iter 5920. [Train Loss 0.546986, Val Loss 0.562193, Train Acc 73%, Val Acc 73%]\n",
            "Iter 5930. [Train Loss 0.619612, Val Loss 0.563121, Train Acc 69%, Val Acc 73%]\n",
            "Iter 5940. [Train Loss 0.511676, Val Loss 0.559938, Train Acc 76%, Val Acc 73%]\n",
            "Iter 5950. [Train Loss 0.480644, Val Loss 0.563326, Train Acc 77%, Val Acc 73%]\n",
            "Iter 5960. [Train Loss 0.709156, Val Loss 0.562043, Train Acc 67%, Val Acc 73%]\n",
            "Iter 5970. [Train Loss 0.479261, Val Loss 0.561302, Train Acc 81%, Val Acc 73%]\n",
            "Iter 5980. [Train Loss 0.542715, Val Loss 0.562743, Train Acc 70%, Val Acc 73%]\n",
            "Iter 5990. [Train Loss 0.449885, Val Loss 0.562565, Train Acc 83%, Val Acc 73%]\n",
            "Iter 6000. [Train Loss 0.517543, Val Loss 0.561007, Train Acc 79%, Val Acc 73%]\n",
            "Iter 6010. [Train Loss 0.511537, Val Loss 0.562748, Train Acc 76%, Val Acc 73%]\n",
            "Iter 6020. [Train Loss 0.557530, Val Loss 0.563885, Train Acc 75%, Val Acc 73%]\n",
            "Iter 6030. [Train Loss 0.632677, Val Loss 0.562363, Train Acc 67%, Val Acc 73%]\n",
            "Iter 6040. [Train Loss 0.538829, Val Loss 0.565237, Train Acc 74%, Val Acc 73%]\n",
            "Iter 6050. [Train Loss 0.518012, Val Loss 0.562786, Train Acc 81%, Val Acc 73%]\n",
            "Iter 6060. [Train Loss 0.589804, Val Loss 0.561529, Train Acc 68%, Val Acc 73%]\n",
            "Iter 6070. [Train Loss 0.576983, Val Loss 0.561568, Train Acc 72%, Val Acc 73%]\n",
            "Iter 6080. [Train Loss 0.495432, Val Loss 0.562957, Train Acc 75%, Val Acc 73%]\n",
            "Iter 6090. [Train Loss 0.465378, Val Loss 0.561820, Train Acc 79%, Val Acc 73%]\n",
            "Iter 6100. [Train Loss 0.502600, Val Loss 0.561794, Train Acc 76%, Val Acc 73%]\n",
            "Iter 6110. [Train Loss 0.498817, Val Loss 0.562843, Train Acc 79%, Val Acc 73%]\n",
            "Iter 6120. [Train Loss 0.452688, Val Loss 0.561937, Train Acc 84%, Val Acc 73%]\n",
            "Iter 6130. [Train Loss 0.574336, Val Loss 0.563849, Train Acc 70%, Val Acc 73%]\n",
            "Iter 6140. [Train Loss 0.598727, Val Loss 0.565282, Train Acc 77%, Val Acc 73%]\n",
            "Iter 6150. [Train Loss 0.500816, Val Loss 0.560356, Train Acc 81%, Val Acc 73%]\n",
            "Iter 6160. [Train Loss 0.572942, Val Loss 0.562020, Train Acc 71%, Val Acc 73%]\n",
            "Iter 6170. [Train Loss 0.507664, Val Loss 0.565260, Train Acc 78%, Val Acc 73%]\n",
            "Iter 6180. [Train Loss 0.565886, Val Loss 0.561996, Train Acc 76%, Val Acc 73%]\n",
            "Iter 6190. [Train Loss 0.555131, Val Loss 0.560613, Train Acc 77%, Val Acc 73%]\n",
            "Iter 6200. [Train Loss 0.581586, Val Loss 0.562996, Train Acc 68%, Val Acc 73%]\n",
            "Iter 6210. [Train Loss 0.569716, Val Loss 0.560176, Train Acc 72%, Val Acc 73%]\n",
            "Iter 6220. [Train Loss 0.589862, Val Loss 0.561332, Train Acc 68%, Val Acc 73%]\n",
            "Iter 6230. [Train Loss 0.529082, Val Loss 0.562081, Train Acc 71%, Val Acc 73%]\n",
            "Iter 6240. [Train Loss 0.598575, Val Loss 0.563573, Train Acc 70%, Val Acc 73%]\n",
            "Iter 6250. [Train Loss 0.518373, Val Loss 0.563827, Train Acc 77%, Val Acc 73%]\n",
            "Iter 6260. [Train Loss 0.598584, Val Loss 0.562724, Train Acc 68%, Val Acc 73%]\n",
            "Iter 6270. [Train Loss 0.513901, Val Loss 0.561688, Train Acc 80%, Val Acc 73%]\n",
            "Iter 6280. [Train Loss 0.539811, Val Loss 0.561755, Train Acc 71%, Val Acc 73%]\n",
            "Iter 6290. [Train Loss 0.671561, Val Loss 0.561596, Train Acc 64%, Val Acc 73%]\n",
            "Iter 6300. [Train Loss 0.607451, Val Loss 0.561717, Train Acc 75%, Val Acc 73%]\n",
            "Iter 6310. [Train Loss 0.520375, Val Loss 0.563139, Train Acc 70%, Val Acc 73%]\n",
            "Iter 6320. [Train Loss 0.511069, Val Loss 0.563397, Train Acc 76%, Val Acc 73%]\n",
            "Iter 6330. [Train Loss 0.500540, Val Loss 0.562127, Train Acc 76%, Val Acc 73%]\n",
            "Iter 6340. [Train Loss 0.450236, Val Loss 0.561693, Train Acc 81%, Val Acc 73%]\n",
            "Iter 6350. [Train Loss 0.525700, Val Loss 0.560973, Train Acc 76%, Val Acc 73%]\n",
            "Iter 6360. [Train Loss 0.512891, Val Loss 0.563113, Train Acc 78%, Val Acc 73%]\n",
            "Iter 6370. [Train Loss 0.521668, Val Loss 0.567109, Train Acc 78%, Val Acc 73%]\n",
            "Iter 6380. [Train Loss 0.486442, Val Loss 0.562721, Train Acc 79%, Val Acc 73%]\n",
            "Iter 6390. [Train Loss 0.489907, Val Loss 0.562720, Train Acc 76%, Val Acc 73%]\n",
            "Iter 6400. [Train Loss 0.542975, Val Loss 0.562756, Train Acc 66%, Val Acc 73%]\n",
            "Iter 6410. [Train Loss 0.535174, Val Loss 0.561240, Train Acc 74%, Val Acc 73%]\n",
            "Iter 6420. [Train Loss 0.539962, Val Loss 0.561056, Train Acc 74%, Val Acc 73%]\n",
            "Iter 6430. [Train Loss 0.535464, Val Loss 0.563435, Train Acc 72%, Val Acc 73%]\n",
            "Iter 6440. [Train Loss 0.550103, Val Loss 0.564029, Train Acc 76%, Val Acc 73%]\n",
            "Iter 6450. [Train Loss 0.537441, Val Loss 0.568577, Train Acc 73%, Val Acc 72%]\n",
            "Iter 6460. [Train Loss 0.573173, Val Loss 0.566781, Train Acc 76%, Val Acc 73%]\n",
            "Iter 6470. [Train Loss 0.592239, Val Loss 0.562548, Train Acc 72%, Val Acc 73%]\n",
            "Iter 6480. [Train Loss 0.532246, Val Loss 0.567422, Train Acc 71%, Val Acc 72%]\n",
            "Iter 6490. [Train Loss 0.588339, Val Loss 0.562862, Train Acc 75%, Val Acc 73%]\n",
            "Iter 6500. [Train Loss 0.511417, Val Loss 0.562470, Train Acc 80%, Val Acc 73%]\n",
            "Iter 6510. [Train Loss 0.619253, Val Loss 0.561434, Train Acc 72%, Val Acc 73%]\n",
            "Iter 6520. [Train Loss 0.564896, Val Loss 0.563458, Train Acc 75%, Val Acc 73%]\n",
            "Iter 6530. [Train Loss 0.552595, Val Loss 0.563449, Train Acc 74%, Val Acc 73%]\n",
            "Iter 6540. [Train Loss 0.505777, Val Loss 0.561092, Train Acc 81%, Val Acc 73%]\n",
            "Iter 6550. [Train Loss 0.517696, Val Loss 0.561226, Train Acc 78%, Val Acc 73%]\n",
            "Iter 6560. [Train Loss 0.686079, Val Loss 0.563081, Train Acc 66%, Val Acc 73%]\n",
            "Iter 6570. [Train Loss 0.531337, Val Loss 0.562276, Train Acc 76%, Val Acc 73%]\n",
            "Iter 6580. [Train Loss 0.563668, Val Loss 0.561387, Train Acc 72%, Val Acc 73%]\n",
            "Iter 6590. [Train Loss 0.500547, Val Loss 0.560140, Train Acc 78%, Val Acc 73%]\n",
            "Iter 6600. [Train Loss 0.592999, Val Loss 0.562088, Train Acc 70%, Val Acc 73%]\n",
            "Iter 6610. [Train Loss 0.490450, Val Loss 0.564240, Train Acc 76%, Val Acc 73%]\n",
            "Iter 6620. [Train Loss 0.528428, Val Loss 0.562287, Train Acc 75%, Val Acc 73%]\n",
            "Iter 6630. [Train Loss 0.493925, Val Loss 0.565167, Train Acc 78%, Val Acc 73%]\n",
            "Iter 6640. [Train Loss 0.613096, Val Loss 0.563019, Train Acc 68%, Val Acc 73%]\n",
            "Iter 6650. [Train Loss 0.520858, Val Loss 0.564207, Train Acc 72%, Val Acc 73%]\n",
            "Iter 6660. [Train Loss 0.551174, Val Loss 0.562609, Train Acc 77%, Val Acc 73%]\n",
            "Iter 6670. [Train Loss 0.583982, Val Loss 0.565350, Train Acc 73%, Val Acc 73%]\n",
            "Iter 6680. [Train Loss 0.554736, Val Loss 0.562680, Train Acc 72%, Val Acc 73%]\n",
            "Iter 6690. [Train Loss 0.543351, Val Loss 0.560913, Train Acc 77%, Val Acc 73%]\n",
            "Iter 6700. [Train Loss 0.492627, Val Loss 0.563452, Train Acc 78%, Val Acc 73%]\n",
            "Iter 6710. [Train Loss 0.576522, Val Loss 0.561197, Train Acc 70%, Val Acc 73%]\n",
            "Iter 6720. [Train Loss 0.541706, Val Loss 0.562585, Train Acc 75%, Val Acc 73%]\n",
            "Iter 6730. [Train Loss 0.564532, Val Loss 0.564456, Train Acc 78%, Val Acc 73%]\n",
            "Iter 6740. [Train Loss 0.507639, Val Loss 0.564061, Train Acc 77%, Val Acc 73%]\n",
            "Iter 6750. [Train Loss 0.485509, Val Loss 0.562902, Train Acc 79%, Val Acc 73%]\n",
            "Iter 6760. [Train Loss 0.585816, Val Loss 0.562474, Train Acc 71%, Val Acc 73%]\n",
            "Iter 6770. [Train Loss 0.544952, Val Loss 0.570691, Train Acc 79%, Val Acc 72%]\n",
            "Iter 6780. [Train Loss 0.481232, Val Loss 0.563775, Train Acc 80%, Val Acc 73%]\n",
            "Iter 6790. [Train Loss 0.490533, Val Loss 0.564546, Train Acc 80%, Val Acc 73%]\n",
            "Iter 6800. [Train Loss 0.514570, Val Loss 0.561069, Train Acc 76%, Val Acc 73%]\n",
            "Iter 6810. [Train Loss 0.537109, Val Loss 0.559926, Train Acc 73%, Val Acc 73%]\n",
            "Iter 6820. [Train Loss 0.505221, Val Loss 0.561830, Train Acc 71%, Val Acc 73%]\n",
            "Iter 6830. [Train Loss 0.561334, Val Loss 0.563879, Train Acc 74%, Val Acc 73%]\n",
            "Iter 6840. [Train Loss 0.602326, Val Loss 0.561109, Train Acc 73%, Val Acc 73%]\n",
            "Iter 6850. [Train Loss 0.509943, Val Loss 0.561726, Train Acc 75%, Val Acc 73%]\n",
            "Iter 6860. [Train Loss 0.521511, Val Loss 0.561060, Train Acc 72%, Val Acc 73%]\n",
            "Iter 6870. [Train Loss 0.514749, Val Loss 0.560902, Train Acc 79%, Val Acc 73%]\n",
            "Iter 6880. [Train Loss 0.564728, Val Loss 0.561026, Train Acc 79%, Val Acc 73%]\n",
            "Iter 6890. [Train Loss 0.498809, Val Loss 0.562150, Train Acc 79%, Val Acc 73%]\n",
            "Iter 6900. [Train Loss 0.583240, Val Loss 0.561315, Train Acc 70%, Val Acc 73%]\n",
            "Iter 6910. [Train Loss 0.535891, Val Loss 0.560814, Train Acc 74%, Val Acc 73%]\n",
            "Iter 6920. [Train Loss 0.597655, Val Loss 0.560592, Train Acc 69%, Val Acc 73%]\n",
            "Iter 6930. [Train Loss 0.531793, Val Loss 0.559934, Train Acc 75%, Val Acc 73%]\n",
            "Iter 6940. [Train Loss 0.537057, Val Loss 0.560766, Train Acc 77%, Val Acc 73%]\n",
            "Iter 6950. [Train Loss 0.580136, Val Loss 0.561983, Train Acc 74%, Val Acc 73%]\n",
            "Iter 6960. [Train Loss 0.516224, Val Loss 0.562065, Train Acc 80%, Val Acc 73%]\n",
            "Iter 6970. [Train Loss 0.504875, Val Loss 0.562219, Train Acc 78%, Val Acc 73%]\n",
            "Iter 6980. [Train Loss 0.619636, Val Loss 0.562060, Train Acc 69%, Val Acc 73%]\n",
            "Iter 6990. [Train Loss 0.524611, Val Loss 0.560550, Train Acc 75%, Val Acc 73%]\n",
            "Iter 7000. [Train Loss 0.540489, Val Loss 0.561660, Train Acc 74%, Val Acc 73%]\n",
            "Iter 7010. [Train Loss 0.525598, Val Loss 0.561295, Train Acc 76%, Val Acc 73%]\n",
            "Iter 7020. [Train Loss 0.549174, Val Loss 0.563182, Train Acc 73%, Val Acc 73%]\n",
            "Iter 7030. [Train Loss 0.528237, Val Loss 0.563408, Train Acc 77%, Val Acc 73%]\n",
            "Iter 7040. [Train Loss 0.552429, Val Loss 0.562790, Train Acc 77%, Val Acc 73%]\n",
            "Iter 7050. [Train Loss 0.542451, Val Loss 0.562338, Train Acc 76%, Val Acc 73%]\n",
            "Iter 7060. [Train Loss 0.563430, Val Loss 0.561190, Train Acc 72%, Val Acc 73%]\n",
            "Iter 7070. [Train Loss 0.449102, Val Loss 0.560784, Train Acc 81%, Val Acc 73%]\n",
            "Iter 7080. [Train Loss 0.507968, Val Loss 0.563172, Train Acc 76%, Val Acc 73%]\n",
            "Iter 7090. [Train Loss 0.627396, Val Loss 0.562054, Train Acc 70%, Val Acc 73%]\n",
            "Iter 7100. [Train Loss 0.476339, Val Loss 0.560075, Train Acc 77%, Val Acc 73%]\n",
            "Iter 7110. [Train Loss 0.565753, Val Loss 0.560765, Train Acc 71%, Val Acc 73%]\n",
            "Iter 7120. [Train Loss 0.647605, Val Loss 0.562099, Train Acc 61%, Val Acc 73%]\n",
            "Iter 7130. [Train Loss 0.519466, Val Loss 0.561263, Train Acc 73%, Val Acc 73%]\n",
            "Iter 7140. [Train Loss 0.561165, Val Loss 0.562424, Train Acc 71%, Val Acc 73%]\n",
            "Iter 7150. [Train Loss 0.489406, Val Loss 0.563701, Train Acc 79%, Val Acc 73%]\n",
            "Iter 7160. [Train Loss 0.576082, Val Loss 0.561894, Train Acc 72%, Val Acc 73%]\n",
            "Iter 7170. [Train Loss 0.503600, Val Loss 0.560913, Train Acc 77%, Val Acc 73%]\n",
            "Iter 7180. [Train Loss 0.544058, Val Loss 0.561396, Train Acc 74%, Val Acc 73%]\n",
            "Iter 7190. [Train Loss 0.589820, Val Loss 0.561628, Train Acc 70%, Val Acc 73%]\n",
            "Iter 7200. [Train Loss 0.543573, Val Loss 0.563452, Train Acc 70%, Val Acc 73%]\n",
            "Iter 7210. [Train Loss 0.543912, Val Loss 0.560887, Train Acc 70%, Val Acc 73%]\n",
            "Iter 7220. [Train Loss 0.499979, Val Loss 0.562388, Train Acc 75%, Val Acc 73%]\n",
            "Iter 7230. [Train Loss 0.509848, Val Loss 0.563393, Train Acc 78%, Val Acc 73%]\n",
            "Iter 7240. [Train Loss 0.628746, Val Loss 0.561852, Train Acc 64%, Val Acc 73%]\n",
            "Iter 7250. [Train Loss 0.593678, Val Loss 0.561545, Train Acc 77%, Val Acc 73%]\n",
            "Iter 7260. [Train Loss 0.481152, Val Loss 0.561001, Train Acc 81%, Val Acc 73%]\n",
            "Iter 7270. [Train Loss 0.546096, Val Loss 0.561802, Train Acc 71%, Val Acc 73%]\n",
            "Iter 7280. [Train Loss 0.595634, Val Loss 0.560590, Train Acc 72%, Val Acc 73%]\n",
            "Iter 7290. [Train Loss 0.576939, Val Loss 0.560690, Train Acc 75%, Val Acc 73%]\n",
            "Iter 7300. [Train Loss 0.525633, Val Loss 0.562623, Train Acc 76%, Val Acc 73%]\n",
            "Iter 7310. [Train Loss 0.448007, Val Loss 0.564147, Train Acc 83%, Val Acc 73%]\n",
            "Iter 7320. [Train Loss 0.570006, Val Loss 0.565678, Train Acc 71%, Val Acc 73%]\n",
            "Iter 7330. [Train Loss 0.497807, Val Loss 0.569860, Train Acc 68%, Val Acc 72%]\n",
            "Iter 7340. [Train Loss 0.561682, Val Loss 0.562362, Train Acc 73%, Val Acc 73%]\n",
            "Iter 7350. [Train Loss 0.570804, Val Loss 0.562892, Train Acc 73%, Val Acc 73%]\n",
            "Iter 7360. [Train Loss 0.657912, Val Loss 0.562464, Train Acc 65%, Val Acc 73%]\n",
            "Iter 7370. [Train Loss 0.571598, Val Loss 0.562880, Train Acc 72%, Val Acc 73%]\n",
            "Iter 7380. [Train Loss 0.526838, Val Loss 0.561064, Train Acc 75%, Val Acc 73%]\n",
            "Iter 7390. [Train Loss 0.560016, Val Loss 0.561027, Train Acc 77%, Val Acc 73%]\n",
            "Iter 7400. [Train Loss 0.516646, Val Loss 0.561808, Train Acc 78%, Val Acc 73%]\n",
            "Iter 7410. [Train Loss 0.542751, Val Loss 0.562344, Train Acc 73%, Val Acc 73%]\n",
            "Iter 7420. [Train Loss 0.548606, Val Loss 0.561778, Train Acc 68%, Val Acc 73%]\n",
            "Iter 7430. [Train Loss 0.556351, Val Loss 0.561421, Train Acc 70%, Val Acc 73%]\n",
            "Iter 7440. [Train Loss 0.553384, Val Loss 0.561514, Train Acc 77%, Val Acc 73%]\n",
            "Iter 7450. [Train Loss 0.463129, Val Loss 0.561125, Train Acc 82%, Val Acc 73%]\n",
            "Iter 7460. [Train Loss 0.517425, Val Loss 0.561781, Train Acc 78%, Val Acc 73%]\n",
            "Iter 7470. [Train Loss 0.470969, Val Loss 0.563239, Train Acc 81%, Val Acc 73%]\n",
            "Iter 7480. [Train Loss 0.514961, Val Loss 0.564865, Train Acc 80%, Val Acc 73%]\n",
            "Iter 7490. [Train Loss 0.472904, Val Loss 0.562301, Train Acc 75%, Val Acc 73%]\n",
            "Iter 7500. [Train Loss 0.577010, Val Loss 0.559960, Train Acc 72%, Val Acc 73%]\n",
            "Iter 7510. [Train Loss 0.626490, Val Loss 0.562110, Train Acc 69%, Val Acc 73%]\n",
            "Iter 7520. [Train Loss 0.500075, Val Loss 0.565730, Train Acc 75%, Val Acc 73%]\n",
            "Iter 7530. [Train Loss 0.575086, Val Loss 0.564711, Train Acc 69%, Val Acc 73%]\n",
            "Iter 7540. [Train Loss 0.640241, Val Loss 0.563344, Train Acc 70%, Val Acc 73%]\n",
            "Iter 7550. [Train Loss 0.564440, Val Loss 0.563671, Train Acc 72%, Val Acc 73%]\n",
            "Iter 7560. [Train Loss 0.561744, Val Loss 0.563735, Train Acc 74%, Val Acc 73%]\n",
            "Iter 7570. [Train Loss 0.528836, Val Loss 0.560879, Train Acc 78%, Val Acc 73%]\n",
            "Iter 7580. [Train Loss 0.496893, Val Loss 0.561403, Train Acc 81%, Val Acc 73%]\n",
            "Iter 7590. [Train Loss 0.453631, Val Loss 0.563996, Train Acc 82%, Val Acc 73%]\n",
            "Iter 7600. [Train Loss 0.558913, Val Loss 0.562388, Train Acc 70%, Val Acc 73%]\n",
            "Iter 7610. [Train Loss 0.492282, Val Loss 0.560731, Train Acc 78%, Val Acc 73%]\n",
            "Iter 7620. [Train Loss 0.505102, Val Loss 0.566215, Train Acc 80%, Val Acc 72%]\n",
            "Iter 7630. [Train Loss 0.595916, Val Loss 0.562086, Train Acc 66%, Val Acc 73%]\n",
            "Iter 7640. [Train Loss 0.630815, Val Loss 0.561231, Train Acc 71%, Val Acc 73%]\n",
            "Iter 7650. [Train Loss 0.561436, Val Loss 0.559801, Train Acc 67%, Val Acc 73%]\n",
            "Iter 7660. [Train Loss 0.605930, Val Loss 0.562403, Train Acc 70%, Val Acc 73%]\n",
            "Iter 7670. [Train Loss 0.518672, Val Loss 0.560418, Train Acc 74%, Val Acc 73%]\n",
            "Iter 7680. [Train Loss 0.496822, Val Loss 0.563854, Train Acc 80%, Val Acc 73%]\n",
            "Iter 7690. [Train Loss 0.596179, Val Loss 0.560421, Train Acc 68%, Val Acc 73%]\n",
            "Iter 7700. [Train Loss 0.521731, Val Loss 0.561058, Train Acc 80%, Val Acc 73%]\n",
            "Iter 7710. [Train Loss 0.490999, Val Loss 0.560787, Train Acc 82%, Val Acc 73%]\n",
            "Iter 7720. [Train Loss 0.614614, Val Loss 0.563675, Train Acc 69%, Val Acc 73%]\n",
            "Iter 7730. [Train Loss 0.623892, Val Loss 0.563910, Train Acc 63%, Val Acc 73%]\n",
            "Iter 7740. [Train Loss 0.640247, Val Loss 0.562812, Train Acc 77%, Val Acc 73%]\n",
            "Iter 7750. [Train Loss 0.494909, Val Loss 0.562032, Train Acc 77%, Val Acc 73%]\n",
            "Iter 7760. [Train Loss 0.596049, Val Loss 0.561697, Train Acc 73%, Val Acc 73%]\n",
            "Iter 7770. [Train Loss 0.512155, Val Loss 0.560660, Train Acc 77%, Val Acc 73%]\n",
            "Iter 7780. [Train Loss 0.446232, Val Loss 0.564230, Train Acc 82%, Val Acc 73%]\n",
            "Iter 7790. [Train Loss 0.589029, Val Loss 0.561922, Train Acc 71%, Val Acc 73%]\n",
            "Iter 7800. [Train Loss 0.489705, Val Loss 0.561248, Train Acc 83%, Val Acc 73%]\n",
            "Iter 7810. [Train Loss 0.550956, Val Loss 0.560733, Train Acc 76%, Val Acc 73%]\n",
            "Iter 7820. [Train Loss 0.533303, Val Loss 0.562925, Train Acc 73%, Val Acc 73%]\n",
            "Iter 7830. [Train Loss 0.615254, Val Loss 0.563518, Train Acc 72%, Val Acc 73%]\n",
            "Iter 7840. [Train Loss 0.502317, Val Loss 0.564171, Train Acc 79%, Val Acc 73%]\n",
            "Iter 7850. [Train Loss 0.577265, Val Loss 0.561556, Train Acc 69%, Val Acc 73%]\n",
            "Iter 7860. [Train Loss 0.504735, Val Loss 0.561159, Train Acc 80%, Val Acc 73%]\n",
            "Iter 7870. [Train Loss 0.501404, Val Loss 0.562685, Train Acc 76%, Val Acc 73%]\n",
            "Iter 7880. [Train Loss 0.494359, Val Loss 0.561412, Train Acc 81%, Val Acc 73%]\n",
            "Iter 7890. [Train Loss 0.551805, Val Loss 0.560923, Train Acc 79%, Val Acc 73%]\n",
            "Iter 7900. [Train Loss 0.522572, Val Loss 0.562505, Train Acc 74%, Val Acc 73%]\n",
            "Iter 7910. [Train Loss 0.482406, Val Loss 0.562360, Train Acc 77%, Val Acc 73%]\n",
            "Iter 7920. [Train Loss 0.607798, Val Loss 0.561471, Train Acc 64%, Val Acc 73%]\n",
            "Iter 7930. [Train Loss 0.496009, Val Loss 0.560308, Train Acc 75%, Val Acc 73%]\n",
            "Iter 7940. [Train Loss 0.539988, Val Loss 0.561621, Train Acc 74%, Val Acc 73%]\n",
            "Iter 7950. [Train Loss 0.564614, Val Loss 0.560830, Train Acc 73%, Val Acc 73%]\n",
            "Iter 7960. [Train Loss 0.475843, Val Loss 0.561006, Train Acc 80%, Val Acc 73%]\n",
            "Iter 7970. [Train Loss 0.571151, Val Loss 0.561054, Train Acc 71%, Val Acc 73%]\n",
            "Iter 7980. [Train Loss 0.531428, Val Loss 0.561546, Train Acc 76%, Val Acc 73%]\n",
            "Iter 7990. [Train Loss 0.483981, Val Loss 0.563417, Train Acc 78%, Val Acc 73%]\n",
            "Iter 8000. [Train Loss 0.549054, Val Loss 0.562690, Train Acc 76%, Val Acc 73%]\n",
            "Iter 8010. [Train Loss 0.565710, Val Loss 0.560073, Train Acc 75%, Val Acc 73%]\n",
            "Iter 8020. [Train Loss 0.522086, Val Loss 0.563193, Train Acc 80%, Val Acc 73%]\n",
            "Iter 8030. [Train Loss 0.552632, Val Loss 0.562782, Train Acc 74%, Val Acc 73%]\n",
            "Iter 8040. [Train Loss 0.560918, Val Loss 0.562180, Train Acc 78%, Val Acc 73%]\n",
            "Iter 8050. [Train Loss 0.485585, Val Loss 0.560314, Train Acc 78%, Val Acc 73%]\n",
            "Iter 8060. [Train Loss 0.612746, Val Loss 0.559714, Train Acc 69%, Val Acc 73%]\n",
            "Iter 8070. [Train Loss 0.630696, Val Loss 0.563416, Train Acc 63%, Val Acc 73%]\n",
            "Iter 8080. [Train Loss 0.527285, Val Loss 0.562583, Train Acc 78%, Val Acc 73%]\n",
            "Iter 8090. [Train Loss 0.515417, Val Loss 0.561837, Train Acc 84%, Val Acc 73%]\n",
            "Iter 8100. [Train Loss 0.557549, Val Loss 0.560844, Train Acc 77%, Val Acc 73%]\n",
            "Iter 8110. [Train Loss 0.584966, Val Loss 0.569007, Train Acc 67%, Val Acc 73%]\n",
            "Iter 8120. [Train Loss 0.590296, Val Loss 0.563943, Train Acc 70%, Val Acc 73%]\n",
            "Iter 8130. [Train Loss 0.452951, Val Loss 0.562537, Train Acc 80%, Val Acc 73%]\n",
            "Iter 8140. [Train Loss 0.531424, Val Loss 0.563741, Train Acc 75%, Val Acc 73%]\n",
            "Iter 8150. [Train Loss 0.536065, Val Loss 0.564607, Train Acc 73%, Val Acc 73%]\n",
            "Iter 8160. [Train Loss 0.517769, Val Loss 0.561790, Train Acc 80%, Val Acc 73%]\n",
            "Iter 8170. [Train Loss 0.642687, Val Loss 0.561631, Train Acc 70%, Val Acc 73%]\n",
            "Iter 8180. [Train Loss 0.496170, Val Loss 0.560123, Train Acc 80%, Val Acc 73%]\n",
            "Iter 8190. [Train Loss 0.542464, Val Loss 0.559519, Train Acc 80%, Val Acc 73%]\n",
            "Iter 8200. [Train Loss 0.642433, Val Loss 0.560716, Train Acc 70%, Val Acc 73%]\n",
            "Iter 8210. [Train Loss 0.469392, Val Loss 0.561933, Train Acc 81%, Val Acc 73%]\n",
            "Iter 8220. [Train Loss 0.638906, Val Loss 0.564889, Train Acc 72%, Val Acc 73%]\n",
            "Iter 8230. [Train Loss 0.561962, Val Loss 0.562149, Train Acc 79%, Val Acc 73%]\n",
            "Iter 8240. [Train Loss 0.523052, Val Loss 0.563877, Train Acc 74%, Val Acc 73%]\n",
            "Iter 8250. [Train Loss 0.535492, Val Loss 0.562776, Train Acc 76%, Val Acc 73%]\n",
            "Iter 8260. [Train Loss 0.567897, Val Loss 0.565733, Train Acc 70%, Val Acc 73%]\n",
            "Iter 8270. [Train Loss 0.537373, Val Loss 0.561749, Train Acc 74%, Val Acc 73%]\n",
            "Iter 8280. [Train Loss 0.453886, Val Loss 0.561408, Train Acc 83%, Val Acc 73%]\n",
            "Iter 8290. [Train Loss 0.504834, Val Loss 0.563513, Train Acc 73%, Val Acc 73%]\n",
            "Iter 8300. [Train Loss 0.525355, Val Loss 0.561780, Train Acc 75%, Val Acc 73%]\n",
            "Iter 8310. [Train Loss 0.527933, Val Loss 0.560460, Train Acc 73%, Val Acc 73%]\n",
            "Iter 8320. [Train Loss 0.575251, Val Loss 0.561772, Train Acc 71%, Val Acc 73%]\n",
            "Iter 8330. [Train Loss 0.585185, Val Loss 0.559859, Train Acc 72%, Val Acc 73%]\n",
            "Iter 8340. [Train Loss 0.554180, Val Loss 0.560247, Train Acc 73%, Val Acc 73%]\n",
            "Iter 8350. [Train Loss 0.501279, Val Loss 0.561765, Train Acc 76%, Val Acc 73%]\n",
            "Iter 8360. [Train Loss 0.548065, Val Loss 0.561329, Train Acc 74%, Val Acc 73%]\n",
            "Iter 8370. [Train Loss 0.548044, Val Loss 0.566220, Train Acc 76%, Val Acc 73%]\n",
            "Iter 8380. [Train Loss 0.513524, Val Loss 0.562775, Train Acc 78%, Val Acc 73%]\n",
            "Iter 8390. [Train Loss 0.471785, Val Loss 0.563278, Train Acc 83%, Val Acc 73%]\n",
            "Iter 8400. [Train Loss 0.529806, Val Loss 0.562217, Train Acc 75%, Val Acc 73%]\n",
            "Iter 8410. [Train Loss 0.629257, Val Loss 0.565016, Train Acc 71%, Val Acc 73%]\n",
            "Iter 8420. [Train Loss 0.574565, Val Loss 0.562630, Train Acc 65%, Val Acc 73%]\n",
            "Iter 8430. [Train Loss 0.618123, Val Loss 0.563012, Train Acc 64%, Val Acc 73%]\n",
            "Iter 8440. [Train Loss 0.614517, Val Loss 0.563020, Train Acc 68%, Val Acc 73%]\n",
            "Iter 8450. [Train Loss 0.516364, Val Loss 0.563930, Train Acc 74%, Val Acc 73%]\n",
            "Iter 8460. [Train Loss 0.527568, Val Loss 0.561607, Train Acc 73%, Val Acc 73%]\n",
            "Iter 8470. [Train Loss 0.551082, Val Loss 0.561738, Train Acc 75%, Val Acc 73%]\n",
            "Iter 8480. [Train Loss 0.503047, Val Loss 0.571316, Train Acc 76%, Val Acc 72%]\n",
            "Iter 8490. [Train Loss 0.575480, Val Loss 0.563001, Train Acc 74%, Val Acc 73%]\n",
            "Iter 8500. [Train Loss 0.562106, Val Loss 0.561408, Train Acc 70%, Val Acc 73%]\n",
            "Iter 8510. [Train Loss 0.494136, Val Loss 0.560616, Train Acc 80%, Val Acc 73%]\n",
            "Iter 8520. [Train Loss 0.552627, Val Loss 0.562507, Train Acc 77%, Val Acc 73%]\n",
            "Iter 8530. [Train Loss 0.479751, Val Loss 0.561379, Train Acc 80%, Val Acc 73%]\n",
            "Iter 8540. [Train Loss 0.553991, Val Loss 0.561635, Train Acc 75%, Val Acc 73%]\n",
            "Iter 8550. [Train Loss 0.538337, Val Loss 0.561654, Train Acc 69%, Val Acc 73%]\n",
            "Iter 8560. [Train Loss 0.534554, Val Loss 0.563968, Train Acc 75%, Val Acc 73%]\n",
            "Iter 8570. [Train Loss 0.557980, Val Loss 0.563103, Train Acc 75%, Val Acc 73%]\n",
            "Iter 8580. [Train Loss 0.521455, Val Loss 0.567762, Train Acc 78%, Val Acc 73%]\n",
            "Iter 8590. [Train Loss 0.581755, Val Loss 0.562522, Train Acc 71%, Val Acc 73%]\n",
            "Iter 8600. [Train Loss 0.629044, Val Loss 0.561076, Train Acc 70%, Val Acc 73%]\n",
            "Iter 8610. [Train Loss 0.599143, Val Loss 0.561218, Train Acc 75%, Val Acc 73%]\n",
            "Iter 8620. [Train Loss 0.605866, Val Loss 0.561198, Train Acc 69%, Val Acc 73%]\n",
            "Iter 8630. [Train Loss 0.508507, Val Loss 0.561005, Train Acc 77%, Val Acc 73%]\n",
            "Iter 8640. [Train Loss 0.586885, Val Loss 0.561928, Train Acc 71%, Val Acc 73%]\n",
            "Iter 8650. [Train Loss 0.557739, Val Loss 0.562745, Train Acc 77%, Val Acc 73%]\n",
            "Iter 8660. [Train Loss 0.615055, Val Loss 0.563432, Train Acc 64%, Val Acc 73%]\n",
            "Iter 8670. [Train Loss 0.512702, Val Loss 0.562194, Train Acc 78%, Val Acc 73%]\n",
            "Iter 8680. [Train Loss 0.506677, Val Loss 0.565403, Train Acc 76%, Val Acc 73%]\n",
            "Iter 8690. [Train Loss 0.508278, Val Loss 0.562125, Train Acc 80%, Val Acc 73%]\n",
            "Iter 8700. [Train Loss 0.535489, Val Loss 0.563231, Train Acc 76%, Val Acc 73%]\n",
            "Iter 8710. [Train Loss 0.644668, Val Loss 0.564008, Train Acc 70%, Val Acc 73%]\n",
            "Iter 8720. [Train Loss 0.543223, Val Loss 0.561605, Train Acc 73%, Val Acc 73%]\n",
            "Iter 8730. [Train Loss 0.493566, Val Loss 0.563376, Train Acc 79%, Val Acc 73%]\n",
            "Iter 8740. [Train Loss 0.585263, Val Loss 0.561805, Train Acc 73%, Val Acc 73%]\n",
            "Iter 8750. [Train Loss 0.523703, Val Loss 0.561120, Train Acc 77%, Val Acc 73%]\n",
            "Iter 8760. [Train Loss 0.489539, Val Loss 0.565171, Train Acc 73%, Val Acc 73%]\n",
            "Iter 8770. [Train Loss 0.471794, Val Loss 0.561843, Train Acc 78%, Val Acc 73%]\n",
            "Iter 8780. [Train Loss 0.543983, Val Loss 0.561405, Train Acc 71%, Val Acc 73%]\n",
            "Iter 8790. [Train Loss 0.516839, Val Loss 0.561997, Train Acc 74%, Val Acc 73%]\n",
            "Iter 8800. [Train Loss 0.586483, Val Loss 0.562504, Train Acc 67%, Val Acc 73%]\n",
            "Iter 8810. [Train Loss 0.508004, Val Loss 0.562528, Train Acc 81%, Val Acc 73%]\n",
            "Iter 8820. [Train Loss 0.505950, Val Loss 0.561844, Train Acc 80%, Val Acc 73%]\n",
            "Iter 8830. [Train Loss 0.568068, Val Loss 0.560929, Train Acc 71%, Val Acc 73%]\n",
            "Iter 8840. [Train Loss 0.522591, Val Loss 0.562290, Train Acc 75%, Val Acc 73%]\n",
            "Iter 8850. [Train Loss 0.592218, Val Loss 0.560294, Train Acc 74%, Val Acc 73%]\n",
            "Iter 8860. [Train Loss 0.468529, Val Loss 0.565673, Train Acc 76%, Val Acc 72%]\n",
            "Iter 8870. [Train Loss 0.525426, Val Loss 0.564123, Train Acc 77%, Val Acc 72%]\n",
            "Iter 8880. [Train Loss 0.501709, Val Loss 0.561545, Train Acc 78%, Val Acc 73%]\n",
            "Iter 8890. [Train Loss 0.582435, Val Loss 0.561383, Train Acc 71%, Val Acc 73%]\n",
            "Iter 8900. [Train Loss 0.430934, Val Loss 0.561811, Train Acc 84%, Val Acc 73%]\n",
            "Iter 8910. [Train Loss 0.519318, Val Loss 0.561788, Train Acc 77%, Val Acc 73%]\n",
            "Iter 8920. [Train Loss 0.503382, Val Loss 0.561898, Train Acc 76%, Val Acc 73%]\n",
            "Iter 8930. [Train Loss 0.524814, Val Loss 0.561715, Train Acc 73%, Val Acc 73%]\n",
            "Iter 8940. [Train Loss 0.610484, Val Loss 0.562077, Train Acc 73%, Val Acc 73%]\n",
            "Iter 8950. [Train Loss 0.645186, Val Loss 0.562111, Train Acc 73%, Val Acc 73%]\n",
            "Iter 8960. [Train Loss 0.570645, Val Loss 0.562108, Train Acc 73%, Val Acc 73%]\n",
            "Iter 8970. [Train Loss 0.550736, Val Loss 0.561723, Train Acc 70%, Val Acc 73%]\n",
            "Iter 8980. [Train Loss 0.589278, Val Loss 0.563194, Train Acc 72%, Val Acc 73%]\n",
            "Iter 8990. [Train Loss 0.489589, Val Loss 0.564326, Train Acc 79%, Val Acc 73%]\n",
            "Iter 9000. [Train Loss 0.606888, Val Loss 0.561837, Train Acc 75%, Val Acc 73%]\n",
            "Iter 9010. [Train Loss 0.499782, Val Loss 0.561738, Train Acc 76%, Val Acc 73%]\n",
            "Iter 9020. [Train Loss 0.466365, Val Loss 0.563321, Train Acc 81%, Val Acc 73%]\n",
            "Iter 9030. [Train Loss 0.580995, Val Loss 0.561957, Train Acc 74%, Val Acc 73%]\n",
            "Iter 9040. [Train Loss 0.477648, Val Loss 0.563412, Train Acc 79%, Val Acc 73%]\n",
            "Iter 9050. [Train Loss 0.569077, Val Loss 0.562837, Train Acc 76%, Val Acc 73%]\n",
            "Iter 9060. [Train Loss 0.555721, Val Loss 0.561233, Train Acc 75%, Val Acc 73%]\n",
            "Iter 9070. [Train Loss 0.547468, Val Loss 0.561485, Train Acc 76%, Val Acc 73%]\n",
            "Iter 9080. [Train Loss 0.446481, Val Loss 0.564207, Train Acc 80%, Val Acc 73%]\n",
            "Iter 9090. [Train Loss 0.538480, Val Loss 0.562169, Train Acc 72%, Val Acc 73%]\n",
            "Iter 9100. [Train Loss 0.545222, Val Loss 0.562647, Train Acc 75%, Val Acc 73%]\n",
            "Iter 9110. [Train Loss 0.519447, Val Loss 0.561834, Train Acc 75%, Val Acc 73%]\n",
            "Iter 9120. [Train Loss 0.465190, Val Loss 0.561840, Train Acc 79%, Val Acc 73%]\n",
            "Iter 9130. [Train Loss 0.718001, Val Loss 0.562072, Train Acc 67%, Val Acc 73%]\n",
            "Iter 9140. [Train Loss 0.484426, Val Loss 0.561887, Train Acc 76%, Val Acc 73%]\n",
            "Iter 9150. [Train Loss 0.495478, Val Loss 0.562009, Train Acc 76%, Val Acc 73%]\n",
            "Iter 9160. [Train Loss 0.576329, Val Loss 0.561660, Train Acc 68%, Val Acc 73%]\n",
            "Iter 9170. [Train Loss 0.507826, Val Loss 0.562559, Train Acc 77%, Val Acc 73%]\n",
            "Iter 9180. [Train Loss 0.584670, Val Loss 0.561550, Train Acc 67%, Val Acc 73%]\n",
            "Iter 9190. [Train Loss 0.534890, Val Loss 0.560950, Train Acc 72%, Val Acc 73%]\n",
            "Iter 9200. [Train Loss 0.562868, Val Loss 0.562673, Train Acc 68%, Val Acc 73%]\n",
            "Iter 9210. [Train Loss 0.609052, Val Loss 0.561804, Train Acc 68%, Val Acc 73%]\n",
            "Iter 9220. [Train Loss 0.457918, Val Loss 0.562593, Train Acc 81%, Val Acc 73%]\n",
            "Iter 9230. [Train Loss 0.518824, Val Loss 0.561598, Train Acc 79%, Val Acc 73%]\n",
            "Iter 9240. [Train Loss 0.601687, Val Loss 0.565301, Train Acc 68%, Val Acc 73%]\n",
            "Iter 9250. [Train Loss 0.532431, Val Loss 0.562726, Train Acc 76%, Val Acc 73%]\n",
            "Iter 9260. [Train Loss 0.492022, Val Loss 0.562392, Train Acc 73%, Val Acc 73%]\n",
            "Iter 9270. [Train Loss 0.523318, Val Loss 0.561650, Train Acc 75%, Val Acc 73%]\n",
            "Iter 9280. [Train Loss 0.543193, Val Loss 0.561187, Train Acc 74%, Val Acc 73%]\n",
            "Iter 9290. [Train Loss 0.503806, Val Loss 0.563818, Train Acc 75%, Val Acc 73%]\n",
            "Iter 9300. [Train Loss 0.478087, Val Loss 0.562299, Train Acc 75%, Val Acc 73%]\n",
            "Iter 9310. [Train Loss 0.618309, Val Loss 0.561895, Train Acc 67%, Val Acc 73%]\n",
            "Iter 9320. [Train Loss 0.608983, Val Loss 0.561781, Train Acc 71%, Val Acc 73%]\n",
            "Iter 9330. [Train Loss 0.544224, Val Loss 0.561872, Train Acc 70%, Val Acc 73%]\n",
            "Iter 9340. [Train Loss 0.573858, Val Loss 0.564636, Train Acc 71%, Val Acc 73%]\n",
            "Iter 9350. [Train Loss 0.514725, Val Loss 0.563819, Train Acc 72%, Val Acc 73%]\n",
            "Iter 9360. [Train Loss 0.582001, Val Loss 0.563247, Train Acc 73%, Val Acc 73%]\n",
            "Iter 9370. [Train Loss 0.491636, Val Loss 0.563016, Train Acc 83%, Val Acc 73%]\n",
            "Iter 9380. [Train Loss 0.617560, Val Loss 0.563216, Train Acc 66%, Val Acc 73%]\n",
            "Iter 9390. [Train Loss 0.491034, Val Loss 0.562118, Train Acc 77%, Val Acc 73%]\n",
            "Iter 9400. [Train Loss 0.579793, Val Loss 0.563594, Train Acc 71%, Val Acc 73%]\n",
            "Iter 9410. [Train Loss 0.578895, Val Loss 0.562552, Train Acc 74%, Val Acc 73%]\n",
            "Iter 9420. [Train Loss 0.557914, Val Loss 0.562043, Train Acc 81%, Val Acc 73%]\n",
            "Iter 9430. [Train Loss 0.561969, Val Loss 0.561946, Train Acc 69%, Val Acc 73%]\n",
            "Iter 9440. [Train Loss 0.543737, Val Loss 0.569280, Train Acc 75%, Val Acc 72%]\n",
            "Iter 9450. [Train Loss 0.513615, Val Loss 0.563391, Train Acc 74%, Val Acc 73%]\n",
            "Iter 9460. [Train Loss 0.582382, Val Loss 0.561487, Train Acc 73%, Val Acc 73%]\n",
            "Iter 9470. [Train Loss 0.481160, Val Loss 0.560918, Train Acc 77%, Val Acc 73%]\n",
            "Iter 9480. [Train Loss 0.612525, Val Loss 0.561193, Train Acc 67%, Val Acc 73%]\n",
            "Iter 9490. [Train Loss 0.599967, Val Loss 0.564741, Train Acc 71%, Val Acc 73%]\n",
            "Iter 9500. [Train Loss 0.532631, Val Loss 0.563544, Train Acc 72%, Val Acc 73%]\n",
            "Iter 9510. [Train Loss 0.558410, Val Loss 0.562942, Train Acc 76%, Val Acc 73%]\n",
            "Iter 9520. [Train Loss 0.523655, Val Loss 0.563090, Train Acc 78%, Val Acc 73%]\n",
            "Iter 9530. [Train Loss 0.597764, Val Loss 0.563781, Train Acc 70%, Val Acc 73%]\n",
            "Iter 9540. [Train Loss 0.608227, Val Loss 0.561991, Train Acc 74%, Val Acc 73%]\n",
            "Iter 9550. [Train Loss 0.526973, Val Loss 0.566075, Train Acc 78%, Val Acc 73%]\n",
            "Iter 9560. [Train Loss 0.480237, Val Loss 0.561225, Train Acc 82%, Val Acc 73%]\n",
            "Iter 9570. [Train Loss 0.586577, Val Loss 0.563040, Train Acc 65%, Val Acc 73%]\n",
            "Iter 9580. [Train Loss 0.502438, Val Loss 0.563049, Train Acc 81%, Val Acc 73%]\n",
            "Iter 9590. [Train Loss 0.546353, Val Loss 0.562406, Train Acc 71%, Val Acc 73%]\n",
            "Iter 9600. [Train Loss 0.549630, Val Loss 0.561887, Train Acc 74%, Val Acc 73%]\n",
            "Iter 9610. [Train Loss 0.520769, Val Loss 0.562043, Train Acc 77%, Val Acc 73%]\n",
            "Iter 9620. [Train Loss 0.529611, Val Loss 0.562517, Train Acc 76%, Val Acc 73%]\n",
            "Iter 9630. [Train Loss 0.513186, Val Loss 0.562029, Train Acc 74%, Val Acc 73%]\n",
            "Iter 9640. [Train Loss 0.629625, Val Loss 0.561330, Train Acc 74%, Val Acc 73%]\n",
            "Iter 9650. [Train Loss 0.607515, Val Loss 0.562192, Train Acc 73%, Val Acc 73%]\n",
            "Iter 9660. [Train Loss 0.535068, Val Loss 0.563848, Train Acc 72%, Val Acc 73%]\n",
            "Iter 9670. [Train Loss 0.496383, Val Loss 0.562633, Train Acc 74%, Val Acc 73%]\n",
            "Iter 9680. [Train Loss 0.630917, Val Loss 0.563248, Train Acc 66%, Val Acc 73%]\n",
            "Iter 9690. [Train Loss 0.649721, Val Loss 0.561292, Train Acc 72%, Val Acc 73%]\n",
            "Iter 9700. [Train Loss 0.625132, Val Loss 0.565778, Train Acc 70%, Val Acc 73%]\n",
            "Iter 9710. [Train Loss 0.535094, Val Loss 0.561632, Train Acc 74%, Val Acc 73%]\n",
            "Iter 9720. [Train Loss 0.570718, Val Loss 0.563759, Train Acc 72%, Val Acc 73%]\n",
            "Iter 9730. [Train Loss 0.536501, Val Loss 0.561592, Train Acc 75%, Val Acc 73%]\n",
            "Iter 9740. [Train Loss 0.574242, Val Loss 0.562026, Train Acc 70%, Val Acc 73%]\n",
            "Iter 9750. [Train Loss 0.551994, Val Loss 0.561042, Train Acc 72%, Val Acc 73%]\n",
            "Iter 9760. [Train Loss 0.556518, Val Loss 0.560460, Train Acc 72%, Val Acc 73%]\n",
            "Iter 9770. [Train Loss 0.494539, Val Loss 0.561372, Train Acc 78%, Val Acc 73%]\n",
            "Iter 9780. [Train Loss 0.538864, Val Loss 0.561396, Train Acc 73%, Val Acc 73%]\n",
            "Iter 9790. [Train Loss 0.549630, Val Loss 0.560926, Train Acc 72%, Val Acc 73%]\n",
            "Iter 9800. [Train Loss 0.520229, Val Loss 0.562693, Train Acc 74%, Val Acc 73%]\n",
            "Iter 9810. [Train Loss 0.568650, Val Loss 0.562040, Train Acc 72%, Val Acc 73%]\n",
            "Iter 9820. [Train Loss 0.496543, Val Loss 0.564504, Train Acc 77%, Val Acc 73%]\n",
            "Iter 9830. [Train Loss 0.532453, Val Loss 0.563472, Train Acc 77%, Val Acc 73%]\n",
            "Iter 9840. [Train Loss 0.458884, Val Loss 0.565481, Train Acc 81%, Val Acc 73%]\n",
            "Iter 9850. [Train Loss 0.564290, Val Loss 0.561381, Train Acc 73%, Val Acc 73%]\n",
            "Iter 9860. [Train Loss 0.538440, Val Loss 0.562910, Train Acc 76%, Val Acc 73%]\n",
            "Iter 9870. [Train Loss 0.539314, Val Loss 0.561039, Train Acc 74%, Val Acc 73%]\n",
            "Iter 9880. [Train Loss 0.571537, Val Loss 0.562098, Train Acc 74%, Val Acc 73%]\n",
            "Iter 9890. [Train Loss 0.496307, Val Loss 0.564887, Train Acc 76%, Val Acc 73%]\n",
            "Iter 9900. [Train Loss 0.598740, Val Loss 0.561412, Train Acc 74%, Val Acc 73%]\n",
            "Iter 9910. [Train Loss 0.472312, Val Loss 0.561960, Train Acc 77%, Val Acc 73%]\n",
            "Iter 9920. [Train Loss 0.611799, Val Loss 0.560764, Train Acc 72%, Val Acc 73%]\n",
            "Iter 9930. [Train Loss 0.492768, Val Loss 0.562917, Train Acc 82%, Val Acc 73%]\n",
            "Iter 9940. [Train Loss 0.456646, Val Loss 0.562021, Train Acc 83%, Val Acc 73%]\n",
            "Iter 9950. [Train Loss 0.570983, Val Loss 0.562386, Train Acc 72%, Val Acc 73%]\n",
            "Iter 9960. [Train Loss 0.494116, Val Loss 0.563060, Train Acc 76%, Val Acc 73%]\n",
            "Iter 9970. [Train Loss 0.510313, Val Loss 0.562862, Train Acc 75%, Val Acc 73%]\n",
            "Iter 9980. [Train Loss 0.557392, Val Loss 0.563948, Train Acc 71%, Val Acc 73%]\n",
            "Iter 9990. [Train Loss 0.577837, Val Loss 0.563029, Train Acc 72%, Val Acc 73%]\n",
            "Iter 10000. [Train Loss 0.522682, Val Loss 0.563804, Train Acc 76%, Val Acc 73%]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S44GmUZ12o-g"
      },
      "source": [
        "**Explain and discuss your results here:**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUYnIxNlumXz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "0b2b8e61-df08-4b3e-dcd3-5b062a299375"
      },
      "source": [
        "plt.plot(range(991), np.convolve(analysis_dict['Train_Loss'], np.ones(10)/10,mode='valid'))\n",
        "plt.plot(range(1000),analysis_dict['Val_Loss'])\n",
        "plt.legend(['Train Loss','Val Loss'])\n",
        "plt.title('Loss Plot ($\\mu=0.1$)')\n",
        "plt.xlabel('Itr')\n",
        "plt.ylabel('$\\mathcal{L}$')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, '$\\\\mathcal{L}$')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ5HlDFAzGrH"
      },
      "source": [
        "### Part (g) -- 7%\n",
        "\n",
        "Find the optimial value of ${\\bf w}$ and $b$ using your code. Explain how you chose\n",
        "the learning rate $\\mu$ and the batch size. Show plots demostrating good and bad behaviours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dFOFSwgzGrI"
      },
      "source": [
        "w0 = np.random.randn(90)\n",
        "b0 = np.random.randn(1)[0]\n",
        "\n",
        "# Write your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkZt7_932zX2"
      },
      "source": [
        "**Explain and discuss your results here:**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KrQqSj2zGrI"
      },
      "source": [
        "### Part (h) -- 15%\n",
        "\n",
        "Using the values of `w` and `b` from part (g), compute your training accuracy, validation accuracy,\n",
        "and test accuracy. Are there any differences between those three values? If so, why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuKw2mLozGrI"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "train_acc = ...\n",
        "val_acc = ...\n",
        "test_acc = ...\n",
        "\n",
        "print('train_acc = ', train_acc, ' val_acc = ', val_acc, ' test_acc = ', test_acc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXZa1u6920M3"
      },
      "source": [
        "**Explain and discuss your results here:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4eP2Yh1zGrI"
      },
      "source": [
        "### Part (i) -- 15%\n",
        "\n",
        "Writing a classifier like this is instructive, and helps you understand what happens when\n",
        "we train a model. However, in practice, we rarely write model building and training code\n",
        "from scratch. Instead, we typically use one of the well-tested libraries available in a package.\n",
        "\n",
        "Use `sklearn.linear_model.LogisticRegression` to build a linear classifier, and make predictions about the test set. Start by reading the\n",
        "[API documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
        "\n",
        "Compute the training, validation and test accuracy of this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24LCfAa1zGrJ"
      },
      "source": [
        "import sklearn.linear_model\n",
        "\n",
        "model = ...\n",
        "\n",
        "train_acc = ...\n",
        "val_acc = ...\n",
        "test_acc = ...\n",
        "\n",
        "print('train_acc = ', train_acc, ' val_acc = ', val_acc, ' test_acc = ', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRqucdV923tG"
      },
      "source": [
        "**This parts helps by checking if the code worked.**\n",
        "**Check if you get similar results, if not repair your code**\n"
      ]
    }
  ]
}